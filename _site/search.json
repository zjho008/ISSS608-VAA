[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "",
    "text": "Oceanus has a dynamic business landscape with frequent startups, mergers, acquisitions and investments. FishEye International, a non-profit organization that focuses on illegal fishing monitors commercial fishing operators to prevent illegal fishing in the region’s sensitive marine ecosystem. Analysts use a hybrid automated/manual process to transform company records into CatchNet: the Oceanus Knowledge Graph.\nLast year, SouthSeafood Express Corp was caught fishing illegally, disrupting the commercial fishing sector. FishEye aims to analyse the temporal patterns and impacts of this incident on the fishing market. The competitive nature of the market might lead some businesses attempting to seize SouthSeafood’s market share, while others may recognize the consequences of illegal fishing."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview---vast-challenge-mini-challenge-3",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview---vast-challenge-mini-challenge-3",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "",
    "text": "Oceanus has a dynamic business landscape with frequent startups, mergers, acquisitions and investments. FishEye International, a non-profit organization that focuses on illegal fishing monitors commercial fishing operators to prevent illegal fishing in the region’s sensitive marine ecosystem. Analysts use a hybrid automated/manual process to transform company records into CatchNet: the Oceanus Knowledge Graph.\nLast year, SouthSeafood Express Corp was caught fishing illegally, disrupting the commercial fishing sector. FishEye aims to analyse the temporal patterns and impacts of this incident on the fishing market. The competitive nature of the market might lead some businesses attempting to seize SouthSeafood’s market share, while others may recognize the consequences of illegal fishing."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-objectives",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-objectives",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "2 Project Objectives",
    "text": "2 Project Objectives\nThe project will focus on 2 out of the 4 tasks (Questions 3 and 4) from VAST Challenge 2024: Mini-Challenge 3\nThis project aims to develop visualisation tools that work with CatchNet to identify the people who hold influence over business networks and hold those who own nefarious companies accountable. That is especially difficult with varied and changing shareholder and ownership relationships. The tasks are:\n\n\nDevelop a visual approach to examine inferences. Infer how the influence of a company changes through time. Can we infer ownership or influence that a network may have?\n\n\n\n\nIdentify the network associated with SouthSeafood Express Corp and visualize how this network and competing businesses change as a result of their illegal fishing behavior. Which companies benefited from SouthSeafood Express Corp legal troubles? Are there other suspicious transactions that may be related to illegal fishing? Providing visual evidence for the conclusions.\n\n\nNote: the VAST challenge is focused on visual analytics and graphical figures should be included with your response to each question. Please include a reasonable number of figures for each question (no more than about 6) and keep written responses as brief as possible (around 250 words per question). Participants are encouraged to new visual representations rather than relying on traditional or existing approaches."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "3 The Data",
    "text": "3 The Data\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json file into the R environment.\n\n\nCode\nmc3 &lt;- fromJSON(\"data/MC3/mc3.json\")\n\n\nInitially, when trying to load the mc3.json data we faced an error message regarding a NaN issue.\n Hence we converted solely the NaN fields to “NaN” to curb this issue and the mc3.json file is imported successfully.\n\n\nCode\nclass(mc3)\n\n\n[1] \"list\"\n\n\nThe output is called mc3. It is a large list R object. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "4 Wrangling and tidying edges",
    "text": "4 Wrangling and tidying edges\nIn this section, we will extract and wrangle the edges object.\n\n4.1 Extracting the edges data\nThe code chunk below will be used to extract the links data.frame of mc3 and saves it as a tibble data.frame called mc3_edges.\n\n\nCode\nmc3_edges &lt;- as_tibble(mc3$links) %&gt;%\n  distinct() #to avoid duplicate records; source,target,type if they are the same will be treated as duplicates and kept as one\n\n\nglimpse() of dplyr will be used to reveal the structure of mc3_edges tibble data.table\n\n\nCode\nglimpse(mc3_edges)\n\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\nIdentified issues from the table above\n\n\n\n\ncolumns with date data type are not in the correct format\nsome field names(for e.g _last_edited_by) start with “_” and will have to be renamed to avoid unnecessary coding issues in the later part of the tasks.\n\n\n\n\n\n4.2 Correcting the date data type\nThe code chunk below uses as_datetime() of the lubridate package to convert fields with character date into POSIXt format.\n\n\nCode\nmc3_edges$\"start_date\" &lt;- as_datetime(mc3_edges$start_date)\nmc3_edges$\"_last_edited_date\" &lt;- as_datetime(mc3_edges$\"_last_edited_date\")\nmc3_edges$\"_date_added\" &lt;- as_datetime(mc3_edges$\"_date_added\")\nmc3_edges$\"end_date\" &lt;- as_datetime(\"mc3_edges$end_date\")\n\n\nNext, glimpse() function will be used to confirm if the process have been performed correctly.\n\n\nCode\nglimpse(mc3_edges)\n\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;dttm&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;dttm&gt; 2035-01-01, 2035-07-15, 2035-01-01, 2035-01-01, 2…\n$ `_date_added`       &lt;dttm&gt; 2035-01-01, 2035-07-15, 2035-01-01, 2035-01-01, 2…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\n\n\n4.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields that start with “_”.\n\n\nCode\nmc3_edges &lt;- mc3_edges %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"date_added\" = \"_date_added\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\nNext, glimpse() function will be used to confirm if the process have been performed correctly.\n\n\nCode\nglimpse(mc3_edges)\n\n\nRows: 75,817\nColumns: 11\n$ start_date       &lt;dttm&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2034…\n$ type             &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholder…\n$ last_edited_by   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pelagia…\n$ last_edited_date &lt;dttm&gt; 2035-01-01, 2035-07-15, 2035-01-01, 2035-01-01, 2035…\n$ date_added       &lt;dttm&gt; 2035-01-01, 2035-07-15, 2035-01-01, 2035-01-01, 2035…\n$ raw_source       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corpora…\n$ algorithm        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Import…\n$ source           &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowman-…\n$ target           &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and Do…\n$ key              &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date         &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\n\n\n4.4 Splitting of words\nFrom the screenshot below, we can see that the text in type field are not in a tidy manner.\n We are going to tidy the type column by creating two columns as shown below.\nFirstly, to split the text in type column into two columns; namely event 1 and event2\n\n\nCode\nword_list &lt;- strsplit(mc3_edges$type, \"\\\\.\")\n\n\nThe code chunk below will be used to find the maximum number of elements in any split\n\n\nCode\nmax_elements &lt;- max(lengths(word_list))\n\n\nThe code chunk below will be used to pad shorter splits with NA values to make them all the same length.\n\n\nCode\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\n\n\n\nCode\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"event\", 1:max_elements)\n\n\nSince the output above is a matrix, the code chunk below is used to convert word_df into a tibble data.frame.\n\n\nCode\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(event2, event3)\nclass(word_df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nNow the extracted columns are appended back into the mc3_edges tibble data.frame\n\n\nCode\nmc3_edges &lt;- mc3_edges %&gt;%\n  cbind(word_df)\n\n\nTo save mc3_edges into R rds file format\n\n\nCode\nwrite_rds(mc3_edges, \"data/rds/mc3_edges.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "4 Wrangling and tidying nodes",
    "text": "4 Wrangling and tidying nodes\nIn this section, we will extract and wrangle the nodes object.\n\n4.1 Extracting the nodes data\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and parses it as a tibble data.frame called mc3_nodes.\n\n\nCode\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  distinct()\n\n\nNext, glimpse() function will be used to confirm if the process have been performed correctly.\n\n\nCode\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the table above, the date data type and inappropriate field name issues as faced earlier are also present:\n\ncolumns with date data type are not in the correct format\nsome field names(for e.g _last_edited_by, _date_added) start with “_” and will have to be renamed to avoid unnecessary coding issues in the later part of the tasks.\n\n\n\nHence, we will also work on correcting these errors.\n\n\n4.2 Correcting the date data type\nThe code chunk below uses as_datetime() of the lubridate package to convert fields with character date into POSIXt format.\n\n\nCode\nmc3_nodes$\"founding_date\" &lt;- as_datetime(mc3_nodes$founding_date)\nmc3_nodes$\"_last_edited_date\" &lt;- as_datetime(mc3_nodes$\"_last_edited_date\")\nmc3_nodes$\"_date_added\" &lt;- as_datetime(mc3_nodes$\"_date_added\")\nmc3_nodes$\"dob\" &lt;- as_datetime(mc3_nodes$dob)\n\n\nNext, glimpse() function will be used to confirm if the process have been performed correctly.\n\n\nCode\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;dttm&gt; 1954-04-24, 2009-06-12, 2029-12-15, 1972-02-16, 1…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;dttm&gt; 2035-01-01, 2035-01-01, 2035-01-01, 2035-01-01, 2…\n$ `_date_added`       &lt;dttm&gt; 2035-01-01, 2035-01-01, 2035-01-01, 2035-01-01, 2…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\n\n\n4.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields that start with “_”.\n\n\nCode\nmc3_nodes &lt;- mc3_nodes %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"date_added\" = \"_date_added\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\nNext, glimpse() function will be used to confirm if the process have been performed correctly.\n\n\nCode\nglimpse(mc3_nodes)\n\n\nRows: 60,520\nColumns: 15\n$ type             &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organization.C…\n$ country          &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", \"Oc…\n$ ProductServices  &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food pr…\n$ PointOfContact   &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertson\",…\n$ HeadOfOrg        &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules Labbé…\n$ founding_date    &lt;dttm&gt; 1954-04-24, 2009-06-12, 2029-12-15, 1972-02-16, 1954…\n$ revenue          &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, 169…\n$ TradeDescription &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer an…\n$ last_edited_by   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoch\",…\n$ last_edited_date &lt;dttm&gt; 2035-01-01, 2035-01-01, 2035-01-01, 2035-01-01, 2035…\n$ date_added       &lt;dttm&gt; 2035-01-01, 2035-01-01, 2035-01-01, 2035-01-01, 2035…\n$ raw_source       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Corpor…\n$ algorithm        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic Im…\n$ id               &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Abbot…\n$ dob              &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\n\n\n4.4 Splitting of words\nFrom the screenshot below, we can see that similar to mc3_edges the text in type field are not in a tidy manner\n We are going to tidy the type column by creating two columns as shown below.\nFirstly, to split the text in type column into two columns; namely event 2 and event 3\n\n\nCode\nword_list_nodes &lt;- strsplit(mc3_nodes$type, \"\\\\.\")\n\n\nThe code chunk below will be used to find the maximum number of elements in any split\n\n\nCode\nmax_elements_nodes &lt;- max(lengths(word_list_nodes))\n\n\nThe code chunk below will be used to pad shorter splits with NA values to make them all the same length.\n\n\nCode\nword_list_padded_nodes &lt;- lapply(word_list_nodes, \nfunction(x) c(x, rep(NA, max_elements_nodes - length(x))))\n\n\n\n\nCode\nword_df_nodes &lt;- do.call(rbind, word_list_padded_nodes)\ncolnames(word_df_nodes) &lt;- paste0(\"event\", 1:max_elements_nodes)\n\n\nSince the output above is a matrix, the code chunk below is used to convert word_df_nodes into a tibble data.frame.\n\n\nCode\nword_df_nodes &lt;- as_tibble(word_df_nodes) %&gt;%\n  select(event2, event3)\nclass(word_df_nodes)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nNow the extracted columns are appended back into the mc3_edges tibble data.frame\n\n\nCode\nmc3_nodes &lt;- mc3_nodes %&gt;%\n  cbind(word_df_nodes)\n\n\nWe will proceed to save the mc3_nodes into R rds file format as a physical file for future usage. Doing so will also ensure we do not have to repeat the steps above.\n\n\nCode\nwrite_rds(mc3_nodes, \"data/rds/mc3_nodes.rds\")\n\n\n\n\nCode\n%%{\n  init: {\n    \"theme\": \"base\",\n    \"themeVariables\": {\n      \"primaryColor\": \"#d8e8e6\",\n      \"primaryTextColor\": \"#325985\",\n      \"primaryBorderColor\": \"#325985\",\n      \"lineColor\": \"#325985\",\n      \"secondaryColor\": \"#cedded\",\n      \"tertiaryColor\": \"#fff\" \n      }\n  }\n}%%\n\nflowchart LR\n    A[Company] --&gt;|Influence| B(Person)\n    B --&gt; C{Entity.Person}\n    B --&gt; D{Entity.Person.CEO}\n    D --&gt;|unique identifier & name| id\n    D --&gt;|person date of birth| dob\n    D --&gt;|country associated|country\n    C --&gt;|unique identifier & name| E(id)\n    C --&gt;|person date of birth| F(dob)\n    C --&gt;|country associated| G(country)\n\n\n\n\n%%{\n  init: {\n    \"theme\": \"base\",\n    \"themeVariables\": {\n      \"primaryColor\": \"#d8e8e6\",\n      \"primaryTextColor\": \"#325985\",\n      \"primaryBorderColor\": \"#325985\",\n      \"lineColor\": \"#325985\",\n      \"secondaryColor\": \"#cedded\",\n      \"tertiaryColor\": \"#fff\" \n      }\n  }\n}%%\n\nflowchart LR\n    A[Company] --&gt;|Influence| B(Person)\n    B --&gt; C{Entity.Person}\n    B --&gt; D{Entity.Person.CEO}\n    D --&gt;|unique identifier & name| id\n    D --&gt;|person date of birth| dob\n    D --&gt;|country associated|country\n    C --&gt;|unique identifier & name| E(id)\n    C --&gt;|person date of birth| F(dob)\n    C --&gt;|country associated| G(country)\n\n\n\n\n\n\n\nCode\nflowchart LR\n  A[Hard edge] --&gt; |TESTING| B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; |TESTING| B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#reference",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#reference",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "8 Reference",
    "text": "8 Reference\n\nKam, T.S. (2023). Chapter 27: Modelling, Visualising and Analysing Network Data with R"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "",
    "text": "In Take-home Exercise 1 (Part 1), we were tasked to produce two to three data visualisations using ggplot2 and its extensions to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024. The data preparation was also processed by using the tidyverse family of packages. The exercise allowed us to explore factors such as Transacted Price ($) and Unit Price ($ PSM) in relation to Property Typeand Planning Region to list a few.\nFor this Take-home Exercise 1 (Part 2), the objective is to perform a makeover and improve on the original data visualisation from other peers. We will be critiquing one data visualisation in terms of its clarity and aesthetics. A sketch of the alternative design will be done up based on the data visualisation design principles (four quadrants of clarity and aesthetic) and finally a remake of the original design will be implemented."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#overview",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#overview",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "",
    "text": "In Take-home Exercise 1 (Part 1), we were tasked to produce two to three data visualisations using ggplot2 and its extensions to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024. The data preparation was also processed by using the tidyverse family of packages. The exercise allowed us to explore factors such as Transacted Price ($) and Unit Price ($ PSM) in relation to Property Typeand Planning Region to list a few.\nFor this Take-home Exercise 1 (Part 2), the objective is to perform a makeover and improve on the original data visualisation from other peers. We will be critiquing one data visualisation in terms of its clarity and aesthetics. A sketch of the alternative design will be done up based on the data visualisation design principles (four quadrants of clarity and aesthetic) and finally a remake of the original design will be implemented."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#getting-started",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the required libraries\n\ntidyverse: (i.e. readr, tidyr, dplyr, ggplot2) for performing data science tasks such as importing, tidying, and wrangling data, as well as creating graphics based on The Grammar of Graphics,\nreshape2 for transforming data between wide and long formats\nggthemes: provides some extra themes, geoms, and scales for ‘ggplot2’.\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty\npatchwork: an R package for preparing composite figure created using ggplot2.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggrepel: an R package which provides geoms for ggplot2 to repel overlapping text labels.\nknitr: for building static html table to aid us in having a better view of tables\nlubridate: R package that makes it easier to work with dates and times.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below uses p_load() function from pacman package to check if packages listed are already installed in the computer. The packages will be loaded if they are found to be installed. Otherwise, the function will proceed to install and load them into R environment.\n\npacman::p_load(tidyverse, reshape2, ggthemes,\n               ggdist, patchwork, ggridges,\n               ggrepel, knitr, lubridate,\n               patchwork)\n\n\n\n2.2 Data Import and Wrangling\n\nLabelling Data2023Q12023Q22023Q32023Q42024Q1\n\n\nThe subsequent code chunks utilises the read_csv function to import the five .csv data files from REALIS into the R environment. The data will also be labelled as such for identification:\n\n2023Q1: ResidentialTransaction20240308160536\n2023Q2: ResidentialTransaction20240308160736\n2023Q3: ResidentialTransaction20240308161009\n2023Q4: ResidentialTransaction20240308161109\n2024Q1: ResidentialTransaction20240414220633\n\nThe code chunk below utilises the rename_with() function to change the column names accordingly using column_rename as an object.\n\ncolumn_rename &lt;- function(orig_name) {\n  # Add underscores to spaces\n  gsub(\" +\", \"_\",\n       # Remove special characters\n       gsub(\"[^A-Z ]\", \"\",\n            # Convert to upper case and remove trailing spaces\n            toupper(orig_name)) %&gt;% trimws())\n}\n\n\n\n\nproperty_2023q1 &lt;- read_csv('data/ResidentialTransaction20240308160536.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2023q2 &lt;- read_csv('data/ResidentialTransaction20240308160736.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2023q3 &lt;- read_csv('data/ResidentialTransaction20240308161009.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2023q4 &lt;- read_csv('data/ResidentialTransaction20240308161109.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2024q1 &lt;- read_csv('data/ResidentialTransaction20240414220633.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nThe code chunk below glimpse() will provide us with an overview of the data.\n\n2023Q12023Q22023Q32023Q42024Q1\n\n\n\nglimpse(property_2023q1)\n\nRows: 4,722\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASURE…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 128000…\n$ AREA_SQFT                   &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88, …\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 2023…\n$ ADDRESS                     &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JALA…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 420.…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive C…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"99 …\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"Pr…\n$ POSTAL_CODE                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", \"7…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"East Region\", \"North Re…\n$ PLANNING_AREA               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishun\"…\n\n\n\n\n\nglimpse(property_2023q2)\n\nRows: 6,125\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"THE GAZANIA\", \"THE GAZANIA\", \"ONE PEARL B…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 1528000, 1938000, 2051000, 1850700, 202150…\n$ AREA_SQFT                   &lt;dbl&gt; 678.13, 958.00, 699.66, 882.65, 699.66, 78…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2253, 2023, 2931, 2097, 2889, 2339, 3560, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Apr 2023\", \"01 Apr 2023\", \"01 Apr 2023…\n$ ADDRESS                     &lt;chr&gt; \"15 HOW SUN DRIVE #02-31\", \"7 HOW SUN DRIV…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 63, 89, 65, 82, 65, 73, 191, 46, 62, 93, 8…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 24254, 21775, 31554, 22570, 31100, 25178, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Apartment\",…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"Freehold\", \"Freehold\", \"99 yrs from 01/03…\n$ COMPLETION_DATE             &lt;chr&gt; \"2022\", \"2022\", \"Uncompleted\", \"Uncomplete…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"N.A\", \"Private\", \"Private\", \"HDB\", \"Priva…\n$ POSTAL_CODE                 &lt;chr&gt; \"538545\", \"538530\", \"169016\", \"419535\", \"2…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"19\", \"19\", \"03\", \"14\", \"10\", \"10\", \"09\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"53\", \"53\", \"16\", \"41\", \"27\", \"26\", \"22\", …\n$ PLANNING_REGION             &lt;chr&gt; \"North East Region\", \"North East Region\", …\n$ PLANNING_AREA               &lt;chr&gt; \"Serangoon\", \"Serangoon\", \"Outram\", \"Bedok…\n\n\n\n\n\nglimpse(property_2023q3)\n\nRows: 6,206\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"MYRA\", \"NORTH GAIA\", \"NORTH GAIA\", \"NORTH…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 1658000, 1449000, 1365000, 1231000, 127200…\n$ AREA_SQFT                   &lt;dbl&gt; 667.37, 1076.40, 1076.40, 958.00, 1001.05,…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2484, 1346, 1268, 1285, 1271, 2062, 1465, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Jul 2023\", \"01 Jul 2023\", \"01 Jul 2023…\n$ ADDRESS                     &lt;chr&gt; \"9 MEYAPPA CHETTIAR ROAD #02-07\", \"27 YISH…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 62, 100, 100, 89, 93, 156, 86, 86, 86, 86,…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 26742, 14490, 13650, 13831, 13677, 22192, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Apartment\", \"Executive Condominium\", \"Exe…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"Freehold\", \"99 yrs from 15/02/2021\", \"99 …\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"N.A\", \"HDB\", \"HDB\", \"HDB\", \"HDB\", \"Privat…\n$ POSTAL_CODE                 &lt;chr&gt; \"358456\", \"769342\", \"769342\", \"769299\", \"7…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"13\", \"27\", \"27\", \"27\", \"27\", \"08\", \"18\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"35\", \"76\", \"76\", \"76\", \"76\", \"21\", \"52\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"North Region\", \"North R…\n$ PLANNING_AREA               &lt;chr&gt; \"Toa Payoh\", \"Yishun\", \"Yishun\", \"Yishun\",…\n\n\n\n\n\nglimpse(property_2023q4)\n\nRows: 4,851\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"LEEDON GREEN\", \"LIV @ MB\", \"MORI\", \"THE A…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 1749000, 3148740, 2422337, 1330000, 223700…\n$ AREA_SQFT                   &lt;dbl&gt; 538.20, 1453.14, 1259.39, 721.19, 1130.22,…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 3250, 2167, 1923, 1844, 1979, 2111, 2131, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Oct 2023\", \"01 Oct 2023\", \"01 Oct 2023…\n$ ADDRESS                     &lt;chr&gt; \"26 LEEDON HEIGHTS #11-08\", \"114A ARTHUR R…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 50.0, 135.0, 117.0, 67.0, 105.0, 55.0, 126…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 34980, 23324, 20704, 19851, 21305, 22725, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Apartment\",…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"Freehold\", \"99 yrs from 23/11/2021\", \"Fre…\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"Private\", \"Private\", \"Private\", \"Private\"…\n$ POSTAL_CODE                 &lt;chr&gt; \"266221\", \"439826\", \"399738\", \"668159\", \"7…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"10\", \"15\", \"14\", \"23\", \"26\", \"22\", \"26\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"26\", \"43\", \"39\", \"66\", \"78\", \"61\", \"78\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"Central Region\", \"Centr…\n$ PLANNING_AREA               &lt;chr&gt; \"Bukit Timah\", \"Marine Parade\", \"Geylang\",…\n\n\n\n\n\nglimpse(property_2024q1)\n\nRows: 4,902\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"THE LANDMARK\", \"POLLEN COLLECTION\", \"SKY …\n$ TRANSACTED_PRICE            &lt;dbl&gt; 2726888, 3850000, 2346000, 2190000, 195400…\n$ AREA_SQFT                   &lt;dbl&gt; 1076.40, 1808.35, 1087.16, 807.30, 796.54,…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2533, 2129, 2158, 2713, 2453, 2577, 838, 1…\n$ SALE_DATE                   &lt;chr&gt; \"01 Jan 2024\", \"01 Jan 2024\", \"01 Jan 2024…\n$ ADDRESS                     &lt;chr&gt; \"173 CHIN SWEE ROAD #22-11\", \"34 POLLEN PL…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Land\", \"Strata\", \"Strata\", \"Str…\n$ AREA_SQM                    &lt;dbl&gt; 100.0, 168.0, 101.0, 75.0, 74.0, 123.0, 32…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 27269, 22917, 23228, 29200, 26405, 27741, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Terrace House\", \"Apartment…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"99 yrs from 28/08/2020\", \"99 yrs from 09/…\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"Private\", \"N.A\", \"HDB\", \"N.A\", \"Private\",…\n$ POSTAL_CODE                 &lt;chr&gt; \"169878\", \"807233\", \"469657\", \"118992\", \"5…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"03\", \"28\", \"16\", \"05\", \"21\", \"21\", \"28\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"16\", \"80\", \"46\", \"11\", \"59\", \"58\", \"79\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"North East Region\", \"Ea…\n$ PLANNING_AREA               &lt;chr&gt; \"Outram\", \"Serangoon\", \"Bedok\", \"Queenstow…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#data-wrangling",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nAdding columnsCombining tablesFiltering necessary columns (The code chunk)\n\n\n\nproperty_2023q1 &lt;- property_2023q1 %&gt;%\n  mutate(\n    QUARTER=\"2023Q1\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2023q2 &lt;- property_2023q2 %&gt;%\n  mutate(\n    QUARTER=\"2023Q2\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2023q3 &lt;- property_2023q3 %&gt;%\n  mutate(\n    QUARTER=\"2023Q3\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2023q4 &lt;- property_2023q4 %&gt;%\n  mutate(\n    QUARTER=\"2023Q4\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2024q1 &lt;- property_2024q1 %&gt;%\n  mutate(\n    QUARTER=\"2024Q1\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\n\n\n\n\nrealis &lt;- property_2023q1 %&gt;%\n  rbind(property_2023q2) %&gt;%\n  rbind(property_2023q3) %&gt;%\n  rbind(property_2023q4) %&gt;%\n  rbind(property_2024q1)\nkable(head(realis, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\nQUARTER\nMONTH_YEAR\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82.0\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n2023Q1\nJan-23\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82.0\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n2023Q1\nJan-23\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100.0\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n2023Q1\nJan-23\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96.0\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n2023Q1\nJan-23\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81.0\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n2023Q1\nJan-23\n\n\nNANYANG PARK\n5870000\n3322.85\n1767\n03 Jan 2023\n72 JALAN LIMBOK\nResale\nLand\n308.7\n19015\n-\nTerrace House\n1\n999 yrs from 14/02/1881\n-\nPrivate\n548742\n19\n54\nNorth East Region\nHougang\n2023Q1\nJan-23\n\n\nPALMS @ SIXTH AVENUE\n4950000\n4520.88\n1095\n03 Jan 2023\n231 SIXTH AVENUE\nResale\nStrata\n420.0\n11786\n-\nSemi-Detached House\n1\nFreehold\n2015\nPrivate\n275780\n10\n27\nCentral Region\nBukit Timah\n2023Q1\nJan-23\n\n\nN.A.\n3260000\n1555.40\n2096\n03 Jan 2023\n19 TENG TONG ROAD\nResale\nLand\n144.5\n22561\n-\nTerrace House\n1\nFreehold\n1941\nPrivate\n423510\n15\n42\nCentral Region\nMarine Parade\n2023Q1\nJan-23\n\n\nWHISTLER GRAND\n850000\n441.32\n1926\n03 Jan 2023\n107 WEST COAST VALE #30-04\nSub Sale\nStrata\n41.0\n20732\n-\nApartment\n1\n99 yrs from 07/05/2018\n2022\nHDB\n126751\n05\n12\nWest Region\nClementi\n2023Q1\nJan-23\n\n\nNORTHOAKS\n1268000\n1603.84\n791\n03 Jan 2023\n30 WOODLANDS CRESCENT #01-11\nResale\nStrata\n149.0\n8510\n-\nExecutive Condominium\n1\n99 yrs from 16/12/1997\n2000\nHDB\n738086\n25\n73\nNorth Region\nWoodlands\n2023Q1\nJan-23\n\n\n\n\n\n\n\nAfter adding the QUARTER columns, there are now 22 variables in the dataframe. However, for this exercise not all of them are necessary to carry out the analysis. We shall filter out the necessary columns and drop the rest for efficiency.\n\nrealis &lt;-\n  realis %&gt;% select(\n    c(\n      QUARTER,\n      MONTH_YEAR,\n      PROPERTY_TYPE,\n      PLANNING_REGION,\n      PLANNING_AREA,\n      TRANSACTED_PRICE,\n      AREA_SQFT,\n      UNIT_PRICE_PSF,\n      SALE_DATE\n    )\n  )\nglimpse(realis) #Overview of transformed data\n\nRows: 26,806\nColumns: 9\n$ QUARTER          &lt;chr&gt; \"2023Q1\", \"2023Q1\", \"2023Q1\", \"2023Q1\", \"2023Q1\", \"20…\n$ MONTH_YEAR       &lt;chr&gt; \"Jan-23\", \"Jan-23\", \"Jan-23\", \"Jan-23\", \"Jan-23\", \"Ja…\n$ PROPERTY_TYPE    &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive Condominium\"…\n$ PLANNING_REGION  &lt;chr&gt; \"Central Region\", \"East Region\", \"North Region\", \"Nor…\n$ PLANNING_AREA    &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishun\", \"Sengkang…\n$ TRANSACTED_PRICE &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280000, 5870000,…\n$ AREA_SQFT        &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88, 3322.85, 45…\n$ UNIT_PRICE_PSF   &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095, 2096, 1926,…\n$ SALE_DATE        &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 2023\", \"02 Jan …\n\n\nUpon using glimpse(), it can be observed that there are 9 variables relevant to our data viz makeover."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#data-visualisation-makeover",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#data-visualisation-makeover",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "3 Data Visualisation Makeover",
    "text": "3 Data Visualisation Makeover\nIn this section, we will proceed with a makeover of a peer’s data visualisation and building an improved version. Shown below is the plot of our peer’s plot.\n\n\n\n\n\n\nThe author stated:\n\n\n\nAs we mentioned about the individual market is focus on the apartment and condominium above, and we know the distribution of total property, what about the first quarter unit price of these two popular goods?\nUpon examination of the violin plots, a clear disparity emerges between the average unit prices of condominiums and apartments, standing at approximately $1,500 and $2,000, respectively, for the period spanning January to March. Noteworthy is the discernible uptick in both unit price and transaction volume from January to March 2024. Despite an overall reduction in total transactions vis-a-vis the preceding year, there is an unmistakable trend towards growth within specific sub-markets, suggesting an increasing inclination towards higher-value properties\n\n\n\nThe code chunk (i)The plot (i)The code chunk (ii)The plot (ii)\n\n\n\nfiltered_data &lt;- combined_data %&gt;%\n  mutate(Sale_Date = dmy(`Sale Date`)) %&gt;%\n  filter((year(Sale_Date) == 2023 & \n          month(Sale_Date) %in% 1:12) |\n         (year(Sale_Date) == 2024 & \n          month(Sale_Date) %in% 1:3)) %&gt;%\n  mutate(Quarter_Sale_Data = case_when(\n    between(Sale_Date, as.Date(\"2023-01-01\"), as.Date(\"2023-03-31\")) ~ \"Q1_2023\",\n    between(Sale_Date, as.Date(\"2023-04-01\"), as.Date(\"2023-06-30\")) ~ \"Q2_2023\",\n    between(Sale_Date, as.Date(\"2023-07-01\"), as.Date(\"2023-09-30\")) ~ \"Q3_2023\",\n    between(Sale_Date, as.Date(\"2023-10-01\"), as.Date(\"2023-12-31\")) ~ \"Q4_2023\",\n    between(Sale_Date, as.Date(\"2024-01-01\"), as.Date(\"2024-03-31\")) ~ \"Q1_2024\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(Quarter_Sale_Data)) %&gt;%\n  mutate(Month_Sale_Data = paste0(year(Sale_Date), \"-\", month(Sale_Date)))\n\nfiltered_data &lt;- filtered_data %&gt;%\n  filter(`Property Type` %in% c(\"Apartment\", \"Condominium\"))\n\nggplot(filtered_data, aes(x = Month_Sale_Data, y = `Unit Price ($ PSF)`, color = `Property Type`)) +\n  geom_violin() +\n  geom_point(position = \"jitter\",\n             size = 0.1) +\n  labs(title = \"Unit Price per Square Foot for Apartments and Condominiums\",\n       x = \"Month\",\n       y = \"Unit Price ($ PSF)\") +\n  theme_light(base_size = 6) +\n  xlim(c(\"2024-1\",\"2024-2\",\"2024-3\"))\n\n\n\n\n\n\nPeer’s Data Visualisation\n\n\n\n\n\nggplot(filtered_data, aes(x = Month_Sale_Data, y = `Unit Price ($ PSF)`, color = `Property Type`)) +\n  geom_violin() +\n  geom_point(position = \"jitter\",\n             size = 0.1) +\n  labs(title = \"Unit Price per Square Foot for Apartments and Condominiums\",\n       x = \"Month\",\n       y = \"Unit Price ($ PSF)\") +\n  theme_light(base_size = 6) +\n  xlim(c(\"2023-1\",\"2023-2\",\"2023-3\"))\n\n\n\n\n\n\nPeer’s Data Visualisation\n\n\n\n\n\n\n3.1 Observations: Clarity and Aesthetics\nClarity\n\nThe use of a violin plot overlaid with scatter plot points helps illustrate the distribution of prices per square foot for both apartments and condominiums across different months.\nThe red (apartment) and teal (condominium) color distinction or scatterplot is generally clear, but there’s significant overlap in data points, which may confuse the viewer about the exact differences in price distributions between these property types. This might also affect the ease of reading and understanding by audiences from the general public.\n\nAesthetics\n\nThe main title while clear could be centralised for easier readability.\nThe plot successfully uses colour to differentiate between the two types of properties. The choice of colors is visually distinct, which is helpful for quick differentiation.\nHowever, the presence of outliers, particularly those extreme values shown as vertical lines extending from the main bodies of the violins, can confuse readers from the overall trends from the plot.\n\n\n\n3.2 Sketch of alternative design\n Improvements based on the above points mentioned earlier:\n\nMain title which was centred to give improved balanced to the plot layout.\nCombine each different selected property type into each portion of the chart, sharing the same y-axis to reveal the distribution among different property types simultaneously.\nAdded additional pointers and/or labels to highlight summary statistic values such as Mean, Median and IQR.\nAddress the issue of outliers in the plot for this case I have chosen to highlight the outliers to enable readers to be aware and take note of them since they were still actual property transactions.\nUse widely different colours to differentiate between the variables for better visual distinction.\n\n\n\n3.3 Remake of Original Design\n\n1st iteration\nDerived from the sketch ideation, this plot shows Unit Price ($ PSF) by Quarter as a start.\n\nggplot(data= realis,\n       aes(x= QUARTER, y= UNIT_PRICE_PSF, color = QUARTER)) +\n  geom_violin(aes(fill = QUARTER), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width= 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +  \n  coord_cartesian(ylim = c(400,6000)) +\n  scale_color_manual(values=c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\", \"#0437bf\")) +\n  theme_economist() +\n  labs(title=\"Unit Price ($PSF) by Quarter\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title=element_text(size= 12, hjust= 0.5),\n        axis.text = element_text(size= 10),\n        legend.position = \"none\")\n\n\n\n\n\n\n2nd iteration (Filtering of variables)\nTo accommodate to the peer’s selection of selected property type\n\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         QUARTER %in% c(\"2023Q1\", \"2024Q1\"))\n\nggplot(data= filtered_data,\n       aes(x= QUARTER, y= UNIT_PRICE_PSF, color = QUARTER)) +\n  geom_violin(aes(fill = QUARTER), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width= 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +  \n  coord_cartesian(ylim = c(400,6000)) +\n  scale_color_manual(values=c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\", \"#0437bf\")) +\n  theme_economist() +\n  labs(title=\"Unit Price ($PSF) by Quarter\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title=element_text(size= 12, hjust= 0.5),\n        axis.text = element_text(size= 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n\n\n\n\n\n3rd iteration (Filtering of variables)\nTo accommodate to the peer’s selection of time period (Month)\n\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\nggplot(data= filtered_data,\n       aes(x= MONTH_YEAR, y= UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width= 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +  \n  coord_cartesian(ylim = c(400,6000)) +\n  scale_color_manual(values=c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\", \"#0437bf\")) +\n  theme_economist() +\n  labs(title=\"Unit Price ($PSF) by Month\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title=element_text(size= 12, hjust= 0.5),\n        axis.text = element_text(size= 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n\n\n\n\n\n4th iteration (Addition of Summary Statistics)\nFor Year 2023\n\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2023)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)\n\n\n\n\nFor Year 2024\n\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-24\", \"Feb-24\", \"Mar-24\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-24\", \"Feb-24\", \"Mar-24\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot2 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2024)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot2)\n\n\n\n\n\n\n5th iteration (Highlighting Outliers)\n\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"darkred\", outlier.size = 1, outlier.shape = 8, \n               outlier.alpha = 0.8) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2023)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#improved-visualisation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#improved-visualisation",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "4 Improved Visualisation",
    "text": "4 Improved Visualisation\n\nJan-Mar 2024Jan-Mar 2023\n\n\n\n\nShow the code\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-24\", \"Feb-24\", \"Mar-24\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-24\", \"Feb-24\", \"Mar-24\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"darkred\", outlier.size = 1, outlier.shape = 8, \n               outlier.alpha = 0.8) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2024)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)\n\n\n\n\n\n\n\n\n\nShow the code\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"darkred\", outlier.size = 1, outlier.shape = 8, \n               outlier.alpha = 0.8) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2023)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#key-takeaways",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#key-takeaways",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "5 Key Takeaways",
    "text": "5 Key Takeaways\nOverall, the selected peer’s work was done up relatively well.\nThe processes for the data visualisation makeover in this take-home exercise illustrates the utmost importance of attention to detail when making a plot. Here are some pointers which I found were useful:\n\nTo check the data\n\nIt goes without saying that data is the core element of any chart or graph. If the data is unreliable, the graph will also be unreliable. Therefore, it’s crucial to ensure your data is accurate. Begin by creating straightforward graphs to identify any outliers or unusual spikes. Always double-check anything that looks off. You may find a surprising number of data entry errors in the spreadsheets you receive.\n\nChoosing of colours\n\nEffective use of color can significantly enhance and clarify a presentation, while poor use of color can lead to confusion and obscurity. Although color adds an aesthetic quality, its primary role in displaying information is functional. The key is to consider what information needs to be conveyed and to determine if and how color can improve the communication of that information.\n\nHighlighting what’s important\n\nTo effectively communicate a message, it’s essential to direct your audience’s attention to the data under analysis. Start with a title that captures the essence of your insight. Then, emphasize your data visually while maintaining other data in a subdued manner in the background, providing context and enabling comparisons."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part2.html#references",
    "title": "Take-home Exercise 1 (Part 2): DataVis Makeover",
    "section": "6 References",
    "text": "6 References\n\nURA releases flash estimate of 1st Quarter 2024 private residential property price index\nUnsold private housing stock on the rise ahead of ramp-up in new launches in 2024\nHDB resale prices rise 1.7%; private home prices up 1.5% in first quarter: Flash estimates\n7 Basic Rules for Making Charts and Graphs\nData Visualization: Clarity or Aesthetics?\nDos and don’ts of data visualisation — European Environment Agency\nChoosing Colors for Data Visualization"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Singapore’s residential property market is branched into two primary sectors: public and private housing.Public housing, which is subsidised by the government, primarily caters to the essential housing needs of the general populace, specifically for households with a monthly income of S$14,000 or less. In contrast, households earning more than this income threshold generally turn to the private residential market. Moreover, given Singapore’s limited land area with it being one of the smallest countries in the world, real estate remains perpetually high in demand. This tends to bring about challenges due to the competitive nature of securing housing in either the public or private residential market.\n\n\n\nThe task for this exercise aims to elucidate the dynamics of the private residential market and sub-markets in the 1st quarter of 2024 as a graphical editor of a media company. This will be done with a couple of data visualizations in which they will are assumed to be consumed by the general public. From the visualisation we aim to uncover:\n\nthe distributions of property prices alongside property type, and\nany plausible relationship between these factors with their planning regions"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#introduction",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#introduction",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Singapore’s residential property market is branched into two primary sectors: public and private housing.Public housing, which is subsidised by the government, primarily caters to the essential housing needs of the general populace, specifically for households with a monthly income of S$14,000 or less. In contrast, households earning more than this income threshold generally turn to the private residential market. Moreover, given Singapore’s limited land area with it being one of the smallest countries in the world, real estate remains perpetually high in demand. This tends to bring about challenges due to the competitive nature of securing housing in either the public or private residential market.\n\n\n\nThe task for this exercise aims to elucidate the dynamics of the private residential market and sub-markets in the 1st quarter of 2024 as a graphical editor of a media company. This will be done with a couple of data visualizations in which they will are assumed to be consumed by the general public. From the visualisation we aim to uncover:\n\nthe distributions of property prices alongside property type, and\nany plausible relationship between these factors with their planning regions"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the required libraries\nFor this exercise, beside tidyverse, five other R packages will be used. They are:\n\nggdist: a ggplot2 extension spacially designed for visualising distribution and uncertainty.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggthemes: an R package which provides some extra themes, geoms, and scales for ‘ggplot2’.\ngganimate: a ggplot extension for creating animated statistical graphs.\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\npatchwork: an R package for preparing composite figure created using ggplot2.\ncolorspace: an R package that provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\ntidyverse: a family of modern R packages specially designed to support data science, analysis and communication tasks including creating static statistical graphs.\n\nThe following code chunk below uses p_load() of pacman package to check that the required R packages have been installed. If they are, the libraries will be called into R.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               gganimate, ggrepel, ggiraph,\n               plotly, patchwork, colorspace,\n               tidyverse)\n\n\n\n2.2 Data Wrangling\nThe data for this exercise is the transaction data of Real Estate Information System (REALIS) which is obtained from Urban Redevelopment Authority (URA) which collects comprehensive and detailed property data under its REALIS section. The data range is dated from 1st January 2023 to 31st March 2024 in csv format and comes in 5 separate csv files for each corresponding quarter.\n\n2.2.1 Importing REALIS Data\nThe code chunk below imports the quarterly transaction data from REALIS by using the read_csv() function of readr package. Each dataset is labelled accordingly to their respective quarter(q)(1,2,3,4)_year(yy).\n\nq1_23 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nq2_23 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nq3_23 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nq4_23 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nq1_24 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nThe datasets are in a tibble dataframe with a total of 26,806 observations (rows) across 21 variables (columns). Each observation (row) corresponds to a property transaction in the private residential market, while the variables (columns) corresponds to information ranging from the transacted price, type of sale, property type for example.\nWith a substabtial large dataset, the individual datasets will be merged before we peform analysis. The rbind() function in the base package is used to combine the five tibble data frames into a single tibble data frame, private_property_data.\n\nprivate_property_data &lt;- rbind(q1_23, q2_23, q3_23, q4_23, q1_24)\n\nAn aggregate of all property types for units.\n\naggregate(private_property_data$`Number of Units`, by=list(Category=private_property_data$`Property Type`), FUN=sum)\n\n               Category     x\n1             Apartment 10785\n2           Condominium 10744\n3        Detached House   236\n4 Executive Condominium  3534\n5   Semi-Detached House   527\n6         Terrace House  1110\n\n\n\n\n2.2.2 Checking for duplicates\nGiven that dataset from URA is expected to be clean we will still proceed with some due diligence checks for duplicates. Using the duplicated() function we can observe if there are any duplicates in the tibble data frame.\n\nprivate_property_data[duplicated(private_property_data), ]\n\n# A tibble: 0 × 21\n# ℹ 21 variables: Project Name &lt;chr&gt;, Transacted Price ($) &lt;dbl&gt;,\n#   Area (SQFT) &lt;dbl&gt;, Unit Price ($ PSF) &lt;dbl&gt;, Sale Date &lt;chr&gt;,\n#   Address &lt;chr&gt;, Type of Sale &lt;chr&gt;, Type of Area &lt;chr&gt;, Area (SQM) &lt;dbl&gt;,\n#   Unit Price ($ PSM) &lt;dbl&gt;, Nett Price($) &lt;chr&gt;, Property Type &lt;chr&gt;,\n#   Number of Units &lt;dbl&gt;, Tenure &lt;chr&gt;, Completion Date &lt;chr&gt;,\n#   Purchaser Address Indicator &lt;chr&gt;, Postal Code &lt;chr&gt;,\n#   Postal District &lt;chr&gt;, Postal Sector &lt;chr&gt;, Planning Region &lt;chr&gt;, …\n\n\nResults confirm that there are no duplicated records found.\n\n\n2.2.3 Data Type Conversion and Transformation\n\nCreating New Columns (Month)\n\ndata_overall &lt;- private_property_data %&gt;%\n  mutate(Month = month(dmy(`Sale Date`), label = TRUE, abbr = FALSE),\n         Quarter = paste0(\"Q\", quarter(dmy(`Sale Date`)), \"-\", year(dmy(`Sale Date`))))\n\n\n\n\n2.2.4 Data Overview\n\nGlimpse of data\nThe glimpse() function will be utilised to have an overview of the dataset we have\n\nglimpse(data_overall)\n\nRows: 26,806\nColumns: 23\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n$ Month                         &lt;ord&gt; January, January, January, January, Janu…\n$ Quarter                       &lt;chr&gt; \"Q1-2023\", \"Q1-2023\", \"Q1-2023\", \"Q1-202…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-anaylsis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-anaylsis",
    "title": "Take-home Exercise 1",
    "section": "3 Exploratory Data Anaylsis",
    "text": "3 Exploratory Data Anaylsis\n\n3.1 Distribution of Private Residential Market (1st quarter of 2023 - 1st quarter of 2024)\n\nProperty distribution vs ($PSM)Property TypeProperty Type with geom_density()\n\n\n\n\nShow the code\nggplot(data=private_property_data, \n       aes(x= `Unit Price ($ PSM)`, \n           fill = `Property Type`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\nObservations: The overlaid histogram illustrates the unit price per square meter ($ PSM) distribution across different property types in Singapore’s private residential market. Apartments and condominiums are predominant, with a high frequency of lower-priced units, indicative of a strong market presence and potential affordability. The executive condominiums show fewer transactions but at a more moderate price range, suggesting a niche market. Detached houses, while less frequent, have transactions across a wider price range, signaling diverse offerings from affordable to luxury segments. Semi-detached and terrace houses exhibit a similar pattern, though terrace houses skew towards lower prices, possibly reflecting market preference for affordability.\n\n\n\ndata &lt;- data_overall\n\n# Check the first few entries of the Sale Date column to understand its format\nhead(data$`Sale Date`)\n\n[1] \"01 Jan 2023\" \"02 Jan 2023\" \"02 Jan 2023\" \"02 Jan 2023\" \"03 Jan 2023\"\n[6] \"03 Jan 2023\"\n\n# Assuming the format is day/month/year, convert it to a Date object\ndata &lt;- data %&gt;%\n  mutate(Sale_Date = dmy(`Sale Date`))\n\n# Check if the conversion was successful\nstr(data$Sale_Date)\n\n Date[1:26806], format: \"2023-01-01\" \"2023-01-02\" \"2023-01-02\" \"2023-01-02\" \"2023-01-03\" ...\n\n\n\ndata &lt;- data %&gt;%\n  mutate(\n    Month = month(Sale_Date, label = TRUE, abbr = TRUE), # Use abbr = TRUE for abbreviated month names\n    Quarter = paste0(\"Q\", quarter(Sale_Date)),\n    Year = year(Sale_Date),\n    Month_Quarter = paste(Month, Quarter, Year, sep = \"-\")\n  )\n\n\ncondo_data &lt;- data %&gt;%\n  filter(`Property Type` == \"Condominium\") %&gt;%\n  group_by(Month_Quarter) %&gt;%\n  summarize(Number_of_Units_Sold = n(), .groups = 'drop')\n\n\n# Check the contents of the summarized data\nhead(condo_data)\n\n# A tibble: 6 × 2\n  Month_Quarter Number_of_Units_Sold\n  &lt;chr&gt;                        &lt;int&gt;\n1 Apr-Q2-2023                   1047\n2 Aug-Q3-2023                    782\n3 Dec-Q4-2023                    558\n4 Feb-Q1-2023                    617\n5 Feb-Q1-2024                    564\n6 Jan-Q1-2023                    441\n\n# Plot without interactivity\nggplot(condo_data, aes(x = Month_Quarter, y = Number_of_Units_Sold)) +\n  geom_col() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))\n\n\n\n\n\n# Interactive plot with ggiraph\ninteractive_bar_chart &lt;- ggplot(condo_data, aes(x = Month_Quarter, y = Number_of_Units_Sold,\n                                                tooltip = paste(Month_Quarter, Number_of_Units_Sold))) +\n  geom_bar_interactive(stat = \"identity\") +\n  labs(title = \"Number of Condominium Units Sold\", x = \"Month and Quarter\", y = \"Number of Units Sold\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n# Convert the ggplot object to an interactive plot with girafe\ninteractive_plot &lt;- girafe(ggobj = interactive_bar_chart)\nprint(interactive_plot)\n\n\n\n\n\nShow the code\nggplot(data=private_property_data, \n       aes(x = `Property Type`, \n           colour = `Property Type`,)) +\n  geom_density()\n\n\n\n\n\nObservations: This density plot visualizes the concentration of different property types in the private residential market. Apartments show a high density at lower price points, indicating commonality and affordability. Detached houses exhibit a peak at a higher price range, suggesting exclusivity and higher valuation, while other property types display varied densities and price ranges.\n\n\n\n\n\n3.2 Relationship between Property Type and Unit Price ($ PSM) (1st quarter of 2024)\n\nggplot(q1_24, \n       aes(x = `Unit Price ($ PSM)`, \n           y = `Property Type`,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nObservations: Based on the plot, it can be observed that the various property types generally resemble a normal distribution. With reference from the quartile lines, the Unit Price Per Square Metre ($ PSM) for Apartments tend to be higher than that for the other remaining five property types; while the ($ PSM) of Executive Condominiums (ECs) tend to be lower than the other property types. This corresponds to the fact that ECs while built by private developers with the facilities of a Condominium are sold as public housing via the Housing Development Board (HDB) which receive some government subsidies. ECs are also catered to middle-income Singaporeans / Singapore Permanent Residents who do not qualify for a HDB flat due to the income ceilling cap but find private condominiums out of their budget.\n\n\n3.3 Comparing Planning Region and Unit Price ($ PSM) (1st quarter of 2024)\n\nggplot(q1_24,\n       aes(x = `Unit Price ($ PSM)`, \n           y = `Planning Region`, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\nObservations: The ridgeplot displays the distribution of unit prices per square meter ($ PSM) for private residential properties across different planning regions in Singapore. Each layer represents one planning region, with the Central Region at the bottom and the West Region at the top.\nThe peaks of each layer indicate the most common unit prices in each region. The Central Region shows a wide distribution with a significant peak, suggesting a large variation in prices, but with a concentration of properties around a particular price point which could be indicative of a prevalent market value for that region. The North East and East Regions display narrower distributions, signifying less variability in unit prices.\nThe tails of the distributions, marked in red and blue, denote the extreme values (outliers) where the probability of unit prices falls into the lowest or highest 2.5%. The presence of these outliers, especially in the Central Region, may suggest private properties or areas of unusually high or low value."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion-and-findings",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion-and-findings",
    "title": "Take-home Exercise 1",
    "section": "4 Conclusion and Findings",
    "text": "4 Conclusion and Findings\nFrom this data visualisation exercise, data wrangling and visualization of the data was carried out to explore the relationship of private residential market price with factors such as Planning Region and Property Type. The key findings are:\n\nApartments and condominiums are prevalent in the lower quartiles, suggesting affordability, while prices for detached houses are spread across all quartiles, indicating a wide price range from moderate to luxury units.\nUnit prices in the Central Region are generally higher and more varied, while prices in other regions are more clustered, indicating less diversity in the housing market value.\nA possible reflection of a higher demand and a wider range of property types in the Central Region, in contrast to more uniform residential areas in other regions.\n\nTo provide a conclusion with the findings, it is worthwhile to note that the exercise primarily focused on visuals and it would be highly beneficial to also use statistical tests in tandem to support all the findings. Furthermore, not the entire dataset was utilised and visualisation was mainly done up for the period of: 1st quarter of 2024. Some of these variables could also bring out more findings such as the Tenure of the unit and the Purchaser Address Indicator which could bring up additional insights for people to make more informed decisions when intending to purchase a property in the private residential market. All in all, this exercise has been a good practice of utilising ggplot fundamentals; but even more enhancements could be done such as using Animated Statistical Graphics to help the audiece connect better if this was a presentation to being insights on how trends have shifted for various properties using visual animation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "title": "Take-home Exercise 1",
    "section": "5 References",
    "text": "5 References\n\nURA releases flash estimate of 1st Quarter 2024 private residential property price index\nUnsold private housing stock on the rise ahead of ramp-up in new launches in 2024\nHDB resale prices rise 1.7%; private home prices up 1.5% in first quarter: Flash estimates\nURA Data Dictionary"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex08/shp/shp/Oceanus Geography.html",
    "href": "In-class_Ex/In-Class_Ex08/shp/shp/Oceanus Geography.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#loading-the-necessary-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#loading-the-necessary-r-packages",
    "title": "In-class Exercise 6b",
    "section": "6.1 Loading the necessary R packages",
    "text": "6.1 Loading the necessary R packages\n\npacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, ggforce,\n               skimr, tidytext, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#data-import",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#data-import",
    "title": "In-class Exercise 6b",
    "section": "6.2 Data import",
    "text": "6.2 Data import\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into the R environment\n\nmc3_data &lt;- fromJSON(\"data/MC3.json\")\n\nIn the code chunk below the class() function is used to confirm that the data is imported as a list\n\nclass(mc3_data)\n\n[1] \"list\"\n\n\nThe output is called mc3_data. It is a large list R object."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#extracing-edges",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#extracing-edges",
    "title": "In-class Exercise 6b",
    "section": "6.3 Extracing edges",
    "text": "6.3 Extracing edges\nThe code chunk below will be used to extract the links data.frame of mc3_data and saves it as a tibble data.frame called mc3_edges.\n\nmc3_edges &lt;-\n  as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;% #to avoid duplicate records; source,target,type if they are the same will be treated as duplicates and kept as one\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n    summarise(weights = n()) %&gt;% #weight - representation the number of linkages\n  filter(source!=target) %&gt;%\n  ungroup()\n\n\n\n\nMC3 Edges tibble data.frame\n\n\n\n\n\n\n\n\nIn the code chunk above\n\n\n\n\ndistinct() is used to ensure that there will be no duplicated records.\nmutate() and as.character() are used to convert the field data type from list to character.\ngroup_by() and summarise() are used to count the number of unique links\nthe filter(source!=target) is to ensure that no records are with similar source and target."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#extracing-nodes",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#extracing-nodes",
    "title": "In-class Exercise 6b",
    "section": "6.4 Extracing nodes",
    "text": "6.4 Extracing nodes\n\nmc3_nodes &lt;- as.tibble(mc3_data$nodes) %&gt;% #extracting from the nodes data.frame\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)), #as.numeric() since revenue should be processed as number to be able to do statistical analysis such as average\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\n\n\nMC3 Nodes tibble data.frame\n\n\n\n\n\n\n\n\nIn the code chunk above\n\n\n\n\nto convert revenue_omu from list data type to numeric data type, we would have to convert the values into character first by using as.character() followed by as.numeric() to convert the data into numeric data type.\nselect() is used to re-organise the order of the fields."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#initial-data-exploration",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#initial-data-exploration",
    "title": "In-class Exercise 6b",
    "section": "6.5 Initial data exploration",
    "text": "6.5 Initial data exploration"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#exploring-the-edges-data-frame",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#exploring-the-edges-data-frame",
    "title": "In-class Exercise 6b",
    "section": "Exploring the edges data frame",
    "text": "Exploring the edges data frame\nIn the code chunk below, [skim()])(https://docs.ropensci.org/skimr/reference/skim.html) of skimr package is used to display the summary statistics of mc3_edges tibble data.frame.\n\nskim(mc3_edges)\n\n\nData summary\n\n\nName\nmc3_edges\n\n\nNumber of rows\n24036\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsource\n0\n1\n6\n700\n0\n12856\n0\n\n\ntarget\n0\n1\n6\n28\n0\n21265\n0\n\n\ntype\n0\n1\n16\n16\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nweights\n0\n1\n1\n0\n1\n1\n1\n1\n1\n▁▁▇▁▁\n\n\n\n\n\nThe code function reveals that there is no missing value in the fields.\nIn the code chunk below, datatable() of DT package is used to display mc3_edges tibble data.frame as an interactive table on the html document.\n\nDT::datatable(mc3_edges)\n\n\n\n\n\n\n\nggplot(data = mc3_edges,\n       aes(x = type)) +\n  geom_bar() +\n  geom_text(aes(label = type), stat = \"count\", vjust = 5.5, colour = \"white\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#building-network-model-with-tidygraph",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#building-network-model-with-tidygraph",
    "title": "In-class Exercise 6b",
    "section": "6.6 Building network model with tidygraph",
    "text": "6.6 Building network model with tidygraph\n\n6.6.1 Preparing the network graph\n\n\n\n\n\n\nIn the code chunk below,\n\n\n\n\nsince some data were trimmed away, the nodes and edges might not sync together\nfrom the code below, we pull out the name/ create a new node from the edges to represent source and target\npurpose is to update the nodes based on the new edges data in the R environment\nfollowed by combining id1 & id2 and using left_join() to append them back to mc3_nodes\n\n\n\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            unmatched = 'drop')\n\n\n\n6.6.2 To construct the graph model\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality =  # field name\ncentrality_betweenness(),  # function - from tidygraph; nested function within the graph\n          closeness_centrality =\ncentrality_closeness())\n\n\nBuilding the graph to visualise\n\nbetweenness_centrality &gt;= 100000betweenness_centrality &gt;= 300000\n\n\n\nmc3_graph %&gt;%\n    filter(betweenness_centrality &gt;= 100000) %&gt;% #`filter()` function used pull out nodes with betweenness centrality greater than input value.\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range = c(1,10)) +\n  theme_graph()\n\n\n\n\n\n\nincreased betweenness_centrality from 100000 to 300000;\n\nmc3_graph %&gt;%\n    filter(betweenness_centrality &gt;= 300000) %&gt;% #`filter()` function is used to pull out nodes with betweenness centrality greater than 300000 to avoid the graph being too cluttered.\nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range = c(1,10)) +\n  theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html",
    "title": "In-class Exercise 5b",
    "section": "",
    "text": "5.3 Loading the necessary R packages\n\npacman::p_load(jsonlite, tidygraph,\n  ggraph, tidyverse, readtext,\n  quanteda, tidytext)\n\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json into R environment.\n\nmc1_data &lt;- fromJSON(\"data/MC1/mc1.json\")\n\n\nmc2_data &lt;- fromJSON(\"data/MC2/mc2.json\")\n\n\n\n\n\n\n\nNote\n\n\n\nWhen attempting to read MC3 data an error message shows up, indicating that there is a problem with the JSON data itself. More specifically an invalid character or format issue at the specified location. This issue is being addressed in Take-home exercise 3.\n\n\n\n\n\n5.4 Creating separate tibbles for nodes and edges\n\nmc2 &lt;- fromJSON(\"data/MC2/Oceanus Information/Oceanus Geography Nodes.json\")\n\nIf other packages used they might be in individual form. From “links” we can observe the time series changes.\n\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n    # Select can be used to reorder dataframe columns\n  select(id, type, name)\n\nmc2_edges &lt;- as_tibble(mc2_data$links) %&gt;%\n  # Move Source and Target to the front\n  select(source, target, type, key)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Loading packagesImporting data\n\n\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-the-packages-and-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-the-packages-and-data",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Loading packagesImporting data\n\n\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method",
    "title": "In-class Exercise 4",
    "section": "4.2 One-sample test: gghistostats() method",
    "text": "4.2 One-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build a visual of one-sample test on English scores.\nFrom the code chunks below there will be changes made to type from parametric to non-parametric (np)\n\nParametricNon Parametric (i)Non Parametric (ii)\n\n\n\n# for reproducibility\nset.seed(1234)\n\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"parametric\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.cruve.args = list(linewidth\n=2),\n  xlab = \"English scores\"\n)\n\n\n\n\nFrom the plot it can be observed that a t-test is carried out.\n\n\n\nset.seed(1234)\n\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.cruve.args = list(linewidth\n=2),\n  xlab = \"English scores\"\n)\n\n\n\n\nWhen type = \"np\" a Wilcoxon test is carried out - statistical test method automatically changed; results kept as a tubular dataframe keeping it as a line of text.\n\n\n\nset.seed(1234)\n\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.cruve.args = list(linewidth\n=2),\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\nNote\n\n\n\nChanging/saving code chunk above as an object to enable us to extract statistical test results using extract_stats() function\n\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 12\n  statistic  p.value method                    alternative effectsize       \n      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;            \n1     38743 3.43e-16 Wilcoxon signed rank test two.sided   r (rank biserial)\n  estimate conf.level conf.low conf.high conf.method n.obs expression\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt; &lt;list&gt;    \n1    0.528       0.95    0.430     0.613 normal        322 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method-varying-type-robust",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method-varying-type-robust",
    "title": "In-class Exercise 4",
    "section": "4.3 One-sample test: gghistostats() method (Varying type = robust)",
    "text": "4.3 One-sample test: gghistostats() method (Varying type = robust)\n\nset.seed(1234)\n\n\n  gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"robust\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.cruve.args = list(linewidth\n=2),\n  xlab = \"English scores\"\n)\n\n\n\n\nFor robust (for trimmed mean) outliers are trimmed and the bootstrapped method is used to calculate test statistics."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method-varying-type-bayes",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method-varying-type-bayes",
    "title": "In-class Exercise 4",
    "section": "4.4 One-sample test: gghistostats() method (Varying type = bayes)",
    "text": "4.4 One-sample test: gghistostats() method (Varying type = bayes)\n\nset.seed(1234)\n\n\n  gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.cruve.args = list(linewidth = 0.5),\n  xlab = \"English scores\"\n)\n\n\n\n\n\nby default normal.curve is FALSE - Argument can be toggled to TRUE - A logical value that decides whether to super-impose a normal curve.\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method-type-bayes-with-normal-curve-adjusting-linewidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-gghistostats-method-type-bayes-with-normal-curve-adjusting-linewidth",
    "title": "In-class Exercise 4",
    "section": "4.5 One-sample test: gghistostats() method (type = bayes with normal curve) & adjusting linewidth",
    "text": "4.5 One-sample test: gghistostats() method (type = bayes with normal curve) & adjusting linewidth\n\nLinewidth = 2Linewidth = 0.5\n\n\n\nset.seed(1234)\n\n\n  gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = TRUE, #Argument toggled to TRUE - Normal Distribution curve plotted\n  normal.curve.args = list(linewidth = 2), #Adjust linewidth as needed. (from 2 to 0.5)\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\nset.seed(1234)\n\n\n  gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  bin.args = list(colour = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = TRUE, #Argument toggled to TRUE - Normal Distribution curve plotted\n  normal.curve.args = list(linewidth = 0.5), #Adjust linewidth as needed. (from 2 to 0.5)\n  xlab = \"English scores\"\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-ggdotplotstats-for-distribution-about-labeled-numeric-variable",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#one-sample-test-ggdotplotstats-for-distribution-about-labeled-numeric-variable",
    "title": "In-class Exercise 4",
    "section": "4.6 One-sample test: ggdotplotstats() for distribution about labeled numeric variable",
    "text": "4.6 One-sample test: ggdotplotstats() for distribution about labeled numeric variable\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH,\n  y = CLASS,\n  title = \"\",\n  xlab = \"\"\n)\n\n\n\n\nPlot above indicates that on average students from 3D Class perform better than students from 3C Class."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-boxviolin-plot-using-ggwithinstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-boxviolin-plot-using-ggwithinstats",
    "title": "In-class Exercise 4",
    "section": "4.6 Creating Box/Violin plot using ggwithinstats()",
    "text": "4.6 Creating Box/Violin plot using ggwithinstats()\n\nexam_long &lt;- exam %&gt;%\n   pivot_longer(\n     cols = ENGLISH:SCIENCE,\n     names_to = \"SUBJECT\",\n     values_to = \"SCORES\") %&gt;%\n   filter(CLASS == \"3A\")\n\n\n\n\n\n\n\nLearning Point\n\n\n\nCurrent data is arranged columns wise by individual students, race, scores etc. To compare individual scores of students for ggstatsplot, the column will have to be combined. Hence we transform the data using _long the initial three columns ENGLISH, MATHS, SCIENCE are combined into one.\n\n\n\nggwithinstats(\n  data = filter(exam_long,\n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x    = SUBJECT,\n  y    = SCORES,\n  type = \"p\"\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-plot-using-ggscatterstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-plot-using-ggscatterstats",
    "title": "In-class Exercise 4",
    "section": "4.7 Creating plot using ggscatterstats()",
    "text": "4.7 Creating plot using ggscatterstats()\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90,\n)\n\n\n\n\n\nEnglish and Maths scores greater than 90 are incorporated as labels in test statistics.\nNote: To remove line if intending to show correlation -&gt; smooth.line.args - controls the line."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1, we have learnt some of the popular statistical graphics methods for visualising distributions which are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#learning-outcome",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1, we have learnt some of the popular statistical graphics methods for visualising distributions which are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "title": "In-class Exercise 2",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\n\n2.2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots,\nggdist, a ggplot2 extension spacially designed for visualising distribution and uncertainty,\ntidyverse, a family of R packages to meet the modern data science and visual communication needs,\nggthemes, a ggplot extension that provides the user additional themes, scales, and geoms for the ggplots package, and\ncolorspace, a R package providing a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\n\nThe code chunk below will be used load these R packages into R Studio environment.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n2.2.2 Data Import\nFor the purpose of this exercise, Exam_data.csv will be used.\nIn the code chunk below, read_csv() of readr package is used to import Exam_data.csv into R and saves it into a tibble data.frame.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-ridgeline-plot",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-ridgeline-plot",
    "title": "In-class Exercise 2",
    "section": "2.3 Visualising Distribution with Ridgeline Plot",
    "text": "2.3 Visualising Distribution with Ridgeline Plot\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\nRidgelines plot: English score by class\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise groups will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n2.3.1 Plotting ridgeline graph: ggridges method\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    colour = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English Grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n2.3.2 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English Grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n2.3.3 Mapping the probabilities directly onto colour\nBesides providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represents the empirical cumulative density function for the distribution of English score.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail Probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n2.3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile))\n       )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as by 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH,\n           y = CLASS,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(0.025, 0.975)\n  ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-raincloud-plot",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-with-raincloud-plot",
    "title": "In-class Exercise 2",
    "section": "2.4 Visualising Distribution with Raincloud Plot",
    "text": "2.4 Visualising Distribution with Raincloud Plot\nRaincloud Plot is a data visualisation technique that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n2.4.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which contains a half-density and a slab-interval.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\n\n\n2.4.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n2.4.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n2.4.4 Finishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = RACE,\n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#references",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#references",
    "title": "In-class Exercise 2",
    "section": "2.5 References",
    "text": "2.5 References\n\nKam, T.S (2024). 9 - Visualising Distribution\nIntroducing Ridgeline Plots (formerly Joyplots)\nClaus O. Wilke Fundamentals of Data Visualization especially Chapter 6, 7, 8, 9 and 10.\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\nDots + interval stats and geoms"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the following data visualisations by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcomes",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the following data visualisations by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "2 Getting Started",
    "text": "2 Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "3 Do It Yourself",
    "text": "3 Do It Yourself\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra,\n               readxl, knitr, data.table, tidyverse, CGPfunctions, ggHoriPlot)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "4 Plotting Calendar Heatmap",
    "text": "4 Plotting Calendar Heatmap\nIn this section, we will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\n\n\nCalendar Heatmap\n\n\nBy the end of this section, we will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n4.1 The Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n4.2 Importing the data\nFirst, we will use the code chunk below to import eventlog.csv file into R environment and call the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n4.3 Examining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n4.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1],\n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday',\n                  'Thursday', 'Wednesday',\n                  'Tuesday', 'Monday',\n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n4.5 Building the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;%\n  count(wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped,\n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"white\",\n            size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\nlabs(x = NULL,\n     y = NULL,\n     title = \"Attacks by weekday and time of the day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n Then we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n4.6 Building Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n4.7 Plotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, we are required to do the following:\n\ncount the number of attacks by country,\ncalculate the percent of attacks by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, it is required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n4.8 Plotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks,\n       aes(hour,\n           wkday,\n           fill = n)) +\n  geom_tile(color = \"white\",\n            size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL,\n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "5 Plotting Cycle Plot",
    "text": "5 Plotting Cycle Plot\nIn this section, we will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\ncycle plot\n\n\n\n5.1 Step 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and saves it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n5.2 Step 2: Deriving month and year fields\nNext, two new fields labelled month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`),\n                    levels = 1:12,\n                    labels = month.abb,\n                    ordered = TRUE)\nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n5.3 Step 3: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;%\n  select(`Vietnam`,\n         month,\n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n5.4 Step 4: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;%\n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n5.5 Step 5: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown below.\n\nggplot() +\n  geom_line(data = Vietnam,\n            aes(x=year,\n                y=`Vietnam`,\n                group=month),\n            colour = \"black\") +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5) +\n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "6 Plotting Slopegraph",
    "text": "6 Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting started, ensure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n6.1 Step 1: Data Import\nStart by importing the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n6.2 Step 2: Plotting the Slopegraph\nNext, the code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;%\n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Countries\",\n                SubTitle = \"1960-1980\",\n                Caption = \"Prepared by: Zi Jun\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#reference",
    "title": "Hands-on Exercise 7: Visualising and Analysing Time-oriented Data",
    "section": "7 Reference",
    "text": "7 Reference\n\nKam, T.S. (2023). Chapter 17 Visualising and Analysing Time-oriented Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcomes",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.2 Getting Started",
    "text": "5.2 Getting Started\n\n5.2.1 Installing and launching R packages\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph)\nDT,\nlubridate and hms.\n\nThe code chunk:\n\npacman::p_load(tidytext, tidyverse, widyr, wordcloud, ggwordcloud, textplot,\n  igraph, tidygraph, ggraph, DT, lubridate, hms)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-i",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.3 Importing Multiple Text Files from Multiple Folders (i)",
    "text": "5.3 Importing Multiple Text Files from Multiple Folders (i)\n\n5.3.1 Creating a folder list\n\nnews20 &lt;- \"data/20news/\"\n\n\n\n5.3.2 Define a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder,\n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file,\n                      read_lines)) %&gt;%\n    transmute(id = basename(file),\n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-ii",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-ii",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.4 Importing Multiple Text Files from Multiple Folders (ii)",
    "text": "5.4 Importing Multiple Text Files from Multiple Folders (ii)\n\n5.4.1 Reading in all the messages from the 20news folder\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.5 Initial EDA",
    "text": "5.5 Initial EDA\n\nnews20 &lt;- read_rds(\"data/rds/news20.rds\")\n\nThe figure below shows the frequency of messages by newsgroup.\n\n\n\n\n\nThe code chunk:\n\nraw_text &lt;- news20\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.6 Introducing tidytext",
    "text": "5.6 Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n\ntidytext workflow\n\n\n\n5.6.1 Removing header and automated email signatures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing fields such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n5.6.2 Removing lines with nested text representing quotes from other users.\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text,\n           \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text,\n                     \"^In article &lt;\")\n    )\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n5.6.3 Text Data Processing\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual words, we can also count words within newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n5.6.4 Visualising Words in newsgroups (i)\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 86) #adjust max words as needed\n\n\n\n\nA DT table can be used to complement the visual discovery.\n\nDT::datatable(words_by_newsgroup,\n  filter = 'top') %&gt;%\n  formatStyle(0, target = 'row',\n              lineHeight = '30%')\n\n\n\n\n\n\n\n\n5.6.5 Visualising Words in newsgroups (ii)\nThe wordcloud below is plotted by using ggwordcloud package.\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)\n\n\n\n\nThe code chunk used:\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.7 Basic Concept of TF-IDF",
    "text": "5.7 Basic Concept of TF-IDF\n\ntf–idf, in short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\n5.7.1 Computing tf-idf within newsgroups\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\n5.7.2 Visualising tf-idf as interactive table (i)\nTable below is an interactive table created by using datatable().\n\n\n\n\n\n\n\n\n\n5.7.3 Visualising tf-idf as interactive table (ii)\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\nDT::datatable(tf_idf, filter = 'top') %&gt;%\n  formatRound(columns = c('tf','idf',\n                          'tf_idf'),\n              digits = 3) %&gt;%\n  formatStyle(0,\n              target = 'row',\n              lineHeight = '25%')\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about customising DT’s table, visit this link.\n\n\n\n\n5.7.4 Visualising tf-idf within newsgroups\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroups.\n\n\n\n\n\nThe code chunk used to prepare the plot.\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf,\n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word,\n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf,\n         word,\n    fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup,\n             scales = \"free\") +\n  labs(x = \"tf-idf\",\n       y = NULL)\n\n\n\n5.7.5 Counting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\n\n\nPhilosophy behind the widyr package\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup,\n               word,\n               n,\n               sort = TRUE)\n\n\n\n5.7.6 Visualising correlation as a network\nNow, we can visualise the relationship between newsgroups in network graph as shown below.\n\n\n\n\n\nThe code chunk:\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation,\n                     width = correlation)) +\n  geom_node_point(size = 6,\n                  colour = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 colour = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n5.7.7 Bigram\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext.\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram,\n                text,\n                token = \"ngrams\",\n                n= 2)\n\n\nbigrams\n\n# A tibble: 28,827 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,817 more rows\n\n\n\n\n5.7.8 Counting bigrams\nThe code chunk is used to count and sort the bigram data frame in ascending order.\n\ncolnames(bigrams)\n\n[1] \"newsgroup\" \"id\"        \"bigram\"   \n\n\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\n\nbigrams_count\n\n# A tibble: 19,888 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,878 more rows\n\n\n\n\n5.7.9 Cleaning bigram\nThe code chunk below is used to separate the bigram into two words.\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"),\n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n\nbigrams_filtered\n\n# A tibble: 4,607 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,597 more rows\n\n\n\n\n5.7.10 Counting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;%\n  count(word1, word2, sort = TRUE)\n\n\n\n5.7.11 Create a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH 3aa4edd DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 3aa4edd (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\n5.7.12 Visualizing a network of bigrams with ggraph\nIn this code chunk below, ggraph package is used to plot the bigram.\n\n\n\n\n\nThe code chunk used to plot the network graph:\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name),\n                 vjust = 1,\n                 hjust = 1)\n\n\n\n5.7.13 Revised version\n\n\n\n\n\nThe code chunk used to plot the revised network graph.\n\nset.seed(1234)\n\nrevised &lt;- grid::arrow(type = \"closed\",\n                       length = unit(.15,\n                                     \"inches\"))\n\nggraph(bigram_graph,\n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n),\n                 show.legend = FALSE,\n                 arrow = revised,\n                 end_cap = circle(.06,\n                                  'inches')) +\n  geom_node_point(colour = \"lightblue\",\n                  size = 5) +\n  geom_node_text(aes(label = name),\n                 vjust = 1,\n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "title": "Hands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)",
    "section": "5.8 References",
    "text": "5.8 References\n\nKam, T.S. (2023). Visualising and Analysing Text Data\n\n\n29.8.0.1 widyr\n\nReference guide\n\nwidyr: Widen, process, and re-tidy a dataset\nUnited Nations Voting Correlations"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, we will gain hands-on experience in creating statistical graphics for visualising uncertainty. By the end of this chapter we will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#learning-outcomes",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, we will gain hands-on experience in creating statistical graphics for visualising uncertainty. By the end of this chapter we will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "11.2 Getting Started",
    "text": "11.2 Getting Started\n\n11.2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty,\nggridgesa ggplot2 extension specially designed for plotting ridgeline plots,\ncolorspace an R package which provides a broad toolbox for selecting individual colors or color palettes,\nunigeviz provides add-on functionality for ggplot2 to make it easier to visualize uncertainty\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse,\n               dplyr)\n\n\n\n11.2.2 Data Import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read.csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "11.3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "11.3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\nIn this section, we will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)\n    ) %&gt;%\n    mutate(se = sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe code chunkThe table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n11.3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE,\n        ymin=mean-se,\n        ymax=mean+se),\n    width=0.2,\n    colour=\"black\",\n    alpha=0.9,\n    size=0.5) +\n  geom_point(aes\n             (x=RACE,\n              y=mean),\n             stat=\"identity\",\n             colour=\"red\",\n             size=1.5,\n             alpha=1) +\n  ggtitle(\"Standard error of mean Maths score by Race\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n\n\n\n11.3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean),\n        ymin=mean-1.96*se,\n        ymax=mean+1.96*se),\n    width=0.2,\n    colour=\"black\",\n    alpha=0.9,\n    size=0.5) +\n  geom_point(aes\n             (x=RACE,\n              y=mean),\n             stat=\"identity\",\n             colour=\"red\",\n             size=1.5,\n             alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% Confidence Interval of mean Maths score by Race\")\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars are sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n\n\n\n11.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, we will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se,\n                     ymax=mean+2.58*se),\n                     width=0.2,\n                     colour=\"black\",\n                     alpha=0.9,\n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE,\n                     y=mean,\n                     text = paste(\"Race:\", `RACE`,\n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg.Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI: [\",\n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\",\n                     colour=\"red\",\n                     size = 1.5,\n                     alpha=1) +\n                   xlab(\"Race\") +\n                   ylab(\"Average Scores\") +\n                   theme_minimal() +\n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust = 1)) +\n                   ggtitle(\"99% Confidence Interval of average /&lt;br&gt;Maths scores by Race\")),\n                tooltip = \"text\"),\n       DT::datatable(shared_df,\n                     rownames = FALSE,\n                     class = \"compact\",\n                     width = \"100%\",\n                     options = list(pageLength = 10,\n                                    scrollX = T),\n                     colnames = c(\"No. of pupils\",\n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns = c('mean', 'sd', 'se'),\n                     digits = 2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "11.4 Visualising Uncertainty: ggdist package",
    "text": "11.4 Visualising Uncertainty: ggdist package\n\nggdist is a R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n11.4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below,stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE,\n             y= MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising Confidence Intervals of mean Maths score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam%&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising Confidence Intervals of Median Math score\",\n    subtitle = \"Median Point + Multiple-interval plot\"\n  )\n\n\n\n\n\n\n11.4.2 Visualizing the uncertainty of point estimates: ggdist methods\n\n\n\n\n\n\nTry it yourself\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nThe plot (95 % CI)The plot (99% CI)The code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(.width = 0.95) +\n  labs(\n    title = \"Visualising 95% confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(.width = 0.99) +\n  labs(\n    title = \"Visualising 99% confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1.0",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1.0",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "11.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs) 1.0",
    "text": "11.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs) 1.0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-2.0",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-2.0",
    "title": "Hands-on Exercise 4b: Visualising Uncertainty",
    "section": "11.6 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs) 2.0",
    "text": "11.6 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs) 2.0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make a deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nAnimation Concept\n\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#overview",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make a deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nAnimation Concept\n\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, an animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#getting-started",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\nFirstly, we will write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, a ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n4.2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nThe code chunk below imports the Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0.\n\n\n\nR Studio warning message\n\n\nIn view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet = \"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_color_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}',\n       x = '% Aged',\n       y = '% Young')\n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young,\n                      size = Population,\n                      colour = Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_color_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}',\n       x = '% Aged',\n       y = '% Young') +\n  transition_time(Year) +\n  ease_aes('linear')\n\nThe animated bubble chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, we will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop,\n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\nNote\n\n\n\n##Things to learn from the code chunk above - Appropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg. - ggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop,\n             aes(x = Old,\n                 y = Young,\n                 size = Population,\n                 colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged',\n       y = '% Young') +\n  theme(legend.position = 'none')\n\nggplotly(gg)\n\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, we will explore how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old,\n          y = ~Young,\n          size = ~Population,\n          color = ~Continent,\n          sizes = c(2,100),\n          frame = ~Year,\n          text = ~Country,\n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03b/Hands-on_Ex03b.html#references",
    "title": "Hands-on Exercise 3b: Programming Animated Statistical Graphics with R",
    "section": "4.5 References",
    "text": "4.5 References\n\nKam, T.S. (2024). Programming Animated Statistical Graphics with R\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "For this exercise the aim is to introduce several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of the exercise we will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figures by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figures by combining ggplot2 graphs by using patchwork package\n\n\n\n\n\n\nFor this exercise, besides tidyverse, four other R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2\npatchwork: an R package for preparing composite figure created using ggplot2\n\nThe code chunk below will be used to check if these packages have been installed and also load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork,\n               ggthemes, hrbrthemes,\n               tidyverse)\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(method = lm,\n              linewidth = 0.5) +\n  geom_label(aes(label = ID),\n             hjust = .5,\n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores verus Maths scores for Primary 3\")\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples shown at the bottom.\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label_repel(aes(label=ID),\n                   fontface=\"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for Priamy 3\")\n\n\n\n\n\n\n\n\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nThe plotThe codePlot with theme_dark()\n\n\n\n\n\n\n\nTheme used: theme_gray()\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distirbution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nYou may refer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size=18,\n              base_size=15,\n              grid=\"Y\")\n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "For this exercise the aim is to introduce several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of the exercise we will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figures by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figures by combining ggplot2 graphs by using patchwork package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "For this exercise, besides tidyverse, four other R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2\npatchwork: an R package for preparing composite figure created using ggplot2\n\nThe code chunk below will be used to check if these packages have been installed and also load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork,\n               ggthemes, hrbrthemes,\n               tidyverse)\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "One of the challenge in plotting statistical graph is annotation, especially with large number of data points\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(method = lm,\n              linewidth = 0.5) +\n  geom_label(aes(label = ID),\n             hjust = .5,\n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores verus Maths scores for Primary 3\")\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples shown at the bottom.\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label_repel(aes(label=ID),\n                   fontface=\"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores vs Maths scores for Priamy 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "ggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nThe plotThe codePlot with theme_dark()\n\n\n\n\n\n\n\nTheme used: theme_gray()\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distirbution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nYou may refer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size=18,\n              base_size=15,\n              grid=\"Y\")\n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-figure-with-insert",
    "title": "Hands-on Exercise 2",
    "section": "2.5.5 Creating figure with insert",
    "text": "2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2,\n                   left=0.02,\n                   bottom=0.7,\n                   right=0.5,\n                   top=1)\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#references",
    "title": "Hands-on Exercise 2",
    "section": "2.6 References",
    "text": "2.6 References\n\nKam, T.S. (2024). Beyond ggplot2 Fundamentals\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi I’m Zi Jun, a dedicated professional pursuing a Master’s of IT in Business (Analytics Track) at Singapore Management University. With a bachelor’s in Business and a passion for data analytics, I am currently focusing on leveraging Python and R programming to uncover insights and solve complex problems. Join me as I explore the world of visual analytics, turning data into compelling stories.\nYou may reach me via email or we can connect with each other on LinkedIn!\n\n\nSingapore Management University Masters of IT in Business (Analytics) | January 2024 - April 2025\nSingapore University of Social Sciences Bachelor of Science (BSc) in Business | July 2023\n\n\n\nEM Services | Executive (Operations) | September 2022 - February 2024\nAlign Technology | Consumer Experience Consultant | May 2021 - July 2022\nThank you for dropping by!"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "Singapore Management University Masters of IT in Business (Analytics) | January 2024 - April 2025\nSingapore University of Social Sciences Bachelor of Science (BSc) in Business | July 2023"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "",
    "text": "EM Services | Executive (Operations) | September 2022 - February 2024\nAlign Technology | Consumer Experience Consultant | May 2021 - July 2022"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this chapter, we will learn the basic principles and essential components of ggplot2. Also, we will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics.\nBy then end of this chapter we will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "2.1 Installing and launching R Packages",
    "text": "2.1 Installing and launching R Packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "2.2 Importing the data",
    "text": "2.2 Importing the data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "A Layered Grammar of Graphics",
    "text": "A Layered Grammar of Graphics\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\n\n\n\nThemes: modify all non-data components of a plot, such as main title, sub-title, y-axis title, or legend background.\nCoordinate systems: define the plane on which data are mapped on the graphic.\nStatistics: statistical transformations that summarise data (e.g. mean, confidence intervals).\nFacets: split the data into subsets to create multiple variations of the same graph (panelling, multiple plots).\nGeometrics: The visual elements used for our data, such as point, bar, or line.\nAesthetics: take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nData: The dataset being plotted."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "4.1 Essential Grammatical Elements in ggplot2: data",
    "text": "4.1 Essential Grammatical Elements in ggplot2: data\nLet us begin by calling the ggplot() function using this code chunk.\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "4.2 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "4.2 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nAesthetic mappings cna take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (each geom layer can also have its own aes specification)\nThe code chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data,\n        aes(x = MATHS))\n\n\n\n\nNote that upon using the code chunk, ggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1",
    "section": "4.3 Essential Grammatical Elements in ggplot2: geom",
    "text": "4.3 Essential Grammatical Elements in ggplot2: geom\n\nGeometric objects are the actual marks we put on a plot. Examples include:\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes geom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n4.3.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart byy using the geom_bar() function.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n4.3.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDo note that the Y Scale might not be useful and in fact misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below will perform the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)\n\n\n\n\n\n\n4.3.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo note that the default bin is at 30.\n\n\n\n\n4.3.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data,\n       aes(x= MATHS)) +\n  geom_histogram(bins=20,     \n                 color=\"black\",\n                 fill=\"light blue\")\n\n\n\n\n\n\n4.3.5 Modifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n4.3.6 Geometric Objects: geom_density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram. This makes it an useful alternative to the histogram for continuous data that comes from a smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data,\n       aes(x = MATHS)) +\n  geom_density()\n\n\n\n\nUsing colour/fill arguments in aes(), the following can be plotted\n\nggplot(data=exam_data,\n       aes(x = MATHS,\n           colour = GENDER)) +\n  geom_density(linewidth = 1.5)\n\n\n\n\nNote that linewidth argument was utilised within the geom_density() function to increase thickness of line.\n\n\n4.3.7 Geometric Objects: geom_boxplot()\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x= GENDER)) +\n  geom_boxplot()\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe following code chunk uses notched plot instead of boxplot to plot the distribution of Maths scores by gender.\n\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n4.3.8 Geometric Objects: geom_violin()\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions.\nWhen ordinary density curves are plotted, there tends to be difficulty in comparinf multiple distributions since the lines usually interfere with one another.\nWith the violin plot, comparing several distributions will be easier since they are beside each other.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n4.3.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplots.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data,\n       aes(x= MATHS,\n           y=ENGLISH)) +\n  geom_point()\n\n\n\n\n\n\n4.3.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data,\n       aes(y = MATHS,\n           x= GENDER)) +\n  geom_boxplot() +     \n  geom_point(position=\"jitter\",\n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "4.4 Essential Grammatical Elements in ggplot2: stat",
    "text": "4.4 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n4.4.1 Working with stat()\nThe boxplots shown below are incomplete because the positions of the means are not shown.\n\nggplot(data=exam_data,\n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n4.4.2 Working with stat - the stat_summary() method\nUsing the code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n4.4.3 Working with stat - the geom() method\nThe code chunk below also adds mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data,\n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",\n             fun=\"mean\", \n             colour =\"red\",\n             size=4)\n\n\n\n\n\n\n4.4.4 Addition of best fit curve on a scatterplot\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nNote that the default method used is loess.\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data,\n       aes(x= MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "4.5 Essential Grammatical Elements in ggplot2: Facets",
    "text": "4.5 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data.\nThis acts as an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n4.5.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n4.5.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables.\nIt is most useful when we have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data,\n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "4.6 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "4.6 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps.\n\n\n4.6.1 Working with Coordinates\nBy the default, the bar chart of ggplot2 is in vertical form as ashown below.\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n4.6.2 Changing the y - and x-axis range\nThe scatterplot at the bottom is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nHence, code chunk below fixes both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "4.7 Essential Grammatical Elements in ggplot2: Themes",
    "text": "4.7 Essential Grammatical Elements in ggplot2: Themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n4.7.1 Working with theme\nThe code chunk below plots a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart is plotted using the theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart is plotted using the theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#references",
    "title": "Hands-on Exercise 1",
    "section": "4.8 References",
    "text": "4.8 References\n\nKam, T. S. (2024). A Layered Grammar of Graphics: ggplot2 methods.\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "For this hands-on exercise we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#learning-outcomes",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "For this hands-on exercise we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#getting-started",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, we will write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nploty, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication tasks including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman:: p_load(ggiraph,plotly,\n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#importing-data",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, we will import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file in R and saves it as a tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf used within a Shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for a more detailed explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip=ID),\n    stackgroups=TRUE,\n    binwidth=1,\n    method=\"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\ngirafe(\n  ggobj=p,\n  width_svg=6,\n  height_svg=6*0.618\n)\n\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on a data point of interest, the student’s ID will be displayed.\n\n\n3.4.2 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\n\nShow the code\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n3.4.3 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\n\nShow the code\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)\n\n\n\n\n\n\nNotice that the background colour of the tooltip is white and the font colour is black and bold.\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactivity",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.5 Interactivity",
    "text": "3.5 Interactivity\n\nDisplaying (Student ID)Displaying (Student ID and Class)Customising Tooltip style\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\n\nShow the code\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip=ID),\n    stackgroups=TRUE,\n    binwidth=1,\n    method=\"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\ngirafe(\n  ggobj=p,\n  width_svg=6,\n  height_svg=6*0.618\n)\n\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\n\nShow the code\nexam_data$tooltip &lt;- c(paste0(\n  \"Name= \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS))\n\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups=TRUE,\n    binwidth=1,\n    method=\"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\n\ngirafe(\n  ggobj=p,\n  width_svg=8,\n  height_svg=8*0.618\n)\n\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by adding css declarations.\n\n\nShow the code\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip=ID),\n    stackgroups=TRUE,\n    binwidth=1,\n    method=\"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)\n\n\n\n\n\n\nNotice that the background color of the tooltip is now white and the font color is black and bold.\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\n3.5.1 Interactivity - Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confidence interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = 0.1) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accurcy = aaccuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data,\n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))),\n    fun.data = \"mean_se\",\n    geom = GeomInteractiveCol,\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, linewidth = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n3.5.2 Hover effect with data_id aesthetic\nThe code chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                    breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nInteractivity: Elements associated with a data_id(i.e CLASS) will be highlighted upon hovering the mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.5.3 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(\n    opts_hover(css = \"fill: #202020;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n)\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation requests are encoded directly.\n\n\n3.5.4 Combining tooltip and hover effect\nThere are times that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = CLASS,\n        data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(\n    opts_hover(css = \"fill: #202020;\"),\n    opts_hover_inv(css = \"opacity:0.2;\")\n  )\n)\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n3.5.5 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618)\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n3.5.6 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data,\n             aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data,\n             aes(x = ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2),\n       width_svg =  6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.6 Interactive Data Visualisation - plotly methods!",
    "text": "3.6 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library creates interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\n\n\nOverview of the conversion and rendering process\n\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.6.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example of a basic interactive plot created by using plot_ly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH)\n\n\n\n\n\n\n3.6.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\n\n3.6.3 Creating an interactive scatter plot: ggplotly() method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n3.6.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d,\n             aes(x = MATHS,\n                 y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d,\n             aes(x = MATHS,\n                 y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nYou may Visit this link to learn more about crosstalk."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.7 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.7 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.7.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\nDT::datatable(exam_data, class = \"compact\")\n\n\n\n\n\n\n\n\n3.7.2 Linked brushing: crosstalk method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np &lt;- ggplot(d,\n            aes(ENGLISH,\n                MATHS)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg,\n                  DT::datatable(d),\n                  widths = 5)\n\nThings to learn from the code chunk:\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a/Hands-on_Ex03a.html#reference",
    "title": "Hands-on Exercise 3a: Programming Interactive Data Visualisation with R",
    "section": "3.8 Reference",
    "text": "3.8 Reference\n\n3.8.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to plot interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.8.2 ploty for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link.\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by a senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "",
    "text": "For this hands-on exercise, it will allow us to gain hands-on experience using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#learning-outcomes",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#learning-outcomes",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "",
    "text": "For this hands-on exercise, it will allow us to gain hands-on experience using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "10.2 Visual Statistical Analysis with ggstatsplot",
    "text": "10.2 Visual Statistical Analysis with ggstatsplot\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\nStatistical Reporting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "10.3 Getting Started",
    "text": "10.3 Getting Started\n\n10.3.1 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n10.3.2 Importing Data\n\n\n\n\n\n\nTry-it-yourself\n\n\n\nImport Exam.csv data by using appropriate tidyverse package.\n\n\n\n\n\n\n\n\nCode chunk\n\n\n\nThe code chunk below uses read_csv() of readr package to import Exam_data.csv data file into R and saves it as a tibble data frame called exam_data.\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#visualising-models",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "10.4 Visualising Models",
    "text": "10.4 Visualising Models"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4a: Visual Statistical Analysis",
    "section": "10.5 Installing and loading the required libraries",
    "text": "10.5 Installing and loading the required libraries"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#overview",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "12.2 Installing and Launching R Packages",
    "text": "12.2 Installing and Launching R Packages\nIn this exercise, five R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(readr, tidyverse, FunnelPlotR, plotly, knitr, ggplot2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#importing-data",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "12.3 Importing Data",
    "text": "12.3 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e.kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and saves it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\nThe code chunk below will be used to display covid19 tibble data frame in an html table format.\n\n\nCode chunk\nkable(head(covid19))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "12.4 FunnelPlotR methods",
    "text": "12.4 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n12.4.1 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\nfunnel_plot( numerator = covid19$Positive, denominator = covid19$Death, group = covid19$Sub-district)\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above:\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n12.4.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05)\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above: . + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis.\n\n\n12.4.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot with titles and labels added.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  xrange = c(0, 6500),\n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\",\n  x_label = \"Cumulative COVID-19 Positive Cases\",\n  y_label = \"Cumulative Fatality Rate\"\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above:\n\nlabel = NA argument is used to remove the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "12.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "12.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, we will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance the working experience of ggplot2 to customise speciallised data visualisations like funnel plot.\n\n12.5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n12.5.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n12.5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label = `Sub-district`),\n             alpha = 0.4) +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ll95),\n            size = 0.4,\n            colour = \"grey40\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ul95),\n            size = 0.4,\n            colour = \"grey40\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ll999),\n            size = 0.4,\n            colour = \"grey40\") +\n  geom_line(data = dfCI,\n            aes(x = number.seq,\n                y = number.ul999),\n            size = 0.4,\n            colour = \"grey40\") +\n  geom_hline(data = dfCI,\n             aes(yintercept = fit.mean),\n             size = 0.4,\n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") +\n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") +\n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") +\n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size = 12),\n        legend.position = c(0.91, 0.85),\n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n12.5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\",\n              \"x\",\n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c/Hands-on_Ex04c.html#references",
    "title": "Hands-on Exercise 4c: Funnel Plots for Fair Comparisons",
    "section": "12.6 References",
    "text": "12.6 References\n\n[]\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse, lubridate, clock and graphlayouts will be installed and launched too.\n\nR Packages\n\n\n\n\n\n\nPackages\nDescription\n\n\n\n\nigraph\nFor Network Analysis and Visualization\n\n\ntidygraph\nA Tidy API for Graph Manipulation\n\n\nggraph\nan extension of the ggplot2 API tailored to graph visualizations and provides the same flexible approach to building up plots layer by layer\n\n\nvisNetwork\na R package for network visualization, using vis.js javascript library (https://visjs.org)\n\n\ntidyverse\na family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs\n\n\nlubridate\nan R package specially designed to handle and wrangle time data\n\n\nclock\npackage providing a comprehensive set of tools for working with date-times\n\n\ngraphlayouts\npackage implements some graph layout algorithms that are not available in igraph or other packages\n\n\n\nThe code chunk:\n\n\nCode\npacman::p_load(igraph, tidygraph, ggraph,\n               visNetwork, tidyverse, lubridate,\n               clock, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "3 The Data",
    "text": "3 The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n3.1 The edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondences between 55 employees.\n\n\n\n\nGAStech-email_edges data preview\n\n\n\n\n3.2 The nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\nGAStech_email_nodes data preview\n\n\n\n\n3.3 Importing network data from files\nIn this step, we will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nCode\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n3.5 Wrangling time\nThe code chunk below will be used to perform the changes.\n\n\nCode\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nLearning points from the code chunk above:\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keeps the days spelt in full, i.e.Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n3.7 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individuals by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n3.8 Reviewing the revised edges file\nThe table below shows the data structure of the reformatted GAStech_edges data frame\n\n\nCode\nglimpse(GAStech_edges_aggregated)\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "4 Creating network objects using tidygraph",
    "text": "4 Creating network objects using tidygraph\nIn this section, we will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, it is advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n4.2 The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above image, the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\n4.3 Using tbl_graph() to build tidygraph data model\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, it is recommended to review to reference guide of tbl_graph()\n\n\nCode\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated,\n                           directed = TRUE)\n\n\n\n\n4.4 Reviewing the output tidygraph’s graph object (i)\n\n\nCode\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n4.5 Reviewing the output tidygraph’s graph object (ii)\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nCode\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "5 Plotting Static Network Graphs with ggraph package",
    "text": "5 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graphs, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspects of graphs, please refer to their respective vignettes provided.\n\n5.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guides at least once.\n\n\nCode\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n5.2 Changing the default network graph theme\nIn this section, we will use theme_graph() to remove the x and y axes. Before we get started, it is advisable to read it’s reference guide in the earlier sub-section at least once.\n\n\nCode\ng &lt;- ggraph(GAStech_graph) +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n5.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the colouring of the plot.\n\n\nCode\ng &lt;- ggraph(GAStech_graph) +\n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n5.4 Working with ggraph’s layouts\nggraph supports many layouts for standard usage, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n \n\n\n5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nCode\ng &lt;- ggraph(GAStech_graph,\n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n5.6 Modifying network nodes\nIn this section, we will colour each node by referring to their respective departments.\n\n\nCode\ng &lt;- ggraph(GAStech_graph,\n            layout = \"nicely\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department,\n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chunks above colour and size are used.\n\n\n\n\n\n5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nCode\ng &lt;- ggraph(GAStech_graph,\n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department),\n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportion to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "6 Creating facet graphs",
    "text": "6 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaningful way by spreading nodes and edges out based on their attributes. In this section, we will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n6.1 Working with facet_edges() (i)\nIn the code chunk below,facet_edges() is used. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nCode\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph,\n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department),\n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n6.2 Working with facet_edges() (ii)\nThe code chunk below uses theme() to change the position of the legend.\n\n\nCode\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph,\n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department),\n                  size = 2) +\n  theme(legend.position = 'bottom')\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n6.3 A framed facet graph\nThe code chunk below adds a frame to each graph.\n\n\nCode\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",\n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n6.4 Working with facet_nodes()\nIn the code chunk below, facet_nodes() is used. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nCode\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "7 Network Metrics Analysis",
    "text": "7 Network Metrics Analysis\n\n7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices used to describe the relative importance of how actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Learners are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nCode\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n                  size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\n7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to pre-compute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nCode\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nCode\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "8 Building Interactive Network Graph with visNetwork",
    "text": "8 Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nWe can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nWe can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\")\n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below renames the Department field to “group”.\n\n\nCode\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department)\n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field. visLegend() is also used to provide the legned for the graph\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n8.5 Working with visual attributes - Edges\nIn the code ran below visEdges() is used to symbolise the edges.\n\nThe argument arrows is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#reference",
    "title": "Hands-on Exercise 6: Network Data Visualisation and Analysis",
    "section": "9 Reference",
    "text": "9 Reference\n\nKam, T.S. (2023). Chapter 27: Modelling, Visualising and Analysing Network Data with R"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load the tidyverse family of packages.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load the tidyverse family of packages.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#comparison-of-functions-for-reading-csv-files.",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#comparison-of-functions-for-reading-csv-files.",
    "title": "In-class Exercise 1",
    "section": "Comparison of functions for reading csv files.",
    "text": "Comparison of functions for reading csv files.\n\nread_csv()read.csv()\n\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nclass(realis)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nFor the read_csv() function it reads the file into a tibble object\n\n\n\nrealis.csv &lt;- read.csv(\"data/realis2019.csv\")\n\n\nclass(realis.csv)\n\n[1] \"data.frame\"\n\n\nFor the read.csv() it reads the file into a data frame object.Any special characters or spaces in between will be replaced with ” . ”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#ggplot---histogram",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#ggplot---histogram",
    "title": "In-class Exercise 1",
    "section": "ggplot - Histogram",
    "text": "ggplot - Histogram\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Superstore Dashboard\nExam Data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#links-to-tableau-visualisations",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#links-to-tableau-visualisations",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Superstore Dashboard\nExam Data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html",
    "title": "In-class Exercise 5a",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext,\n               quanteda, tidytext)\n\n\n\n\n\ndata_folder &lt;- \"data/MC1/articles\"\n\n\n\n\n\ntext_data &lt;- readtext(paste0(\"data/MC1/articles\",\n                \"/*\"))\n\nOR the below code chunk can be utilised as well\n\ntext_data &lt;- readtext(\"data/MC1/articles\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#an-exploration-of-vast-challenge-2024---mc1-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#an-exploration-of-vast-challenge-2024---mc1-data",
    "title": "In-class Exercise 5a",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext,\n               quanteda, tidytext)\n\n\n\n\n\ndata_folder &lt;- \"data/MC1/articles\"\n\n\n\n\n\ntext_data &lt;- readtext(paste0(\"data/MC1/articles\",\n                \"/*\"))\n\nOR the below code chunk can be utilised as well\n\ntext_data &lt;- readtext(\"data/MC1/articles\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#basic-tokenisation",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#basic-tokenisation",
    "title": "In-class Exercise 5a",
    "section": "5.2 Basic tokenisation",
    "text": "5.2 Basic tokenisation\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%  #reading the text data\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word) #remove stop words\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\nObservations- Most common words are: fishing, sustainable and company\n\n5.2.1 Creating a table to observe word counts\n\ntemp_table &lt;- usenet_words %&gt;%\n  count(word, sort = TRUE)\n\n\n\n5.2.2 Using corpus to read text data\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\nTo separate the data; into 2 columns X & Y.\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\", \"Y\"),\n                       too_few = \"align_end\")\n\nSome text are starting with “1” hence the split does not occur"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html",
    "title": "In-class Exercise 6a",
    "section": "",
    "text": "corporaexplorer can be used to explore not only chronological text collections with documen date as main organising principle, but any collection of texts. The example used here is the King James Bible."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#exploring-the-king-james-bible",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#exploring-the-king-james-bible",
    "title": "In-class Exercise 6a",
    "section": "",
    "text": "corporaexplorer can be used to explore not only chronological text collections with documen date as main organising principle, but any collection of texts. The example used here is the King James Bible."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#loading-the-necessary-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#loading-the-necessary-r-packages",
    "title": "In-class Exercise 6a",
    "section": "6.1 Loading the necessary R packages",
    "text": "6.1 Loading the necessary R packages\n\npacman::p_load(tidyverse, readtext, corporaexplorer,\n               quanteda, stringi, stringr, rvest, tidytext)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#loading-the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#loading-the-data",
    "title": "In-class Exercise 6a",
    "section": "6.2 Loading the data",
    "text": "6.2 Loading the data\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\nthe data is a text file; a plain text from a website"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#tidying-up-the-text",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#tidying-up-the-text",
    "title": "In-class Exercise 6a",
    "section": "6.3 Tidying up the text",
    "text": "6.3 Tidying up the text\n\n6.3.1 Pre-processing the text\n\nCollapsing into one string.\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n\nIdentifying the beginning and end of the Bible / stripping PJ metadata\n\n\n\n\n\n\nNote\n\n\n\ntechnique borrowed from - https://quanteda.io/articles/pkgdown/replication/digital-humanities.html.\n\n\n\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n\nIn the file, every book in the bible is preceded by five newlines,\nwhich we use to split our string into a vector where each element is a book.\n\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40] # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n\nBecause of the structure of the text in the file:\nReplacing double or more newlines with two newlines, and a single newline with space.\n\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n\nIdentifying new chapters within each book and split the text into chapters.\nE.g. (The first characters in chapter 2 will e.g. be 2:1)\n\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n\nRemoving the chapter headings from the text (we want them as metadata).\n\nchapters &lt;- lapply(chapters, function(x) x[-1])"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#metadata",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#metadata",
    "title": "In-class Exercise 6a",
    "section": "6.4 Metadata",
    "text": "6.4 Metadata\nWe are not quite happy with the long book titles in the King James Bible, so we retrieve shorter versions from esv.org which will take up less space in the corpus map plot.\n\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#creating-data-frame-with-text-and-metadata",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#creating-data-frame-with-text-and-metadata",
    "title": "In-class Exercise 6a",
    "section": "6.5 Creating data frame with text and metadata",
    "text": "6.5 Creating data frame with text and metadata\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#using-corporaexplorer",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#using-corporaexplorer",
    "title": "In-class Exercise 6a",
    "section": "6.6 Using corporaexplorer",
    "text": "6.6 Using corporaexplorer\n\nAs this is a corpus which is not organised by date,\n\n\n\n\n\n\nNote\n\n\n\n\nwe set date_based_corpus to FALSE.\nBecause we want to organise our exploration around the books in the Bible,\nwe pass \"Book\" to the grouping_variable argument.\nWe specify which metadata columns we want to be displayed in the: “Document information” tab, using the columns_doc_info argument.\n\n\n\n\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info =\nc(\"Testament\", \"Book\"))  #that helps group together the one that we are extracting\n# a unique object class is created that R Studio can read\n\n\nclass(KJB) #to check that the object class is created properly since it is specially catered to corpora explorer\n\n[1] \"corporaexplorerobject\"\n\n\nFrom the class function it shows that the object class is a “corporaexplorerobject” to show that we are on the right track.\n\nexplore(KJB) #pull up the shiny app\n\nShiny applications not supported in static R Markdown documents\n\n\nSnapshots of corpus exploration tool\n   \n\n\n\n\n\n\nSteps/processes for this exercise\n\n\n\n\nPreparing and then tidying up the data (working with text data instead of usual numerical data)\nConstructing the data frame\nExploration of the data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#references",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#references",
    "title": "In-class Exercise 6a",
    "section": "6.7 References",
    "text": "6.7 References\nExploring the King James Bible"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-Class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7",
    "section": "",
    "text": "Calendar Heatmap\nVisitors arrival by Month/Year"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex07/In-class_Ex07.html#links-to-tableau-visualisations",
    "href": "In-class_Ex/In-Class_Ex07/In-class_Ex07.html#links-to-tableau-visualisations",
    "title": "In-class Exercise 7",
    "section": "",
    "text": "Calendar Heatmap\nVisitors arrival by Month/Year"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Visual Analytics and Applications Homepage",
    "section": "",
    "text": "Hey there! Welcome to my Visual Analytics and Applications page which documents and showcase my coursework and projects for this module.\nFrom here, you can see how I utilise various data analytics methods to interact with data and explore relationships where I try to “detect the expected and discover the unexpected”.\nA Feature of My Latest Works:\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1\n\n\n\n\n\n\nHo Zi Jun\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 09\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9a: Creating Ternary Plot with R\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9b: Visual Correlation Analysis\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 9e: Treemap Visualisation with R\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 3: Network Data Visualisation and Analysis\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 8\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8a: Choropleth Mapping with R\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8b: Visualising Geospatial Point Data\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 8c: Analytical Mapping\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 7\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7: Visualising and Analysing Time-oriented Data\n\n\n\n\n\n\nHo Zi Jun\n\n\nJun 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 6a\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 6b\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6: Network Data Visualisation and Analysis\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 5a\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 5b\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5: Visualising and Analysing Text Data with R (tidytext methods)\n\n\n\n\n\n\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 1 (Part 2): DataVis Makeover\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake-home Exercise 2: DataVis Makeover\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 4\n\n\n\n\n\n\nHo Zi Jun\n\n\nMay 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 3\n\n\n\n\n\n\nHo Zi Jun\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Project/Project.html",
    "href": "Project/Project.html",
    "title": "ISSS608 Visual Analytics Project",
    "section": "",
    "text": "Do check out my group’s project upcoming website which is still a work in progress: Link coming soon"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Singapore’s residential property market is branched into two primary sectors: public and private housing.Public housing, which is subsidised by the government, primarily caters to the essential housing needs of the general populace, specifically for households with a monthly income of S$14,000 or less. In contrast, households earning more than this income threshold generally turn to the private residential market. Moreover, given Singapore’s limited land area with it being one of the smallest countries in the world, real estate remains perpetually high in demand. This tends to bring about challenges due to the competitive nature of securing housing in either the public or private residential market.\n\n\n\nThe task for this exercise aims to elucidate the dynamics of the private residential market and sub-markets in the 1st quarter of 2024 as a graphical editor of a media company. This will be done with a couple of data visualizations in which they will are assumed to be consumed by the general public. From the visualisation we aim to uncover:\n\nthe distributions of property prices alongside property type, and\nany plausible relationship between these factors with their planning regions"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#introduction",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#introduction",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Singapore’s residential property market is branched into two primary sectors: public and private housing.Public housing, which is subsidised by the government, primarily caters to the essential housing needs of the general populace, specifically for households with a monthly income of S$14,000 or less. In contrast, households earning more than this income threshold generally turn to the private residential market. Moreover, given Singapore’s limited land area with it being one of the smallest countries in the world, real estate remains perpetually high in demand. This tends to bring about challenges due to the competitive nature of securing housing in either the public or private residential market.\n\n\n\nThe task for this exercise aims to elucidate the dynamics of the private residential market and sub-markets in the 1st quarter of 2024 as a graphical editor of a media company. This will be done with a couple of data visualizations in which they will are assumed to be consumed by the general public. From the visualisation we aim to uncover:\n\nthe distributions of property prices alongside property type, and\nany plausible relationship between these factors with their planning regions"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#getting-started",
    "title": "Take-home Exercise 1",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the required libraries\nFor this exercise, beside tidyverse, five other R packages will be used. They are:\n\nggdist: a ggplot2 extension spacially designed for visualising distribution and uncertainty.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggthemes: an R package which provides some extra themes, geoms, and scales for ‘ggplot2’.\ngganimate: a ggplot extension for creating animated statistical graphs.\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\npatchwork: an R package for preparing composite figure created using ggplot2.\ncolorspace: an R package that provides a broad toolbox for selecting individual colors or color palettes, manipulating these colors, and employing them in various kinds of visualisations.\ntidyverse: a family of modern R packages specially designed to support data science, analysis and communication tasks including creating static statistical graphs.\n\nThe following code chunk below uses p_load() of pacman package to check that the required R packages have been installed. If they are, the libraries will be called into R.\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               gganimate, ggrepel, ggiraph,\n               plotly, patchwork, colorspace,\n               tidyverse)\n\n\n\n2.2 Data Wrangling\nThe data for this exercise is the transaction data of Real Estate Information System (REALIS) which is obtained from Urban Redevelopment Authority (URA) which collects comprehensive and detailed property data under its REALIS section. The data range is dated from 1st January 2023 to 31st March 2024 in csv format and comes in 5 separate csv files for each corresponding quarter.\n\n2.2.1 Importing REALIS Data\nThe code chunk below imports the quarterly transaction data from REALIS by using the read_csv() function of readr package. Each dataset is labelled accordingly to their respective quarter(q)(1,2,3,4)_year(yy).\n\nq1_23 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nq2_23 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nq3_23 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nq4_23 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nq1_24 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nThe datasets are in a tibble dataframe with a total of 26,806 observations (rows) across 21 variables (columns). Each observation (row) corresponds to a property transaction in the private residential market, while the variables (columns) corresponds to information ranging from the transacted price, type of sale, property type for example.\nWith a substabtial large dataset, the individual datasets will be merged before we peform analysis. The rbind() function in the base package is used to combine the five tibble data frames into a single tibble data frame, private_property_data.\n\nprivate_property_data &lt;- rbind(q1_23, q2_23, q3_23, q4_23, q1_24)\n\nAn aggregate of all property types for units.\n\naggregate(private_property_data$`Number of Units`, by=list(Category=private_property_data$`Property Type`), FUN=sum)\n\n               Category     x\n1             Apartment 10785\n2           Condominium 10744\n3        Detached House   236\n4 Executive Condominium  3534\n5   Semi-Detached House   527\n6         Terrace House  1110\n\n\n\n\n2.2.2 Checking for duplicates\nGiven that dataset from URA is expected to be clean we will still proceed with some due diligence checks for duplicates. Using the duplicated() function we can observe if there are any duplicates in the tibble data frame.\n\nprivate_property_data[duplicated(private_property_data), ]\n\n# A tibble: 0 × 21\n# ℹ 21 variables: Project Name &lt;chr&gt;, Transacted Price ($) &lt;dbl&gt;,\n#   Area (SQFT) &lt;dbl&gt;, Unit Price ($ PSF) &lt;dbl&gt;, Sale Date &lt;chr&gt;,\n#   Address &lt;chr&gt;, Type of Sale &lt;chr&gt;, Type of Area &lt;chr&gt;, Area (SQM) &lt;dbl&gt;,\n#   Unit Price ($ PSM) &lt;dbl&gt;, Nett Price($) &lt;chr&gt;, Property Type &lt;chr&gt;,\n#   Number of Units &lt;dbl&gt;, Tenure &lt;chr&gt;, Completion Date &lt;chr&gt;,\n#   Purchaser Address Indicator &lt;chr&gt;, Postal Code &lt;chr&gt;,\n#   Postal District &lt;chr&gt;, Postal Sector &lt;chr&gt;, Planning Region &lt;chr&gt;, …\n\n\nResults confirm that there are no duplicated records found.\n\n\n2.2.3 Data Type Conversion and Transformation\n\nCreating New Columns (Month)\n\ndata_overall &lt;- private_property_data %&gt;%\n  mutate(Month = month(dmy(`Sale Date`), label = TRUE, abbr = FALSE),\n         Quarter = paste0(\"Q\", quarter(dmy(`Sale Date`)), \"-\", year(dmy(`Sale Date`))))\n\n\n\n\n2.2.4 Data Overview\n\nGlimpse of data\nThe glimpse() function will be utilised to have an overview of the dataset we have\n\nglimpse(data_overall)\n\nRows: 26,806\nColumns: 23\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n$ Month                         &lt;ord&gt; January, January, January, January, Janu…\n$ Quarter                       &lt;chr&gt; \"Q1-2023\", \"Q1-2023\", \"Q1-2023\", \"Q1-202…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#exploratory-data-anaylsis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#exploratory-data-anaylsis",
    "title": "Take-home Exercise 1",
    "section": "3 Exploratory Data Anaylsis",
    "text": "3 Exploratory Data Anaylsis\n\n3.1 Distribution of Private Residential Market (1st quarter of 2023 - 1st quarter of 2024)\n\nProperty distribution vs ($PSM)Property TypeProperty Type with geom_density()\n\n\n\n\nShow the code\nggplot(data=private_property_data, \n       aes(x= `Unit Price ($ PSM)`, \n           fill = `Property Type`)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\nObservations: The overlaid histogram illustrates the unit price per square meter ($ PSM) distribution across different property types in Singapore’s private residential market. Apartments and condominiums are predominant, with a high frequency of lower-priced units, indicative of a strong market presence and potential affordability. The executive condominiums show fewer transactions but at a more moderate price range, suggesting a niche market. Detached houses, while less frequent, have transactions across a wider price range, signaling diverse offerings from affordable to luxury segments. Semi-detached and terrace houses exhibit a similar pattern, though terrace houses skew towards lower prices, possibly reflecting market preference for affordability.\n\n\n\ndata &lt;- data_overall\n\n# Check the first few entries of the Sale Date column to understand its format\nhead(data$`Sale Date`)\n\n[1] \"01 Jan 2023\" \"02 Jan 2023\" \"02 Jan 2023\" \"02 Jan 2023\" \"03 Jan 2023\"\n[6] \"03 Jan 2023\"\n\n# Assuming the format is day/month/year, convert it to a Date object\ndata &lt;- data %&gt;%\n  mutate(Sale_Date = dmy(`Sale Date`))\n\n# Check if the conversion was successful\nstr(data$Sale_Date)\n\n Date[1:26806], format: \"2023-01-01\" \"2023-01-02\" \"2023-01-02\" \"2023-01-02\" \"2023-01-03\" ...\n\n\n\ndata &lt;- data %&gt;%\n  mutate(\n    Month = month(Sale_Date, label = TRUE, abbr = TRUE), # Use abbr = TRUE for abbreviated month names\n    Quarter = paste0(\"Q\", quarter(Sale_Date)),\n    Year = year(Sale_Date),\n    Month_Quarter = paste(Month, Quarter, Year, sep = \"-\")\n  )\n\n\ncondo_data &lt;- data %&gt;%\n  filter(`Property Type` == \"Condominium\") %&gt;%\n  group_by(Month_Quarter) %&gt;%\n  summarize(Number_of_Units_Sold = n(), .groups = 'drop')\n\n\n# Check the contents of the summarized data\nhead(condo_data)\n\n# A tibble: 6 × 2\n  Month_Quarter Number_of_Units_Sold\n  &lt;chr&gt;                        &lt;int&gt;\n1 Apr-Q2-2023                   1047\n2 Aug-Q3-2023                    782\n3 Dec-Q4-2023                    558\n4 Feb-Q1-2023                    617\n5 Feb-Q1-2024                    564\n6 Jan-Q1-2023                    441\n\n# Plot without interactivity\nggplot(condo_data, aes(x = Month_Quarter, y = Number_of_Units_Sold)) +\n  geom_col() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))\n\n\n\n\n\n# Interactive plot with ggiraph\ninteractive_bar_chart &lt;- ggplot(condo_data, aes(x = Month_Quarter, y = Number_of_Units_Sold,\n                                                tooltip = paste(Month_Quarter, Number_of_Units_Sold))) +\n  geom_bar_interactive(stat = \"identity\") +\n  labs(title = \"Number of Condominium Units Sold\", x = \"Month and Quarter\", y = \"Number of Units Sold\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n# Convert the ggplot object to an interactive plot with girafe\ninteractive_plot &lt;- girafe(ggobj = interactive_bar_chart)\nprint(interactive_plot)\n\n\n\n\n\nShow the code\nggplot(data=private_property_data, \n       aes(x = `Property Type`, \n           colour = `Property Type`,)) +\n  geom_density()\n\n\n\n\n\nObservations: This density plot visualizes the concentration of different property types in the private residential market. Apartments show a high density at lower price points, indicating commonality and affordability. Detached houses exhibit a peak at a higher price range, suggesting exclusivity and higher valuation, while other property types display varied densities and price ranges.\n\n\n\n\n\n3.2 Relationship between Property Type and Unit Price ($ PSM) (1st quarter of 2024)\n\nggplot(q1_24, \n       aes(x = `Unit Price ($ PSM)`, \n           y = `Property Type`,\n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nObservations: Based on the plot, it can be observed that the various property types generally resemble a normal distribution. With reference from the quartile lines, the Unit Price Per Square Metre ($ PSM) for Apartments tend to be higher than that for the other remaining five property types; while the ($ PSM) of Executive Condominiums (ECs) tend to be lower than the other property types. This corresponds to the fact that ECs while built by private developers with the facilities of a Condominium are sold as public housing via the Housing Development Board (HDB) which receive some government subsidies. ECs are also catered to middle-income Singaporeans / Singapore Permanent Residents who do not qualify for a HDB flat due to the income ceilling cap but find private condominiums out of their budget.\n\n\n3.3 Comparing Planning Region and Unit Price ($ PSM) (1st quarter of 2024)\n\nggplot(q1_24,\n       aes(x = `Unit Price ($ PSM)`, \n           y = `Planning Region`, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\nObservations: The ridgeplot displays the distribution of unit prices per square meter ($ PSM) for private residential properties across different planning regions in Singapore. Each layer represents one planning region, with the Central Region at the bottom and the West Region at the top.\nThe peaks of each layer indicate the most common unit prices in each region. The Central Region shows a wide distribution with a significant peak, suggesting a large variation in prices, but with a concentration of properties around a particular price point which could be indicative of a prevalent market value for that region. The North East and East Regions display narrower distributions, signifying less variability in unit prices.\nThe tails of the distributions, marked in red and blue, denote the extreme values (outliers) where the probability of unit prices falls into the lowest or highest 2.5%. The presence of these outliers, especially in the Central Region, may suggest private properties or areas of unusually high or low value."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#conclusion-and-findings",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#conclusion-and-findings",
    "title": "Take-home Exercise 1",
    "section": "4 Conclusion and Findings",
    "text": "4 Conclusion and Findings\nFrom this data visualisation exercise, data wrangling and visualization of the data was carried out to explore the relationship of private residential market price with factors such as Planning Region and Property Type. The key findings are:\n\nApartments and condominiums are prevalent in the lower quartiles, suggesting affordability, while prices for detached houses are spread across all quartiles, indicating a wide price range from moderate to luxury units.\nUnit prices in the Central Region are generally higher and more varied, while prices in other regions are more clustered, indicating less diversity in the housing market value.\nA possible reflection of a higher demand and a wider range of property types in the Central Region, in contrast to more uniform residential areas in other regions.\n\nTo provide a conclusion with the findings, it is worthwhile to note that the exercise primarily focused on visuals and it would be highly beneficial to also use statistical tests in tandem to support all the findings. Furthermore, not the entire dataset was utilised and visualisation was mainly done up for the period of: 1st quarter of 2024. Some of these variables could also bring out more findings such as the Tenure of the unit and the Purchaser Address Indicator which could bring up additional insights for people to make more informed decisions when intending to purchase a property in the private residential market. All in all, this exercise has been a good practice of utilising ggplot fundamentals; but even more enhancements could be done such as using Animated Statistical Graphics to help the audiece connect better if this was a presentation to being insights on how trends have shifted for various properties using visual animation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01_Part1.html#references",
    "title": "Take-home Exercise 1",
    "section": "5 References",
    "text": "5 References\n\nURA releases flash estimate of 1st Quarter 2024 private residential property price index\nUnsold private housing stock on the rise ahead of ramp-up in new launches in 2024\nHDB resale prices rise 1.7%; private home prices up 1.5% in first quarter: Flash estimates\nURA Data Dictionary"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "",
    "text": "In Take-home Exercise 1, we were tasked to produce two to three data visualisations using ggplot2 and its extensions to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024. The data preparation was also processed by using the tidyverse family of packages. The exercise allowed us to explore factors such as Transacted Price ($) and Unit Price ($ PSM) in relation to Property Typeand Planning Region to list a few.\nFor this Take-home Exercise 1 (Part 2), the objective is to perform a makeover and improve on the original data visualisation from other peers. We will be critiquing one data visualisation in terms of its clarity and aesthetics. A sketch of the alternative design will be done up based on the data visualisation design principles (four quadrants of clarity and aesthetic) and finally a remake of the original design will be implemented."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "",
    "text": "In Take-home Exercise 1, we were tasked to produce two to three data visualisations using ggplot2 and its extensions to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024. The data preparation was also processed by using the tidyverse family of packages. The exercise allowed us to explore factors such as Transacted Price ($) and Unit Price ($ PSM) in relation to Property Typeand Planning Region to list a few.\nFor this Take-home Exercise 1 (Part 2), the objective is to perform a makeover and improve on the original data visualisation from other peers. We will be critiquing one data visualisation in terms of its clarity and aesthetics. A sketch of the alternative design will be done up based on the data visualisation design principles (four quadrants of clarity and aesthetic) and finally a remake of the original design will be implemented."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading the required libraries\n\ntidyverse: (i.e. readr, tidyr, dplyr, ggplot2) for performing data science tasks such as importing, tidying, and wrangling data, as well as creating graphics based on The Grammar of Graphics,\nreshape2 for transforming data between wide and long formats\nggthemes: provides some extra themes, geoms, and scales for ‘ggplot2’.\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty\npatchwork: an R package for preparing composite figure created using ggplot2.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggrepel: an R package which provides geoms for ggplot2 to repel overlapping text labels.\nknitr: for building static html table to aid us in having a better view of tables\nlubridate: R package that makes it easier to work with dates and times.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe code chunk below uses p_load() function from pacman package to check if packages listed are already installed in the computer. The packages will be loaded if they are found to be installed. Otherwise, the function will proceed to install and load them into R environment.\n\npacman::p_load(tidyverse, reshape2, ggthemes,\n               ggdist, patchwork, ggridges,\n               ggrepel, knitr, lubridate,\n               patchwork)\n\n\n\n2.2 Data Import and Wrangling\n\nLabelling Data2023Q12023Q22023Q32023Q42024Q1\n\n\nThe subsequent code chunks utilises the read_csv function to import the five .csv data files from REALIS into the R environment. The data will also be labelled as such for identification:\n\n2023Q1: ResidentialTransaction20240308160536\n2023Q2: ResidentialTransaction20240308160736\n2023Q3: ResidentialTransaction20240308161009\n2023Q4: ResidentialTransaction20240308161109\n2024Q1: ResidentialTransaction20240414220633\n\nThe code chunk below utilises the rename_with() function to change the column names accordingly using column_rename as an object.\n\ncolumn_rename &lt;- function(orig_name) {\n  # Add underscores to spaces\n  gsub(\" +\", \"_\",\n       # Remove special characters\n       gsub(\"[^A-Z ]\", \"\",\n            # Convert to upper case and remove trailing spaces\n            toupper(orig_name)) %&gt;% trimws())\n}\n\n\n\n\nproperty_2023q1 &lt;- read_csv('data/ResidentialTransaction20240308160536.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2023q2 &lt;- read_csv('data/ResidentialTransaction20240308160736.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2023q3 &lt;- read_csv('data/ResidentialTransaction20240308161009.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2023q4 &lt;- read_csv('data/ResidentialTransaction20240308161109.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nproperty_2024q1 &lt;- read_csv('data/ResidentialTransaction20240414220633.csv') %&gt;%\n                  rename_with(column_rename)\nkable(head(property_2023q1, n=5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n\n\n\n\n\n\n\n\nThe code chunk below glimpse() will provide us with an overview of the data.\n\n2023Q12023Q22023Q32023Q42024Q1\n\n\n\nglimpse(property_2023q1)\n\nRows: 4,722\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASURE…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 128000…\n$ AREA_SQFT                   &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88, …\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 2023…\n$ ADDRESS                     &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JALA…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 420.…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive C…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"99 …\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"Pr…\n$ POSTAL_CODE                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", \"7…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"East Region\", \"North Re…\n$ PLANNING_AREA               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishun\"…\n\n\n\n\n\nglimpse(property_2023q2)\n\nRows: 6,125\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"THE GAZANIA\", \"THE GAZANIA\", \"ONE PEARL B…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 1528000, 1938000, 2051000, 1850700, 202150…\n$ AREA_SQFT                   &lt;dbl&gt; 678.13, 958.00, 699.66, 882.65, 699.66, 78…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2253, 2023, 2931, 2097, 2889, 2339, 3560, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Apr 2023\", \"01 Apr 2023\", \"01 Apr 2023…\n$ ADDRESS                     &lt;chr&gt; \"15 HOW SUN DRIVE #02-31\", \"7 HOW SUN DRIV…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 63, 89, 65, 82, 65, 73, 191, 46, 62, 93, 8…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 24254, 21775, 31554, 22570, 31100, 25178, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Apartment\",…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"Freehold\", \"Freehold\", \"99 yrs from 01/03…\n$ COMPLETION_DATE             &lt;chr&gt; \"2022\", \"2022\", \"Uncompleted\", \"Uncomplete…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"N.A\", \"Private\", \"Private\", \"HDB\", \"Priva…\n$ POSTAL_CODE                 &lt;chr&gt; \"538545\", \"538530\", \"169016\", \"419535\", \"2…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"19\", \"19\", \"03\", \"14\", \"10\", \"10\", \"09\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"53\", \"53\", \"16\", \"41\", \"27\", \"26\", \"22\", …\n$ PLANNING_REGION             &lt;chr&gt; \"North East Region\", \"North East Region\", …\n$ PLANNING_AREA               &lt;chr&gt; \"Serangoon\", \"Serangoon\", \"Outram\", \"Bedok…\n\n\n\n\n\nglimpse(property_2023q3)\n\nRows: 6,206\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"MYRA\", \"NORTH GAIA\", \"NORTH GAIA\", \"NORTH…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 1658000, 1449000, 1365000, 1231000, 127200…\n$ AREA_SQFT                   &lt;dbl&gt; 667.37, 1076.40, 1076.40, 958.00, 1001.05,…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2484, 1346, 1268, 1285, 1271, 2062, 1465, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Jul 2023\", \"01 Jul 2023\", \"01 Jul 2023…\n$ ADDRESS                     &lt;chr&gt; \"9 MEYAPPA CHETTIAR ROAD #02-07\", \"27 YISH…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 62, 100, 100, 89, 93, 156, 86, 86, 86, 86,…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 26742, 14490, 13650, 13831, 13677, 22192, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Apartment\", \"Executive Condominium\", \"Exe…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"Freehold\", \"99 yrs from 15/02/2021\", \"99 …\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"N.A\", \"HDB\", \"HDB\", \"HDB\", \"HDB\", \"Privat…\n$ POSTAL_CODE                 &lt;chr&gt; \"358456\", \"769342\", \"769342\", \"769299\", \"7…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"13\", \"27\", \"27\", \"27\", \"27\", \"08\", \"18\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"35\", \"76\", \"76\", \"76\", \"76\", \"21\", \"52\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"North Region\", \"North R…\n$ PLANNING_AREA               &lt;chr&gt; \"Toa Payoh\", \"Yishun\", \"Yishun\", \"Yishun\",…\n\n\n\n\n\nglimpse(property_2023q4)\n\nRows: 4,851\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"LEEDON GREEN\", \"LIV @ MB\", \"MORI\", \"THE A…\n$ TRANSACTED_PRICE            &lt;dbl&gt; 1749000, 3148740, 2422337, 1330000, 223700…\n$ AREA_SQFT                   &lt;dbl&gt; 538.20, 1453.14, 1259.39, 721.19, 1130.22,…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 3250, 2167, 1923, 1844, 1979, 2111, 2131, …\n$ SALE_DATE                   &lt;chr&gt; \"01 Oct 2023\", \"01 Oct 2023\", \"01 Oct 2023…\n$ ADDRESS                     &lt;chr&gt; \"26 LEEDON HEIGHTS #11-08\", \"114A ARTHUR R…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", \"S…\n$ AREA_SQM                    &lt;dbl&gt; 50.0, 135.0, 117.0, 67.0, 105.0, 55.0, 126…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 34980, 23324, 20704, 19851, 21305, 22725, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Apartment\",…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"Freehold\", \"99 yrs from 23/11/2021\", \"Fre…\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"Private\", \"Private\", \"Private\", \"Private\"…\n$ POSTAL_CODE                 &lt;chr&gt; \"266221\", \"439826\", \"399738\", \"668159\", \"7…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"10\", \"15\", \"14\", \"23\", \"26\", \"22\", \"26\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"26\", \"43\", \"39\", \"66\", \"78\", \"61\", \"78\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"Central Region\", \"Centr…\n$ PLANNING_AREA               &lt;chr&gt; \"Bukit Timah\", \"Marine Parade\", \"Geylang\",…\n\n\n\n\n\nglimpse(property_2024q1)\n\nRows: 4,902\nColumns: 21\n$ PROJECT_NAME                &lt;chr&gt; \"THE LANDMARK\", \"POLLEN COLLECTION\", \"SKY …\n$ TRANSACTED_PRICE            &lt;dbl&gt; 2726888, 3850000, 2346000, 2190000, 195400…\n$ AREA_SQFT                   &lt;dbl&gt; 1076.40, 1808.35, 1087.16, 807.30, 796.54,…\n$ UNIT_PRICE_PSF              &lt;dbl&gt; 2533, 2129, 2158, 2713, 2453, 2577, 838, 1…\n$ SALE_DATE                   &lt;chr&gt; \"01 Jan 2024\", \"01 Jan 2024\", \"01 Jan 2024…\n$ ADDRESS                     &lt;chr&gt; \"173 CHIN SWEE ROAD #22-11\", \"34 POLLEN PL…\n$ TYPE_OF_SALE                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New S…\n$ TYPE_OF_AREA                &lt;chr&gt; \"Strata\", \"Land\", \"Strata\", \"Strata\", \"Str…\n$ AREA_SQM                    &lt;dbl&gt; 100.0, 168.0, 101.0, 75.0, 74.0, 123.0, 32…\n$ UNIT_PRICE_PSM              &lt;dbl&gt; 27269, 22917, 23228, 29200, 26405, 27741, …\n$ NETT_PRICE                  &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-…\n$ PROPERTY_TYPE               &lt;chr&gt; \"Condominium\", \"Terrace House\", \"Apartment…\n$ NUMBER_OF_UNITS             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ TENURE                      &lt;chr&gt; \"99 yrs from 28/08/2020\", \"99 yrs from 09/…\n$ COMPLETION_DATE             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncompleted…\n$ PURCHASER_ADDRESS_INDICATOR &lt;chr&gt; \"Private\", \"N.A\", \"HDB\", \"N.A\", \"Private\",…\n$ POSTAL_CODE                 &lt;chr&gt; \"169878\", \"807233\", \"469657\", \"118992\", \"5…\n$ POSTAL_DISTRICT             &lt;chr&gt; \"03\", \"28\", \"16\", \"05\", \"21\", \"21\", \"28\", …\n$ POSTAL_SECTOR               &lt;chr&gt; \"16\", \"80\", \"46\", \"11\", \"59\", \"58\", \"79\", …\n$ PLANNING_REGION             &lt;chr&gt; \"Central Region\", \"North East Region\", \"Ea…\n$ PLANNING_AREA               &lt;chr&gt; \"Outram\", \"Serangoon\", \"Bedok\", \"Queenstow…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nAdding columnsCombining tablesFiltering necessary columns (The code chunk)\n\n\n\nproperty_2023q1 &lt;- property_2023q1 %&gt;%\n  mutate(\n    QUARTER=\"2023Q1\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2023q2 &lt;- property_2023q2 %&gt;%\n  mutate(\n    QUARTER=\"2023Q2\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2023q3 &lt;- property_2023q3 %&gt;%\n  mutate(\n    QUARTER=\"2023Q3\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2023q4 &lt;- property_2023q4 %&gt;%\n  mutate(\n    QUARTER=\"2023Q4\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\nproperty_2024q1 &lt;- property_2024q1 %&gt;%\n  mutate(\n    QUARTER=\"2024Q1\",\n    MONTH_YEAR=format(dmy(SALE_DATE), \"%b-%y\")\n  )\n\n\n\n\nrealis &lt;- property_2023q1 %&gt;%\n  rbind(property_2023q2) %&gt;%\n  rbind(property_2023q3) %&gt;%\n  rbind(property_2023q4) %&gt;%\n  rbind(property_2024q1)\nkable(head(realis, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\nTRANSACTED_PRICE\nAREA_SQFT\nUNIT_PRICE_PSF\nSALE_DATE\nADDRESS\nTYPE_OF_SALE\nTYPE_OF_AREA\nAREA_SQM\nUNIT_PRICE_PSM\nNETT_PRICE\nPROPERTY_TYPE\nNUMBER_OF_UNITS\nTENURE\nCOMPLETION_DATE\nPURCHASER_ADDRESS_INDICATOR\nPOSTAL_CODE\nPOSTAL_DISTRICT\nPOSTAL_SECTOR\nPLANNING_REGION\nPLANNING_AREA\nQUARTER\nMONTH_YEAR\n\n\n\n\nTHE REEF AT KING’S DOCK\n2317000\n882.65\n2625\n01 Jan 2023\n12 HARBOURFRONT AVENUE #05-32\nNew Sale\nStrata\n82.0\n28256\n-\nCondominium\n1\n99 yrs from 12/01/2021\nUncompleted\nHDB\n097996\n04\n09\nCentral Region\nBukit Merah\n2023Q1\nJan-23\n\n\nURBAN TREASURES\n1823500\n882.65\n2066\n02 Jan 2023\n205 JALAN EUNOS #08-02\nNew Sale\nStrata\n82.0\n22238\n-\nCondominium\n1\nFreehold\nUncompleted\nPrivate\n419535\n14\n41\nEast Region\nBedok\n2023Q1\nJan-23\n\n\nNORTH GAIA\n1421112\n1076.40\n1320\n02 Jan 2023\n29 YISHUN CLOSE #08-10\nNew Sale\nStrata\n100.0\n14211\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269343\n27\n26\nNorth Region\nYishun\n2023Q1\nJan-23\n\n\nNORTH GAIA\n1258112\n1033.34\n1218\n02 Jan 2023\n45 YISHUN CLOSE #07-42\nNew Sale\nStrata\n96.0\n13105\n-\nExecutive Condominium\n1\n99 yrs from 15/02/2021\nUncompleted\nHDB\n269294\n27\n26\nNorth Region\nYishun\n2023Q1\nJan-23\n\n\nPARC BOTANNIA\n1280000\n871.88\n1468\n03 Jan 2023\n12 FERNVALE STREET #06-16\nResale\nStrata\n81.0\n15802\n-\nCondominium\n1\n99 yrs from 28/12/2016\n2022\nHDB\n797391\n28\n79\nNorth East Region\nSengkang\n2023Q1\nJan-23\n\n\nNANYANG PARK\n5870000\n3322.85\n1767\n03 Jan 2023\n72 JALAN LIMBOK\nResale\nLand\n308.7\n19015\n-\nTerrace House\n1\n999 yrs from 14/02/1881\n-\nPrivate\n548742\n19\n54\nNorth East Region\nHougang\n2023Q1\nJan-23\n\n\nPALMS @ SIXTH AVENUE\n4950000\n4520.88\n1095\n03 Jan 2023\n231 SIXTH AVENUE\nResale\nStrata\n420.0\n11786\n-\nSemi-Detached House\n1\nFreehold\n2015\nPrivate\n275780\n10\n27\nCentral Region\nBukit Timah\n2023Q1\nJan-23\n\n\nN.A.\n3260000\n1555.40\n2096\n03 Jan 2023\n19 TENG TONG ROAD\nResale\nLand\n144.5\n22561\n-\nTerrace House\n1\nFreehold\n1941\nPrivate\n423510\n15\n42\nCentral Region\nMarine Parade\n2023Q1\nJan-23\n\n\nWHISTLER GRAND\n850000\n441.32\n1926\n03 Jan 2023\n107 WEST COAST VALE #30-04\nSub Sale\nStrata\n41.0\n20732\n-\nApartment\n1\n99 yrs from 07/05/2018\n2022\nHDB\n126751\n05\n12\nWest Region\nClementi\n2023Q1\nJan-23\n\n\nNORTHOAKS\n1268000\n1603.84\n791\n03 Jan 2023\n30 WOODLANDS CRESCENT #01-11\nResale\nStrata\n149.0\n8510\n-\nExecutive Condominium\n1\n99 yrs from 16/12/1997\n2000\nHDB\n738086\n25\n73\nNorth Region\nWoodlands\n2023Q1\nJan-23\n\n\n\n\n\n\n\nAfter adding the QUARTER columns, there are now 22 variables in the dataframe. However, for this exercise not all of them are necessary to carry out the analysis. We shall filter out the necessary columns and drop the rest for efficiency.\n\nrealis &lt;-\n  realis %&gt;% select(\n    c(\n      QUARTER,\n      MONTH_YEAR,\n      PROPERTY_TYPE,\n      PLANNING_REGION,\n      PLANNING_AREA,\n      TRANSACTED_PRICE,\n      AREA_SQFT,\n      UNIT_PRICE_PSF,\n      SALE_DATE\n    )\n  )\nglimpse(realis) #Overview of transformed data\n\nRows: 26,806\nColumns: 9\n$ QUARTER          &lt;chr&gt; \"2023Q1\", \"2023Q1\", \"2023Q1\", \"2023Q1\", \"2023Q1\", \"20…\n$ MONTH_YEAR       &lt;chr&gt; \"Jan-23\", \"Jan-23\", \"Jan-23\", \"Jan-23\", \"Jan-23\", \"Ja…\n$ PROPERTY_TYPE    &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive Condominium\"…\n$ PLANNING_REGION  &lt;chr&gt; \"Central Region\", \"East Region\", \"North Region\", \"Nor…\n$ PLANNING_AREA    &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishun\", \"Sengkang…\n$ TRANSACTED_PRICE &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280000, 5870000,…\n$ AREA_SQFT        &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88, 3322.85, 45…\n$ UNIT_PRICE_PSF   &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095, 2096, 1926,…\n$ SALE_DATE        &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 2023\", \"02 Jan …\n\n\nUpon using glimpse(), it can be observed that there are 9 variables relevant to our data viz makeover."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-visualisation-makeover",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-visualisation-makeover",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "3 Data Visualisation Makeover",
    "text": "3 Data Visualisation Makeover\nIn this section, we will proceed with a makeover of a peer’s data visualisation and building an improved version. Shown below is the plot of our peer’s plot.\n\n\n\n\n\n\nThe author stated:\n\n\n\nAs we mentioned about the individual market is focus on the apartment and condominium above, and we know the distribution of total property, what about the first quarter unit price of these two popular goods?\nUpon examination of the violin plots, a clear disparity emerges between the average unit prices of condominiums and apartments, standing at approximately $1,500 and $2,000, respectively, for the period spanning January to March. Noteworthy is the discernible uptick in both unit price and transaction volume from January to March 2024. Despite an overall reduction in total transactions vis-a-vis the preceding year, there is an unmistakable trend towards growth within specific sub-markets, suggesting an increasing inclination towards higher-value properties\n\n\n\nThe code chunk (i)The plot (i)The code chunk (ii)The plot (ii)\n\n\n\nfiltered_data &lt;- combined_data %&gt;%\n  mutate(Sale_Date = dmy(`Sale Date`)) %&gt;%\n  filter((year(Sale_Date) == 2023 & \n          month(Sale_Date) %in% 1:12) |\n         (year(Sale_Date) == 2024 & \n          month(Sale_Date) %in% 1:3)) %&gt;%\n  mutate(Quarter_Sale_Data = case_when(\n    between(Sale_Date, as.Date(\"2023-01-01\"), as.Date(\"2023-03-31\")) ~ \"Q1_2023\",\n    between(Sale_Date, as.Date(\"2023-04-01\"), as.Date(\"2023-06-30\")) ~ \"Q2_2023\",\n    between(Sale_Date, as.Date(\"2023-07-01\"), as.Date(\"2023-09-30\")) ~ \"Q3_2023\",\n    between(Sale_Date, as.Date(\"2023-10-01\"), as.Date(\"2023-12-31\")) ~ \"Q4_2023\",\n    between(Sale_Date, as.Date(\"2024-01-01\"), as.Date(\"2024-03-31\")) ~ \"Q1_2024\",\n    TRUE ~ NA_character_\n  )) %&gt;%\n  filter(!is.na(Quarter_Sale_Data)) %&gt;%\n  mutate(Month_Sale_Data = paste0(year(Sale_Date), \"-\", month(Sale_Date)))\n\nfiltered_data &lt;- filtered_data %&gt;%\n  filter(`Property Type` %in% c(\"Apartment\", \"Condominium\"))\n\nggplot(filtered_data, aes(x = Month_Sale_Data, y = `Unit Price ($ PSF)`, color = `Property Type`)) +\n  geom_violin() +\n  geom_point(position = \"jitter\",\n             size = 0.1) +\n  labs(title = \"Unit Price per Square Foot for Apartments and Condominiums\",\n       x = \"Month\",\n       y = \"Unit Price ($ PSF)\") +\n  theme_light(base_size = 6) +\n  xlim(c(\"2024-1\",\"2024-2\",\"2024-3\"))\n\n\n\n\n\n\nPeer’s Data Visualisation\n\n\n\n\n\nggplot(filtered_data, aes(x = Month_Sale_Data, y = `Unit Price ($ PSF)`, color = `Property Type`)) +\n  geom_violin() +\n  geom_point(position = \"jitter\",\n             size = 0.1) +\n  labs(title = \"Unit Price per Square Foot for Apartments and Condominiums\",\n       x = \"Month\",\n       y = \"Unit Price ($ PSF)\") +\n  theme_light(base_size = 6) +\n  xlim(c(\"2023-1\",\"2023-2\",\"2023-3\"))\n\n\n\n\n\n\nPeer’s Data Visualisation\n\n\n\n\n\n\n3.1 Observations: Clarity and Aesthetics\nClarity\n\nThe use of a violin plot overlaid with scatter plot points helps illustrate the distribution of prices per square foot for both apartments and condominiums across different months.\nThe red (apartment) and teal (condominium) color distinction or scatterplot is generally clear, but there’s significant overlap in data points, which may confuse the viewer about the exact differences in price distributions between these property types. This might also affect the ease of reading and understanding by audiences from the general public.\n\nAesthetics\n\nThe main title while clear could be centralised for easier readability.\nThe plot successfully uses colour to differentiate between the two types of properties. The choice of colors is visually distinct, which is helpful for quick differentiation.\nHowever, the presence of outliers, particularly those extreme values shown as vertical lines extending from the main bodies of the violins, can confuse readers from the overall trends from the plot.\n\n\n\n3.2 Sketch of alternative design\n Improvements based on the above points mentioned earlier:\n\nMain title which was centred to give improved balanced to the plot layout.\nCombine each different selected property type into each portion of the chart, sharing the same y-axis to reveal the distribution among different property types simultaneously.\nAdded additional pointers and/or labels to highlight summary statistic values such as Mean, Median and IQR.\nAddress the issue of outliers in the plot for this case I have chosen to highlight the outliers to enable readers to be aware and take note of them since they were still actual property transactions.\nUse widely different colours to differentiate between the variables for better visual distinction.\n\n\n\n3.3 Remake of Original Design\n\n1st iteration\nDerived from the sketch ideation, this plot shows Unit Price ($ PSF) by Quarter as a start.\n\nggplot(data= realis,\n       aes(x= QUARTER, y= UNIT_PRICE_PSF, color = QUARTER)) +\n  geom_violin(aes(fill = QUARTER), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width= 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +  \n  coord_cartesian(ylim = c(400,6000)) +\n  scale_color_manual(values=c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\", \"#0437bf\")) +\n  theme_economist() +\n  labs(title=\"Unit Price ($PSF) by Quarter\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title=element_text(size= 12, hjust= 0.5),\n        axis.text = element_text(size= 10),\n        legend.position = \"none\")\n\n\n\n\n\n\n2nd iteration (Filtering of variables)\nTo accommodate to the peer’s selection of selected property type\n\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         QUARTER %in% c(\"2023Q1\", \"2024Q1\"))\n\nggplot(data= filtered_data,\n       aes(x= QUARTER, y= UNIT_PRICE_PSF, color = QUARTER)) +\n  geom_violin(aes(fill = QUARTER), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width= 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +  \n  coord_cartesian(ylim = c(400,6000)) +\n  scale_color_manual(values=c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\", \"#0437bf\")) +\n  theme_economist() +\n  labs(title=\"Unit Price ($PSF) by Quarter\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title=element_text(size= 12, hjust= 0.5),\n        axis.text = element_text(size= 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n\n\n\n\n\n3rd iteration (Filtering of variables)\nTo accommodate to the peer’s selection of time period (Month)\n\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\nggplot(data= filtered_data,\n       aes(x= MONTH_YEAR, y= UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width= 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +  \n  coord_cartesian(ylim = c(400,6000)) +\n  scale_color_manual(values=c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\", \"#0437bf\")) +\n  theme_economist() +\n  labs(title=\"Unit Price ($PSF) by Month\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title=element_text(size= 12, hjust= 0.5),\n        axis.text = element_text(size= 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n\n\n\n\n\n4th iteration (Addition of Summary Statistics)\nFor Year 2023\n\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2023)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)\n\n\n\n\nFor Year 2024\n\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-24\", \"Feb-24\", \"Mar-24\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-24\", \"Feb-24\", \"Mar-24\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot2 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"grey20\", outlier.size = 1, \n               outlier.alpha = 0.3) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2024)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot2)\n\n\n\n\n\n\n5th iteration (Highlighting Outliers)\n\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"darkred\", outlier.size = 1, outlier.shape = 8, \n               outlier.alpha = 0.8) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2023)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#improved-visualisation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#improved-visualisation",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "4 Improved Visualisation",
    "text": "4 Improved Visualisation\n\nJan-Mar 2024Jan-Mar 2023\n\n\n\n\nShow the code\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-24\", \"Feb-24\", \"Mar-24\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-24\", \"Feb-24\", \"Mar-24\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"darkred\", outlier.size = 1, outlier.shape = 8, \n               outlier.alpha = 0.8) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2024)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)\n\n\n\n\n\n\n\n\n\nShow the code\n# Filter and order the data as before\nfiltered_data &lt;- realis %&gt;%\n  filter(PROPERTY_TYPE %in% c(\"Apartment\", \"Condominium\"),\n         MONTH_YEAR %in% c(\"Jan-23\", \"Feb-23\", \"Mar-23\")) %&gt;%\n  mutate(MONTH_YEAR = factor(MONTH_YEAR, levels = c(\"Jan-23\", \"Feb-23\", \"Mar-23\")))\n\n# Calculate summary statistics for annotations\nstats_data &lt;- filtered_data %&gt;%\n  group_by(MONTH_YEAR, PROPERTY_TYPE) %&gt;%\n  summarise(\n    Mean = mean(UNIT_PRICE_PSF),\n    Median = median(UNIT_PRICE_PSF),\n    IQR = IQR(UNIT_PRICE_PSF),\n    .groups = 'drop'\n  )\n\n# Generate the violin plot with statistical annotations\nplot1 &lt;- ggplot(data = filtered_data,\n       aes(x = MONTH_YEAR, y = UNIT_PRICE_PSF, color = MONTH_YEAR)) +\n  geom_violin(aes(fill = MONTH_YEAR), size = 0.6, alpha = 0.3, linewidth = 0) +\n  geom_boxplot(width = 0.4, outlier.colour = \"darkred\", outlier.size = 1, outlier.shape = 8, \n               outlier.alpha = 0.8) +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"black\",        \n               size=2) +\n  geom_text(data = stats_data, aes(label = sprintf(\"Mean: %.2f\\nMedian: %.2f\\nIQR: %.2f\", Mean, Median, IQR), \n                                   y = 5500), size = 3, hjust = 0.5) +\n  coord_cartesian(ylim = c(400, 6000)) +\n  scale_color_manual(values = c(\"#c73824\", \"#0477bf\", \"#9E9E9E\", \"#0CDBBC\")) +\n  theme_economist() +\n  labs(title = \"Unit Price ($PSF) by Month (Year 2023)\") +\n  scale_y_continuous(breaks = seq(400, 6000, by = 500)) +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        plot.title = element_text(size = 12, hjust = 0.5),\n        axis.text = element_text(size = 10),\n        legend.position = \"none\") +\n  facet_wrap(~PROPERTY_TYPE)\n\n# Display the plot\nprint(plot1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#key-takeaways",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#key-takeaways",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "5 Key Takeaways",
    "text": "5 Key Takeaways\nOverall, the selected peer’s work was done up relatively well.\nThe processes for the data visualisation makeover in this take-home exercise illustrates the utmost importance of attention to detail when making a plot. Here are some pointers which I found were useful:\n\nTo check the data\n\nIt goes without saying that data is the core element of any chart or graph. If the data is unreliable, the graph will also be unreliable. Therefore, it’s crucial to ensure your data is accurate. Begin by creating straightforward graphs to identify any outliers or unusual spikes. Always double-check anything that looks off. You may find a surprising number of data entry errors in the spreadsheets you receive.\n\nChoosing of colours\n\nEffective use of color can significantly enhance and clarify a presentation, while poor use of color can lead to confusion and obscurity. Although color adds an aesthetic quality, its primary role in displaying information is functional. The key is to consider what information needs to be conveyed and to determine if and how color can improve the communication of that information.\n\nHighlighting what’s important\n\nTo effectively communicate a message, it’s essential to direct your audience’s attention to the data under analysis. Start with a title that captures the essence of your insight. Then, emphasize your data visually while maintaining other data in a subdued manner in the background, providing context and enabling comparisons."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#references",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#references",
    "title": "Take-home Exercise 2: DataVis Makeover",
    "section": "6 References",
    "text": "6 References\n\nURA releases flash estimate of 1st Quarter 2024 private residential property price index\nUnsold private housing stock on the rise ahead of ramp-up in new launches in 2024\nHDB resale prices rise 1.7%; private home prices up 1.5% in first quarter: Flash estimates\n7 Basic Rules for Making Charts and Graphs\nData Visualization: Clarity or Aesthetics?\nDos and don’ts of data visualisation — European Environment Agency\nChoosing Colors for Data Visualization"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#getting-started",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nIn this hands-on exercise, the key R package being used is the tmap package. Besides tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tidyverse, tmap)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#importing-data-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#importing-data-in-r",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "3 Importing Data in R",
    "text": "3 Importing Data in R\n\n3.1 The Data\nTwo data sets will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e.MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on the URA Master Plan 2014.\nSingapore Residents by Planning Area(PA) / Subzone(SZ), Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e.respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to the MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjho008\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n\n\n\n\nPossible reasons\n\n\n\n\nDefault Behaviour: R, by default, limits the number of rows displayed in the console for data frames and spatial objects to avoid clutter.\nEfficiency: Spatial data can be quite large, so showing all records at once can be impractical and slows down the session.\n\n\n\n\n\n3.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n3.4 Data Preparation\nBefore a thematic map can be prepared, it is required for us to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nPLANNING AREA\nSUBZONE\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n3.4.1 Data Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) +\n  rowSums(.[13:15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n  /`ECONOMY ACTIVE`) %&gt;%\n    select(`PA` ,`SZ`, `YOUNG`,\n           `ECONOMY ACTIVE`, `AGED`,\n           `TOTAL`, `DEPENDENCY`)\n\n\n\n3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\n\n\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "4 Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest approach to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown after the code.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, the “view” option should be used.\nfill argument is used to map the attribute (i.e.DEPENDENCY)\n\n\n\n\n\n4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes the aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency Ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-Zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics (DOS)\",\n              position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-sections, we will explore more on tmap functions that are used to plot these elements.\n\n4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer of elements such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\nDEPENDENCYECONOMY ACTIVEAGEDYOUNG\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"ECONOMY ACTIVE\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\")\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. We will learn more about the color scheme in sub-section 4.4.\nBy default, Missing values will be shaded in grey.\n\n\n\n4.2.3 Drawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is actually a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\nDEPENDENCYECONOMY ACTIVE\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"ECONOMY ACTIVE\")\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to their respective values such as Dependency\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n4.3.1 Plotting choropleth maps with built-in classification methods\n\nquantile methodequal method\n\n\nThe code chunk below shows a quantile data classification that uses 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method is more evenly distributed than the equal data classification method.\n\n\n\n\nWarning: Maps Lie!\n\n\nDIY: Using what we had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nsd method (5 classes)pretty method (5 classes)kmeans method (5 classes)fisher method (5 classes)\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, pretty data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, kmeans data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, fisher data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observations can be drawn?\n\n\nsd method (2 classes)sd method (6 classes)sd method (10 classes)sd method (20 classes)\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, sd data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nquantile method (2 classes)quantile method (6 classes)quantile method (10 classes)quantile method (20 classes)\n\n\nIn the code chunk below, quantile data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, quantile data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, quantile data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nIn the code chunk below, quantile data classification method is used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n4.3.2 Plotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we can set break points at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we can set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n4.4.1 Using ColourBrewer palette\nTo change the colour, we will assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that in the code chunk below, the choropleth map is shaded in green.\n\npalette = “Greens”palette = “-Greens”\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\n\n\n4.5 Map Layouts\nMap layout refers to the combination of all map elements into a comprehensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n4.5.2 Map Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style being used.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of Persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics (DOS)\",\n          position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style of the choropleth map, we can utilise the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n4.6.1 Assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example shown below, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n          style = c(\"equal\", \"quantile\"),\n          palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) +\n  tm_facets(by = \"REGION_N\",\n            free.coords = TRUE,\n            drop.shapes = FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)\n\n\n\n\n\n\n\n4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#reference",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "5 Reference",
    "text": "5 Reference\n\nKam, T.S. (2023). Chapter 17 Visualising and Analysing Time-oriented Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#references",
    "title": "Hands-on Exercise 8a: Choropleth Mapping with R",
    "section": "5 References",
    "text": "5 References\n\nKam, T.S. (2023). Choropleth Mapping with R\n\n\n5.1 All about tmap packages\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "5 Data Wrangling",
    "text": "5 Data Wrangling\nIn order to improve the data quality and make it more consumable and useful for analytics, we will proceed with data wrangling to transform and structure the raw data form into specific desired formats\n\n5.1 Extracing the edges and nodes data\n\nEdgesNodes\n\n\nIn this section, we will extract and wrangle the edges object. The edges form the relationship or link between different nodes.\n\n5.1.1 Extracting the edges data\nThe code chunk below will be used to extract the links data.frame of mc3_data and saves it as a tibble data.frame called mc3_edges_raw.\n\n\nCode\nmc3_edges_raw &lt;- as_tibble(mc3_data$links) %&gt;%\n  distinct() #use to avoid duplicate records; if they are the same will be treated as duplicates and kept as one\n\n\nglimpse() of dplyr will be used to reveal the structure of mc3_edges_raw tibble data.table\n\n\nCode\nglimpse(mc3_edges_raw)\n\n\nRows: 75,817\nColumns: 11\n$ start_date          &lt;chr&gt; \"2016-10-29T00:00:00\", \"2035-06-03T00:00:00\", \"202…\n$ type                &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Sharehol…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pela…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-07-15T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corp…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Imp…\n$ source              &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowm…\n$ target              &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and…\n$ key                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe following issues can be identified from the table above:\n\ncolumns with date data type are not in the correct format\nsome field names(for e.g _last_edited_by, _date_added) start with “_” and will have to be renamed to avoid unnecessary coding issues in the later part of the tasks.\n\n\n\n\n\n5.1.2 Correcting the date data type\nThe code chunk below uses as_datetime() of the lubridate package to convert fields with character date into POSIXt format.\n\n\nCode\nmc3_edges_raw$\"start_date\" &lt;- as_datetime(mc3_edges_raw$start_date)\nmc3_edges_raw$\"_last_edited_date\" &lt;- as_datetime(mc3_edges_raw$\"_last_edited_date\")\nmc3_edges_raw$\"_date_added\" &lt;- as_datetime(mc3_edges_raw$\"_date_added\")\nmc3_edges_raw$\"end_date\" &lt;- as_datetime(mc3_edges_raw$end_date)\n\n\n\n\n5.1.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields that start with “_”.\n\n\nCode\nmc3_edges_raw &lt;- mc3_edges_raw %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"date_added\" = \"_date_added\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\nNext, glimpse() function will be used to confirm if the processes above have been performed correctly.\n\n\nCode\nglimpse(mc3_edges_raw)\n\n\nRows: 75,817\nColumns: 11\n$ start_date       &lt;dttm&gt; 2016-10-29, 2035-06-03, 2028-11-20, 2024-09-04, 2034…\n$ type             &lt;chr&gt; \"Event.Owns.Shareholdership\", \"Event.Owns.Shareholder…\n$ last_edited_by   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Niklaus Oberon\", \"Pelagia…\n$ last_edited_date &lt;dttm&gt; 2035-01-01, 2035-07-15, 2035-01-01, 2035-01-01, 2035…\n$ date_added       &lt;dttm&gt; 2035-01-01, 2035-07-15, 2035-01-01, 2035-01-01, 2035…\n$ raw_source       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Oceanus Corpora…\n$ algorithm        &lt;chr&gt; \"Automatic Import\", \"Manual Entry\", \"Automatic Import…\n$ source           &lt;chr&gt; \"Avery Inc\", \"Berger-Hayes\", \"Bowers Group\", \"Bowman-…\n$ target           &lt;chr&gt; \"Allen, Nichols and Thompson\", \"Jensen, Morris and Do…\n$ key              &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ end_date         &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\n\n\n5.1.4 Selecting the columns\nWe will select the relevant variables for our analysis:\n\nsource - to identify the actor of the relationship, corresponds to id in nodes.\ntarget - to identify the receiver of the relationship, corresponds to id in nodes.\ntype - to identify the type(edge - 3 types) of the relationship\nstart_date - to identify date at which the event began\n\n\n\nCode\nmc3_edges &lt;- mc3_edges_raw %&gt;%\n  select(source, target, type, start_date)\n\n\nTo help us better understand the 3 distinct types that are present under mc3_edges the unique() function is used:\n\n\nCode\nmc3_edges$type %&gt;% unique()\n\n\n[1] \"Event.Owns.Shareholdership\"      \"Event.Owns.BeneficialOwnership\" \n[3] \"Event.WorksFor\"                  \"Relationship.FamilyRelationship\"\n\n\n\n\n\nIn this section, we will extract and wrangle the nodes object. The nodes form either the organisation/individual in the network.\n\n5.1.5 Extracting the nodes data\nThe code chunk below will be used to extract the nodes data.frame of mc3_data and parses it as a tibble data.frame called mc3_nodes_raw.\n\n\nCode\nmc3_nodes_raw &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  distinct() # applied distinct() to remove duplicate node records\n\n\nglimpse() of dplyr will be used to reveal the structure of mc3_nodes_raw tibble data.table\n\n\nCode\nglimpse(mc3_nodes_raw)\n\n\nRows: 60,520\nColumns: 15\n$ type                &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organizatio…\n$ country             &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", …\n$ ProductServices     &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food…\n$ PointOfContact      &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertso…\n$ HeadOfOrg           &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules La…\n$ founding_date       &lt;chr&gt; \"1954-04-24T00:00:00\", \"2009-06-12T00:00:00\", \"202…\n$ revenue             &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, …\n$ TradeDescription    &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer…\n$ `_last_edited_by`   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoc…\n$ `_last_edited_date` &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_date_added`       &lt;chr&gt; \"2035-01-01T00:00:00\", \"2035-01-01T00:00:00\", \"203…\n$ `_raw_source`       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Cor…\n$ `_algorithm`        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic…\n$ id                  &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Ab…\n$ dob                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the table above, the date data type and inappropriate field name issues as faced earlier are also present:\n\ncolumns with date data type are not in the correct format\nsome field names(for e.g _last_edited_by, _date_added) start with “_” and will have to be renamed to avoid unnecessary coding issues in the later part of the tasks.\n\n\n\nHence, we will also work on correcting these errors.\n\n\n5.1.6 Correcting the date data type\nThe code chunk below uses as_datetime() of the lubridate package to convert fields with character date into POSIXt format.\n\n\nCode\nmc3_nodes_raw$\"founding_date\" &lt;- as_datetime(mc3_nodes_raw$founding_date)\nmc3_nodes_raw$\"_last_edited_date\" &lt;- as_datetime(mc3_nodes_raw$\"_last_edited_date\")\nmc3_nodes_raw$\"_date_added\" &lt;- as_datetime(mc3_nodes_raw$\"_date_added\")\nmc3_nodes_raw$\"dob\" &lt;- as_datetime(mc3_nodes_raw$dob)\n\n\n\n\n5.1.7 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields that start with “_”.\n\n\nCode\nmc3_nodes_raw &lt;- mc3_nodes_raw %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"date_added\" = \"_date_added\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\nNext, glimpse() function will be used to confirm if the processes above have been performed correctly.\n\n\nCode\nglimpse(mc3_nodes_raw)\n\n\nRows: 60,520\nColumns: 15\n$ type             &lt;chr&gt; \"Entity.Organization.Company\", \"Entity.Organization.C…\n$ country          &lt;chr&gt; \"Uziland\", \"Mawalara\", \"Uzifrica\", \"Islavaragon\", \"Oc…\n$ ProductServices  &lt;chr&gt; \"Unknown\", \"Furniture and home accessories\", \"Food pr…\n$ PointOfContact   &lt;chr&gt; \"Rebecca Lewis\", \"Michael Lopez\", \"Steven Robertson\",…\n$ HeadOfOrg        &lt;chr&gt; \"Émilie-Susan Benoit\", \"Honoré Lemoine\", \"Jules Labbé…\n$ founding_date    &lt;dttm&gt; 1954-04-24, 2009-06-12, 2029-12-15, 1972-02-16, 1954…\n$ revenue          &lt;dbl&gt; 5994.73, 71766.67, 0.00, 0.00, 4746.67, 46566.67, 169…\n$ TradeDescription &lt;chr&gt; \"Unknown\", \"Abbott-Gomez is a leading manufacturer an…\n$ last_edited_by   &lt;chr&gt; \"Pelagia Alethea Mordoch\", \"Pelagia Alethea Mordoch\",…\n$ last_edited_date &lt;dttm&gt; 2035-01-01, 2035-01-01, 2035-01-01, 2035-01-01, 2035…\n$ date_added       &lt;dttm&gt; 2035-01-01, 2035-01-01, 2035-01-01, 2035-01-01, 2035…\n$ raw_source       &lt;chr&gt; \"Existing Corporate Structure Data\", \"Existing Corpor…\n$ algorithm        &lt;chr&gt; \"Automatic Import\", \"Automatic Import\", \"Automatic Im…\n$ id               &lt;chr&gt; \"Abbott, Mcbride and Edwards\", \"Abbott-Gomez\", \"Abbot…\n$ dob              &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\n\n\n5.1.8 Selecting the columns\nSimilarly, we will select the relevant variables for our analysis:\n\nid - the unique identifier of the node and the name of the person or organisation\ntype - to identify either the person or company from the entity\ncountry - to identify country associated with the entity\nProductServices - list of products and services that the organization provides\nrevenue - the last reported annual revenue for the company in local currency; (all empty values have been set to 0)\n\n\n\nCode\nmc3_nodes &lt;- mc3_nodes_raw %&gt;%\n  select(id, type, country, ProductServices, revenue)\n\n\nTo help us better understand the multiple distinct types that are present under mc3_nodes the unique() function is used:\n\n\nCode\nmc3_nodes$type %&gt;% unique()\n\n\n[1] \"Entity.Organization.Company\"         \n[2] \"Entity.Organization.LogisticsCompany\"\n[3] \"Entity.Organization.FishingCompany\"  \n[4] \"Entity.Organization.FinancialCompany\"\n[5] \"Entity.Organization.NewsCompany\"     \n[6] \"Entity.Organization.NGO\"             \n[7] \"Entity.Person\"                       \n[8] \"Entity.Person.CEO\""
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex08/shp/Oceanus Geography.html",
    "href": "In-class_Ex/In-Class_Ex08/shp/Oceanus Geography.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#getting-started",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "4 Getting Started",
    "text": "4 Getting Started\n\n4.1 Installing and launching R packages\nIn the code chunk below, p_load() of pacman package is used to check if the following packages have been installed and also will load them into the working R environment.\nThe code chunk:\n\n\nCode\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, knitr,\n               graphlayouts, ggforce, tidyverse, tidytext, RColorBrewer,\n               skimr, DT, lubridate, plotly, clock, igraph)\n\n\n\n\n4.2 The Data\nIn the code chunk below, fromJSON() of jsonlite package is used to import MC3.json file into the R environment.\n\n\nCode\nmc3_data &lt;- fromJSON(\"data/MC3/mc3.json\")\n\n\nInitially, when trying to load the mc3.json data we faced an error message regarding a NaN issue.\n Hence we converted solely the NaN fields to “NaN” to curb this issue and the mc3.json file is imported successfully.\n\n\nCode\nclass(mc3_data)\n\n\n[1] \"list\"\n\n\nThe output is called mc3_data. It is a large list R object. There are two data frames. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\nCode\nmc3_edges &lt;- as_tibble(mc3_data$links) %&gt;% \n  unnest(source) %&gt;% \n  distinct() %&gt;% \n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type),\n         startdate = as_datetime(start_date)) %&gt;% \n  group_by(source, target, type, startdate) %&gt;% \n  summarise(weights = n()) %&gt;% \n  filter(source != target) %&gt;%\n  ungroup()\n\nhead(mc3_edges)\n\n\n# A tibble: 6 × 5\n  source                 target                type  startdate           weights\n  &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt; &lt;dttm&gt;                &lt;int&gt;\n1 4. SeaCargo Ges.m.b.H. Dry CreekRybachit Ma… Even… 2034-12-31 00:00:00       1\n2 4. SeaCargo Ges.m.b.H. KambalaSea Freight I… Even… 2033-04-12 00:00:00       1\n3 9. RiverLine CJSC      SumacAmerica Transpo… Even… 2028-12-02 00:00:00       1\n4 Aaron Acosta           Manning-Pratt         Even… 2008-09-14 00:00:00       1\n5 Aaron Acosta           Manning-Pratt         Even… 2008-07-30 00:00:00       1\n6 Aaron Allen            Hicks-Calderon        Even… 2025-03-06 00:00:00       1\n\n\n\n\nCode\nggplot(data = mc3_edges, aes(x = type)) +\n  geom_bar()\n\n\n\n\n\nFrom the type field, we can see that there are four types of edges with FamilyRelationship edges only having type attributes as stated in the VAST 2024 - MC3 Data Description.\n\n\nCode\n# extract all nodes from graph\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;% \n  mutate(country = as.character(country),\n         id = as.character(id),\n         revenue = as.numeric(as.character(revenue)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue)\n\n# extract all nodes from edges\nid1 &lt;- mc3_edges %&gt;%\n  select(source, type) %&gt;%\n  rename(id = source) %&gt;% \n  mutate(country = NA, revenue = NA) %&gt;% \n  select(id, country, type, revenue)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target, type) %&gt;%\n  rename(id = target) %&gt;% \n  mutate(country = NA, revenue = NA) %&gt;% \n  select(id, country, type, revenue)\n\nadditional_nodes &lt;- rbind(id1, id2) %&gt;% \n  distinct %&gt;% \n  filter(!id %in% mc3_nodes[[\"id\"]])\n\n# combine all nodes\nmc3_nodes_updated &lt;- rbind(mc3_nodes, additional_nodes) %&gt;%\n  distinct()\n\nhead(mc3_nodes_updated)\n\n\n# A tibble: 6 × 4\n  id                          country     type                        revenue\n  &lt;chr&gt;                       &lt;chr&gt;       &lt;chr&gt;                         &lt;dbl&gt;\n1 Abbott, Mcbride and Edwards Uziland     Entity.Organization.Company   5995.\n2 Abbott-Gomez                Mawalara    Entity.Organization.Company  71767.\n3 Abbott-Harrison             Uzifrica    Entity.Organization.Company      0 \n4 Abbott-Ibarra               Islavaragon Entity.Organization.Company      0 \n5 Abbott-Sullivan             Oceanus     Entity.Organization.Company   4747.\n6 Acevedo and Sons            Imazam      Entity.Organization.Company  46567.\n\n\n\n\nCode\nggplot(data = mc3_nodes_updated, aes(x = type)) +\n  geom_bar()\n\n\n\n\n\n\n\nCode\nmc3_nodes_updated[duplicated(mc3_nodes_updated$id),] %&gt;% \n  arrange(id)\n\n\n# A tibble: 0 × 4\n# ℹ 4 variables: id &lt;chr&gt;, country &lt;chr&gt;, type &lt;chr&gt;, revenue &lt;dbl&gt;\n\n\nNo Duplicates\n\n\nCode\nmc3_nodes_master &lt;- mc3_nodes_updated %&gt;% \n  group_by(id) %&gt;% \n  arrange(id, type, country) %&gt;% \n  summarise(countries = paste0(unique(country), collapse = \", \"),\n            num_countries = n_distinct(country),\n            types = paste0(unique(type), collapse = \", \"),\n            num_types = n_distinct(type),\n            revenue = sum(revenue))\n\n\n\n\nCode\n# form graph\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes_master,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;% \n  mutate(betweenness_centrality = centrality_betweenness())\n\n# extract node with highest betweenness centrality\ntop1_betw &lt;- mc3_graph %&gt;% \n  activate(nodes) %&gt;% \n  as_tibble() %&gt;% \n  top_n(1, betweenness_centrality) %&gt;% \n    select(id, countries, types)\n\n# extract lvl 1 edges\ntop1_betw_edges_lvl1 &lt;- mc3_edges %&gt;% \n  filter(source %in% top1_betw[[\"id\"]] | target %in% top1_betw[[\"id\"]])\n\n# extract nodes from lvl 1 edges\nid1 &lt;- top1_betw_edges_lvl1 %&gt;%\n  select(source) %&gt;%\n  rename(id = source) %&gt;% \n  left_join(mc3_nodes_master, by = \"id\") %&gt;% \n  select(id, countries, types)\n\nid2 &lt;- top1_betw_edges_lvl1 %&gt;%\n  select(target) %&gt;%\n  rename(id = target) %&gt;% \n  left_join(mc3_nodes_master, by = \"id\") %&gt;% \n  select(id, countries, types)\n\nadditional_nodes_lvl1 &lt;- rbind(id1, id2) %&gt;% \n  distinct %&gt;% \n  filter(!id %in% top1_betw[[\"id\"]])\n\n# extract lvl 2 edges\ntop1_betw_edges_lvl2 &lt;- mc3_edges %&gt;% \n  filter(source %in% additional_nodes_lvl1[[\"id\"]] | target %in% additional_nodes_lvl1[[\"id\"]])\n\n# extract nodes from lvl 1 edges\nid1 &lt;- top1_betw_edges_lvl2 %&gt;%\n  select(source) %&gt;%\n  rename(id = source) %&gt;% \n  left_join(mc3_nodes_master, by = \"id\") %&gt;% \n  select(id, countries, types)\n\nid2 &lt;- top1_betw_edges_lvl2 %&gt;%\n  select(target) %&gt;%\n  rename(id = target) %&gt;% \n  left_join(mc3_nodes_master, by = \"id\") %&gt;% \n  select(id, countries, types)\n\nadditional_nodes_lvl2 &lt;- rbind(id1, id2) %&gt;% \n  distinct %&gt;% \n  filter(!id %in% top1_betw[[\"id\"]] & !id %in% additional_nodes_lvl1[[\"id\"]])\n\n# combine all nodes\ntop1_betw_nodes &lt;- rbind(top1_betw, additional_nodes_lvl1, additional_nodes_lvl2) %&gt;%\n  distinct()\n\n# combine all edges\ntop1_betw_edges &lt;- rbind(top1_betw_edges_lvl1, top1_betw_edges_lvl2) %&gt;% \n  distinct()\n\n# colur palatte for betweenness centrality colours\nsw_colors &lt;- colorRampPalette(brewer.pal(3, \"RdBu\"))(3)\n\n# customise edges for plotting\ntop1_betw_edges &lt;- top1_betw_edges %&gt;% \n  rename(from = source,\n         to = target) %&gt;% \n  mutate(title = paste0(\"Type: \", type), # tooltip when hover over\n         color = \"#0085AF\") # color of edge\n\n# customise nodes for plotting\ntop1_betw_nodes &lt;- top1_betw_nodes %&gt;% \n  rename(group = types) %&gt;% \n  mutate(id.type = ifelse(id == top1_betw[[\"id\"]], sw_colors[1], sw_colors[2])) %&gt;%\n  mutate(title = paste0(id, \"&lt;br&gt;Group: \", group), # tooltip when hover over\n         size = 30, # set size of nodes\n         color.border = \"#013848\", # border colour of nodes\n         color.background = id.type, # background colour of nodes\n         color.highlight.background = \"#FF8000\" # background colour of nodes when highlighted\n         )\n\n# plot graph\nvisNetwork(top1_betw_nodes, top1_betw_edges,\n           height = \"500px\", width = \"100%\",\n           main = paste0(\"Network Graph of \", top1_betw[[\"id\"]])) %&gt;%\n  visIgraphLayout() %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NewsCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NewsCompany, Entity.Organization.NGO\", shape = \"triangle\") %&gt;%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = T, degree = 1, hover = T),\n             nodesIdSelection = TRUE) %&gt;% \n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nPerform analysis on largest components in the network:\n\n\nCode\n# form graph\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes_master,\n                       edges = mc3_edges,\n                       directed = FALSE)\n\n# find components in graph\nset.seed(123)\nclusters &lt;- components(mc3_graph)\n\n# update graph with component membership\nmc3_nodes_master &lt;- mc3_nodes_master %&gt;% \n  mutate(component_membership = clusters$membership)\n\n# extract info relating to components\ncomponent_df &lt;- clusters$csize %&gt;% \n  as_tibble() %&gt;% \n  rownames_to_column() %&gt;% \n  rename(component_membership = rowname,\n         component_size = value)\n\n# find components that are top 3 in size    \ntop_3_components &lt;- component_df %&gt;% \n  top_n(3, component_size) %&gt;% \n  arrange(desc(component_size))\n\ndatatable(top_3_components)\n\n\n\n\n\n\n\nNext, we will visualise the network charts of the three largest clusters separately using interactive charts below.\n\n\nCode\nvisualise_cluster &lt;- function(x){\n  \n# extract nodes in component\ncomponent_nodes &lt;- mc3_nodes_master %&gt;%\n  filter(component_membership == x)\n\n# extract edges in component\ncomponent_edges &lt;- mc3_edges %&gt;% \n  filter(source %in% component_nodes[[\"id\"]] | target %in% component_nodes[[\"id\"]])\n\n# compute centrality measures\ncomponent_graph &lt;- tbl_graph(nodes = component_nodes,\n                             edges = component_edges,\n                             directed = FALSE) %&gt;% \n  mutate(closeness_centrality = centrality_closeness(),\n         betweenness_centrality = centrality_betweenness(),\n         eigen_cetrality = centrality_eigen())\n\n# compute the top 90th percentile centrality\ncomponent_nodes_updated &lt;- component_graph %&gt;% \n  activate(nodes) %&gt;% \n  as_tibble()\n\ncent_per_90 &lt;- quantile(component_nodes_updated$betweenness_centrality,\n                               probs = 0.90)\n\ncomponent_nodes_updated &lt;- component_nodes_updated %&gt;% \n  mutate(is_top_cent_90 = ifelse(betweenness_centrality &gt;= cent_per_90, \"yes\", \"no\"))\n\n# colur palatte for betweenness centrality colours\nsw_colors &lt;- colorRampPalette(brewer.pal(3, \"RdBu\"))(3)\n\n# customise edges for plotting\ncomponent_edges &lt;- component_edges %&gt;% \n  rename(from = source,\n         to = target) %&gt;% \n  mutate(title = paste0(\"Type: \", type), # tooltip when hover over\n         color = \"#0085AF\") # color of edge\n\n# customise nodes for plotting\ncomponent_nodes_updated &lt;- component_nodes_updated %&gt;% \n  rename(group = types) %&gt;% \n  mutate(is_top_cent_90.type = ifelse(is_top_cent_90 == \"yes\", sw_colors[1], sw_colors[2])) %&gt;% \n  mutate(title = paste0(id, \"&lt;br&gt;Group: \", group), # tooltip when hover over\n         size = 40, # set size of nodes\n         color.border = \"#013848\", # border colour of nodes\n         color.background = is_top_cent_90.type, # background colour of nodes\n         color.highlight.background = \"#FF8000\" # background colour of nodes when highlighted\n         )\n\n# plot graph\nvisNetwork(component_nodes_updated, component_edges,\n           height = \"500px\", width = \"100%\",\n           main = paste0(\"Entities in Component \", x)) %&gt;%\n  visIgraphLayout() %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NewsCompany\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NewsCompany, Entity.Organization.NGO\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NewsCompany, Entity.Organization.NGO, Entity.Person\", shape = \"triangle\") %&gt;%\n  visGroups(groupname = \"Entity.Organization.Company, Entity.Organization.FishingCompany, Entity.Organization.LogisticsCompany, Entity.Organization.FinancialCompany, Entity.Organization.NewsCompany, Entity.Organization.NGO, Entity.Person, Entity.Person.CEO\", shape = \"triangle\") %&gt;%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = T, degree = 1, hover = T),\n             nodesIdSelection = TRUE) %&gt;% \n  visLayout(randomSeed = 123)\n\n}\n\nvisualise_cluster(1)\n\n\n\n\n\n\n\n\nCode\nvisualise_cluster(504)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hypothesis-and-methodology",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#hypothesis-and-methodology",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "3 Hypothesis and Methodology",
    "text": "3 Hypothesis and Methodology\nFor these questions, we would have to investigate the changes through time in multiple areas mainly:\n\nIndividual’s ownership and influence on a network for the first portion\nFollowing which, how the networks and companies changes as a result of the SouthSeafood Express Corp incident.\n\nTo achieve this we will attempt to create visualisations of network graphs and carrying out faceting to allow us to observe for patterns and trends and make our inferences.\n\n\n\n\n%%{\n  init: {\n    \"theme\": \"base\",\n    \"themeVariables\": {\n      \"primaryColor\": \"#d8e8e6\",\n      \"primaryTextColor\": \"#325985\",\n      \"primaryBorderColor\": \"#325985\",\n      \"lineColor\": \"#325985\",\n      \"secondaryColor\": \"#cedded\",\n      \"tertiaryColor\": \"#fff\" \n      }\n  }\n}%%\n\nflowchart LR\n    A[Person / CEO] --&gt;|Ownership\\n OR \\nInfluence| B(Organisation)\n    B ---&gt; C{Company}\n    B ---&gt; D{FishingCompany}\n    B ---&gt; E{LogisticsCompany}\n    B ---&gt; F{NewsCompany}\n    B ---&gt; G{FinancialCompany}\n    B ---&gt; H{NGO}\n\n\n\n\n\n\n\n\n\n%%{\n  init: {\n    \"theme\": \"base\",\n    \"themeVariables\": {\n      \"primaryColor\": \"#d8e8e6\",\n      \"primaryTextColor\": \"#325985\",\n      \"primaryBorderColor\": \"#325985\",\n      \"lineColor\": \"#325985\",\n      \"secondaryColor\": \"#cedded\",\n      \"tertiaryColor\": \"#fff\" \n      }\n  }\n}%%\n   \nflowchart LR\n  A[Companies] --&gt; |BENEFITED| B(SouthSeafood Express Corp)\n  C{Suspicious\\nTranscations}\n  C --&gt; A\n  C --&gt; E[Illegal Fishing]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#initial-data-exploration",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#initial-data-exploration",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "5 Initial Data Exploration",
    "text": "5 Initial Data Exploration\n\n5.1 Exploring the edges data frame\nIn the code chunk below, skim() of skimr package is used to display the summary statistics of mc3_edges_raw tibble data frame.\n\n\nCode\nskim(mc3_edges_raw)\n\n\n\nData summary\n\n\nName\nmc3_edges_raw\n\n\nNumber of rows\n75817\n\n\nNumber of columns\n14\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n9\n\n\nnumeric\n1\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntype\n0\n1.0\n14\n31\n0\n4\n0\n\n\nlast_edited_by\n0\n1.0\n14\n23\n0\n2\n0\n\n\nraw_source\n0\n1.0\n33\n38\n0\n13\n0\n\n\nalgorithm\n0\n1.0\n12\n16\n0\n2\n0\n\n\nsource\n0\n1.0\n6\n42\n0\n51996\n0\n\n\ntarget\n0\n1.0\n6\n48\n0\n8926\n0\n\n\nevent1\n0\n1.0\n5\n12\n0\n2\n0\n\n\nevent2\n0\n1.0\n4\n18\n0\n3\n0\n\n\nevent3\n14908\n0.8\n15\n19\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nkey\n0\n1\n0.21\n0.41\n0\n0\n0\n0\n2\n▇▁▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstart_date\n90\n1\n1952-05-31\n2035-12-29\n2023-12-12\n11468\n\n\nlast_edited_date\n0\n1\n2035-01-01\n2036-01-15\n2035-01-01\n13\n\n\ndate_added\n0\n1\n2035-01-01\n2036-01-15\n2035-01-01\n13\n\n\nend_date\n75469\n0\n2035-01-01\n2035-12-29\n2035-05-19\n73\n\n\n\n\n\n\n5.1.1 Selecting the columns\n\nsource - to identify the actor of the relationship, corresponds to id in nodes.\ntarget - to identify the receiver of the relationship, corresponds to id in nodes.\ntype - to identify the type of the relationship\nstart_date - to identify when the relationship started\nend_date - to identify when the relationship ended\n\n\n\nCode\n%%{\n  init: {\n    \"theme\": \"base\",\n    \"themeVariables\": {\n      \"primaryColor\": \"#d8e8e6\",\n      \"primaryTextColor\": \"#325985\",\n      \"primaryBorderColor\": \"#325985\",\n      \"lineColor\": \"#325985\",\n      \"secondaryColor\": \"#cedded\",\n      \"tertiaryColor\": \"#fff\" \n      }\n  }\n}%%\n\nflowchart LR\n    A[Company] --&gt;|Influence| B(Person)\n    B --&gt; C{Entity.Person}\n    B --&gt; D{Entity.Person.CEO}\n    D --&gt;|unique identifier & name| id\n    D --&gt;|person date of birth| dob\n    D --&gt;|country associated|country\n    C --&gt;|unique identifier & name| E(id)\n    C --&gt;|person date of birth| F(dob)\n    C --&gt;|country associated| G(country)\n\n\n\n\n%%{\n  init: {\n    \"theme\": \"base\",\n    \"themeVariables\": {\n      \"primaryColor\": \"#d8e8e6\",\n      \"primaryTextColor\": \"#325985\",\n      \"primaryBorderColor\": \"#325985\",\n      \"lineColor\": \"#325985\",\n      \"secondaryColor\": \"#cedded\",\n      \"tertiaryColor\": \"#fff\" \n      }\n  }\n}%%\n\nflowchart LR\n    A[Company] --&gt;|Influence| B(Person)\n    B --&gt; C{Entity.Person}\n    B --&gt; D{Entity.Person.CEO}\n    D --&gt;|unique identifier & name| id\n    D --&gt;|person date of birth| dob\n    D --&gt;|country associated|country\n    C --&gt;|unique identifier & name| E(id)\n    C --&gt;|person date of birth| F(dob)\n    C --&gt;|country associated| G(country)\n\n\n\n\n\n\n\nCode\nflowchart LR\n  A[Hard edge] --&gt; |TESTING| B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; |TESTING| B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#preparing-network-objects-to-build-the-graph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#preparing-network-objects-to-build-the-graph",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "6 Preparing network objects to build the graph",
    "text": "6 Preparing network objects to build the graph\n\nEdgesNodes\n\n\nThe code chunk below will be used to perform the changes to further reformat mc3_edges data frame\n\n\nCode\nmc3_edges_aggregated &lt;- mc3_edges %&gt;%\n  rename(from = source, to = target, ) %&gt;%\n  mutate(\n    status = ifelse(\n      grepl(\"Event.Owns\", type),\n      \"Ownership\",\n      ifelse(grepl(\"Relationship\", type), \"Relationship\", \"Employment\")\n    ),\n    subtype = strsplit(type, \".\", fixed = TRUE) %&gt;% sapply(tail, n = 1),\n    StartDate = date(start_date),\n    Month = month(start_date, label = TRUE),\n    Year = year(start_date)\n  ) %&gt;%\n  filter(from != to) %&gt;%\n  group_by(from, to, status, subtype, StartDate, Month, Year) %&gt;%\n  summarize(weight = n())\n\nkable(head(mc3_edges_aggregated))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom\nto\nstatus\nsubtype\nStartDate\nMonth\nYear\nweight\n\n\n\n\n4. SeaCargo Ges.m.b.H.\nDry CreekRybachit Marine A/S\nOwnership\nShareholdership\n2034-12-31\nDec\n2034\n1\n\n\n4. SeaCargo Ges.m.b.H.\nKambalaSea Freight Inc\nOwnership\nShareholdership\n2033-04-12\nApr\n2033\n1\n\n\n9. RiverLine CJSC\nSumacAmerica Transport GmbH & Co. KG\nOwnership\nShareholdership\n2028-12-02\nDec\n2028\n1\n\n\nAaron Acosta\nManning-Pratt\nEmployment\nWorksFor\n2008-07-30\nJul\n2008\n1\n\n\nAaron Acosta\nManning-Pratt\nOwnership\nShareholdership\n2008-09-14\nSep\n2008\n1\n\n\nAaron Allen\nHicks-Calderon\nOwnership\nBeneficialOwnership\n2025-03-06\nMar\n2025\n1\n\n\n\n\n\nNext, summarise() function will be used to confirm if type has been mapped correctly.\n\n\nCode\nmc3_edges_aggregated %&gt;%\n  group_by(status, subtype) %&gt;%\n  summarize(count = n()) %&gt;%\n  kable()\n\n\n\n\n\nstatus\nsubtype\ncount\n\n\n\n\nEmployment\nWorksFor\n14817\n\n\nOwnership\nBeneficialOwnership\n21529\n\n\nOwnership\nShareholdership\n39378\n\n\nRelationship\nFamilyRelationship\n91\n\n\n\n\n\n\n\nThe code chunk below will be used to perform the changes to further reformat mc3_nodes data frame\n\n\nCode\nmc3_nodes_aggregated &lt;- mc3_nodes %&gt;%\n  mutate(\n    name = id,\n    status = strsplit(type, \".\", fixed=TRUE) %&gt;% sapply('[', 2),\n    # Get the last type as status. In the case of Entity.Person,\n    # both status and subtype are \"Person\".\n    subtype = strsplit(type, \".\", fixed=TRUE) %&gt;% sapply(tail, n=1),\n    country = as.character(country),\n    product_services = as.character(ProductServices),\n    revenue = as.numeric(as.character(revenue))\n  ) %&gt;%\n  select(name, status, subtype, country, product_services, revenue)\n\nkable(head(mc3_nodes_aggregated))\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nstatus\nsubtype\ncountry\nproduct_services\nrevenue\n\n\n\n\nAbbott, Mcbride and Edwards\nOrganization\nCompany\nUziland\nUnknown\n5994.73\n\n\nAbbott-Gomez\nOrganization\nCompany\nMawalara\nFurniture and home accessories\n71766.67\n\n\nAbbott-Harrison\nOrganization\nCompany\nUzifrica\nFood products\n0.00\n\n\nAbbott-Ibarra\nOrganization\nCompany\nIslavaragon\nUnknown\n0.00\n\n\nAbbott-Sullivan\nOrganization\nCompany\nOceanus\nUnknown\n4746.67\n\n\nAcevedo and Sons\nOrganization\nCompany\nImazam\nFish, crustaceans and molluscs\n46566.67\n\n\n\n\n\nNext, summarise() function will be used to confirm if type has been mapped correctly.\n\n\nCode\nmc3_nodes_aggregated %&gt;%\n  group_by(status, subtype) %&gt;%\n  summarize(count = n()) %&gt;%\n  kable()\n\n\n\n\n\nstatus\nsubtype\ncount\n\n\n\n\nOrganization\nCompany\n7927\n\n\nOrganization\nFinancialCompany\n23\n\n\nOrganization\nFishingCompany\n600\n\n\nOrganization\nLogisticsCompany\n311\n\n\nOrganization\nNGO\n5\n\n\nOrganization\nNewsCompany\n5\n\n\nPerson\nCEO\n1293\n\n\nPerson\nPerson\n50356"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-network-model-with-tidygraph",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#building-network-model-with-tidygraph",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "7 Building network model with tidygraph",
    "text": "7 Building network model with tidygraph\n\n7.1 To construct the graph model using tbl_graph object"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#vast-challenge-mini-challenge-3",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#vast-challenge-mini-challenge-3",
    "title": "Take-home Exercise 3: Network Data Visualisation and Analysis",
    "section": "",
    "text": "Oceanus has a dynamic business landscape with frequent startups, mergers, acquisitions and investments. FishEye International, a non-profit organization that focuses on illegal fishing monitors commercial fishing operators to prevent illegal fishing in the region’s sensitive marine ecosystem. Analysts use a hybrid automated/manual process to transform company records into CatchNet: the Oceanus Knowledge Graph.\nLast year, SouthSeafood Express Corp was caught fishing illegally, disrupting the commercial fishing sector. FishEye aims to analyse the temporal patterns and impacts of this incident on the fishing market. The competitive nature of the market might lead some businesses attempting to seize SouthSeafood’s market share, while others may recognize the consequences of illegal fishing."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "",
    "text": "For this hands-on exercise, it will allow us to gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#overview",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "",
    "text": "For this hands-on exercise, it will allow us to gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#getting-started",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading packages\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. This data set is a polygon feature data.frame providing information on water point of Nigeria at the local government areas (LGA) level. The data set can be found in the rds sub-direct of the hands-on data folder.\n\nNGA_WP &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "3 Basic Choropleth Mapping",
    "text": "3 Basic Choropleth Mapping\n\n3.1 Visualising distribution of functional water points\nThe code chunk below is used to plot a choropleth map showing the distribution of non-function water point by LGA\n\np1 &lt;- tm_shape(NGA_WP) +\n  tm_fill(\"wp_functional\",\n           n = 10,\n           style = \"equal\",\n           palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water points by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_WP) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water points by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "4 Choropleth Map for Rates",
    "text": "4 Choropleth Map for Rates\nIn much of our readings, we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_WP &lt;- NGA_WP %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n4.2 Plotting map of rate\nThe code chunk below plots a choropleth map showing the distribution of percentage functional water point by LGA\n\ntm_shape(NGA_WP) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water points by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08c.html#extreme-value-maps",
    "title": "Hands-on Exercise 8c: Analytical Mapping",
    "section": "5 Extreme Value Maps",
    "text": "5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the beginning and end points need to be included.\n\n5.1.1 Data Preparation\n\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nNGA_WP &lt;- NGA_WP %&gt;%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_WP[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from a sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behaviour, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\n5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update the code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname, df) {\n  v &lt;- df[vname] %&gt;%\n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle = NA, mtitle = \"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title = legtitle,\n             breaks = bperc,\n             palette = \"Blues\",\n          labels = c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\", \"bottom\"))\n}\n\n\n\n5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_WP)\n\n\n\n\n\n\n\n5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_WP,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creates break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v, mult = 1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialise break points vector\n  bb &lt;- vector(mode = \"numeric\", length = 7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) {  # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n  }\n\n\n\n5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname, df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n5.2.3 Test drive the newly created function\nThe code chunk below is used to test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_WP)\nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df,\n                   legtitle = NA,\n                   mtitle = \"Box Map\",\n                   mult = 1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n    tm_fill(vnam, title = legtitle,\n            breaks = bb,\n            palette = \"Blues\",\n         labels = c(\"lower outlier\",\n                    \"&lt; 25%\",\n                    \"25% - 50%\",\n                    \"50% - 75%\",\n                    \"&gt; 75%\",\n                    \"upper outlier\")) +\n    tm_borders() +\n    tm_layout(main.title = mtitle,\n              title.position = c(\"left\",\n                                 \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_WP)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, we should have acquired the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly created simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#overview",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, we should have acquired the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly created simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#getting-started",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "3 Geospatial Data Wrangling",
    "text": "3 Geospatial Data Wrangling\n\n3.1 The Data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 17 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n3.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows how list() function is used to do the job.\n\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n3.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nsgpools_sf &lt;- st_as_sf(sgpools,\n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs = 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n You can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "4 Drawing Proportional Symbol Map",
    "text": "4 Drawing Proportional Symbol Map\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code chunk below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n4.1 Starting with an interactive point symbol map\nThe code chunk below is used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n4.2 Making the map proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n4.3 Giving a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"OUTLET TYPE\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n4.4 Twinning Multiple Maps (I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\ntm_bubbles(col = \"OUTLET TYPE\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1) +\n  tm_facets(by = \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBefore ending the session/exercise, it is advisable to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08b.html#references",
    "title": "Hands-on Exercise 8b: Visualising Geospatial Point Data",
    "section": "5 References",
    "text": "5 References\n\n5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-Class_Ex08/In-class_Ex08.html",
    "title": "In-class Exercise 8",
    "section": "",
    "text": "REALIS Data Dashboard\nSGPools_svy21: Svy21_ProjectedCoordianteSystem aspatial data exploration\nSGPools_wgs84 Choropleth Map -"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex08/In-class_Ex08.html#links-to-tableau-visualisations",
    "href": "In-class_Ex/In-Class_Ex08/In-class_Ex08.html#links-to-tableau-visualisations",
    "title": "In-class Exercise 8",
    "section": "",
    "text": "REALIS Data Dashboard\nSGPools_svy21: Svy21_ProjectedCoordianteSystem aspatial data exploration\nSGPools_wgs84 Choropleth Map -"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html",
    "title": "Hands-on Exercise 9a: Creating Ternary Plot with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, we will learn how to build ternary plots programmatically using R for visualising and analysing the population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#overview",
    "title": "Hands-on Exercise 9a: Creating Ternary Plot with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, we will learn how to build ternary plots programmatically using R for visualising and analysing the population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9a: Creating Ternary Plot with R",
    "section": "2 Installing and launching R packages",
    "text": "2 Installing and launching R packages\nFor this exercise, two main R packages will be used and they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R library contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#data-preparation",
    "title": "Hands-on Exercise 9a: Creating Ternary Plot with R",
    "section": "3 Data Preparation",
    "text": "3 Data Preparation\n\n3.1 The Data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n3.2 Importing the Data\nTo import the data respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n# Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\n\n\n\n3.3 Preparing the Data\nNext, using the mutate() function of dplyr package to derive three new measures, namely: young, economy active, and old.\n\n# Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year)) %&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;%\n  mutate(ACTIVE = rowSums(.[9:16])) %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018) %&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 9a: Creating Ternary Plot with R",
    "section": "4 Plotting Ternary Diagram with R",
    "text": "4 Plotting Ternary Diagram with R\n\n4.1 Plotting a static ternary diagram\nUsing ggtern() function of ggtern package to create a simple ternary plot.\n\n# Buildign a static ternary plot\nggtern(data = agpop_mutated, aes(x= YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point()\n\n\n\n\n\n# Building on the static ternary plot\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point() +\n  labs(title = \"Population Structure 2018\") +\n  theme_rgbw()\n\n\n\n\n\n\n4.2 Plotting an interactive ternary diagram\nThe code below creates an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating an annotation object\n\nlabel &lt;- function(txt) {\n  list(\n    text = txt,\n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\" , yref = \"paper\",\n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10) \n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"),\n  baxis = axis(\"Active\"),\n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualisation\n\nplot_ly(\n  agpop_mutated,\n  a = ~YOUNG,\n  b = ~ACTIVE,\n  c = ~OLD,\n  color = I(\"black\"),\n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"),\n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that is used to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficients of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix:\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tends to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, we will learn how to create correlation matrix using pairs() of R Graphics. Next, we will learn how to plot corrgram using corrplot package of R. Lastly, we will learn how to create an interactive correlation matrix using Plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#overview",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that is used to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficients of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix:\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tends to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, we will learn how to create correlation matrix using pairs() of R Graphics. Next, we will learn how to plot corrgram using corrplot package of R. Lastly, we will learn how to create an interactive correlation matrix using Plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "2 Installing and Launching R Packages",
    "text": "2 Installing and Launching R Packages\nThe code chunk below is used to install and launch corrplot, ggpubr, plotly and tidyverse in R Studio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#importing-and-preparing-the-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#importing-and-preparing-the-dataset",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "3 Importing and Preparing the Dataset",
    "text": "3 Importing and Preparing the Dataset\nIn this hands-on exercise, the Wine Quality Data Set from UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, the red wine and white wine data have been combined into one data file. It is called wine_quality and is in csv file format.\n\n3.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\n Notice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "4 Building Correlation Matrix: pairs() method",
    "text": "4 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, we will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore continuing to the next step, it is advisable to read the syntax description of pairsfunction.\n\n4.1 Building a basic correlation matrix\nThe code chunk and figure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n4.2 Drawing the lower corner\npairs function of R Graphics provides many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chunk below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nWe do not have to worry about the details for now. We can just type this code into the R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x , y, digits = 2, prefix = \"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use = \"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits = digits)[1]\ntxt &lt;- paste(prefix, txt, sep = \"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12],\n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "5 Visualising Correlation Matrix: ggcormat()",
    "text": "5 Visualising Correlation Matrix: ggcormat()\nOne of the major limitations of the correlation matrix is that the scatter plots appear very cluttered when the number of observations are relatively large (i.e. more than 500 observations). To overcome this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThere are at least three R packages which provide functions to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R packages like ggstatsplot package also provides functions for building corrgram.\nIn this section, we will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n5.1 The basic plot\nOne of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11)\n\n\n\n\nCode chunk below includes elements such as Title & Subtitle in the report\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title = \"Correlogram for Wine dataset\",\n  subtitle = \"Four pairs are not significant with p-value &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provides additional (mostly aesthetic) arguments that will be passed to ggstatsplot::ggcorrmat function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk shown below can be used to control specific components of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\n\n\nggplot.component = list(\n    theme(text = element_text(size = 5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#building-multiple-plots",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "6 Building multiple plots",
    "text": "6 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\",\n                       hc.order = TRUE,\n                       tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "7 Visualising Correlation Matrix using corrplot Package",
    "text": "7 Visualising Correlation Matrix using corrplot Package\nIn this hands-on exercise, we will focus on corrplot. However, it is encouraged to explore the other two packages too.\nBefore getting started, we are required to read An Introduction to corrplot Package in order to gain a basic understanding of corrplot package.\n\n7.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of the wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the default visual object used to plot the corrgram is a circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\n\n7.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter methods) that can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, colour and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\nEllipseShadeColourPie\n\n\n\ncorrplot(wine.cor,\n         method = \"ellipse\")\n\n\n\n\n\n\n\ncorrplot(wine.cor,\n         method = \"shade\")\n\n\n\n\n\n\n\ncorrplot(wine.cor,\n         method = \"color\")\n\n\n\n\n\n\n\ncorrplot(wine.cor,\n         method = \"pie\")\n\n\n\n\n\n\n\nShown above are a few different geometrics. Feel free to change the method argument to other supported visual geometrics.\n\n\n7.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\")\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nDo feel free to experiment with other layout design argument such as: tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\ntl.poscl.cex\n\n\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.pos = \"lt\")\n\n\n\n\n\n\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         diag = FALSE,\n         cl.cex = 0.9)\n\n\n\n\n\n\n\n\n\n7.4 Working with mixed layout\nWith corrplot package, it is also possible to design corrgram with mixed visual matrix on one half and aa numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram is shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nNotice that arguments lower and upper are used to define the visualisation method used. In this case, ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other hand, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of the variables for their correlation coefficients are statistically significant.\nImage below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example, the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level = .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hidden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-written by using the order argument of corrplot(). Currently, corrplot package supports four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order = \"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n7.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() we can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order = \"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#references",
    "title": "Hands-on Exercise 9b: Visual Correlation Analysis",
    "section": "8 References",
    "text": "8 References\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.\n\n8.1 R Packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html",
    "title": "Hands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rows and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will gain hands-on experience on using R to plot static and interactive heatmaps for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#overview",
    "title": "Hands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rows and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will gain hands-on experience on using R to plot static and interactive heatmaps for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "2 Installing and Launching R Packages",
    "text": "2 Installing and Launching R Packages\nBefore getting started, we are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, we will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "3 Importing and Preparing The Data Set",
    "text": "3 Importing and Preparing The Data Set\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloadeded from the following source here. The original data set is in Microsoft Excel format. It has been extracted and saved as csv file format called WHData-2018.csv.\n\n3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is labelled as wh.\n\n\n3.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country’s name.\n\n\n\n3.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to form our heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#static-heatmap",
    "title": "Hands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "4 Static Heatmap",
    "text": "4 Static Heatmap\nThere are many R packages and functions which can be used to draw static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, we will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv = NA, Colv = NA)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\n\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compared to the native wh_matrix. This is because heatmap does a reordering using clusterisation: it calculates the distance between each pair of rows and columns and attempts to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale = \"column\",\n                      cexRow = 0.6,\n                      celCol = 0.8,\n                      margins = c(10,4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#creating-an-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09c.html#creating-an-interactive-heatmap",
    "title": "Hands-on Exercise 9c: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5 Creating an Interactive Heatmap",
    "text": "5 Creating an Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manual of the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n5.1 Working with heatmaply\nThe mtcars dataset is a built-in dataset in R from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973-74 models).\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create an interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the right hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the left hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degrees from the north.\n\n\n\n5.2 Data transformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation is commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n5.2.1 Scaling method\n\nWhen all variables are coming from or assumed to have come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columnwise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n5.2.2 Normalising method\n\nWhen variables in the data come from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n5.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n5.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = (\"ward.D\"))\n\n\n\n\n\n\n\n5.5 Statistical approach\nIn order to determine the best clustering method and number of clusters, the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the highest optimum value.\nNext, find_k() is used to determine the optimal number of clusters.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n5.7 Working with colour palettes\nThe default colour palette used by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette alongside other palettes of rColorBrewer is used\n\nBluesPurplesGreens\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n                    seriate = \"none\",\n                    colors = Blues)\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n                    seriate = \"none\",\n                    colors = Purples)\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n                    seriate = \"none\",\n                    colors = Greens)\n\n\n\n\n\n\n\n\n\n\n5.8 The finishing touch(es)\nBesides providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n                    Colv = NA,\n                    seriate = \"none\",\n                    colors = Blues,\n                    k_row = 5,\n                    margins = c(NA, 200, 60, NA),\n                    fontsize_col = 5,\n                    fontsize_row = 6,\n                    main = \"World Happiness Score and Variables by Country, 2018 \\nData Transformation using Normalize Method\",\n                    xlab = \"World Happiness Indicators\",\n                    ylab = \"World Countries\"\n                    )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contributing to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations.\nAs pointed out by Stephen Few (2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, we should gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#overview",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contributing to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations.\nAs pointed out by Stephen Few (2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, we should gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "2 Installing and Launching R Packages",
    "text": "2 Installing and Launching R Packages\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunk below is used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#data-preparation",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "3 Data Preparation",
    "text": "3 Data Preparation\nIn this hands-on exercise, the World Happiness 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is downloaded from: https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "4 Plotting Static Parallel Coordinates Plot",
    "text": "4 Plotting Static Parallel Coordinates Plot\nIn this section, we will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh,\n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns are used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, we will learn how to do a makeover of the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE,\n           title = \"Parallel Coordinates Plot of World Happiness Variables\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scales each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\n\n4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can use a combination for some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represents one geographical region such as East Asia.\n\nggparcoord(data = wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE,\n           title = \"Multiple Parallel Coordinates Plots of World Happiness Variables by Region\") +\nfacet_wrap(~ Region)\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n4.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE,\n           title = \"Multiple Parallel Coordinates Plots of World Happiness Variables by Region\") +\nfacet_wrap(~ Region) +\ntheme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degrees.\n\n\n\n\n4.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#things-to-learn-from-the-code-chunk-above",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#things-to-learn-from-the-code-chunk-above",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5 Things to learn from the code chunk above",
    "text": "5 Things to learn from the code chunk above\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scales each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#things-to-learn-from-the-code-chunk-above-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#things-to-learn-from-the-code-chunk-above-1",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5 Things to learn from the code chunk above",
    "text": "5 Things to learn from the code chunk above\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degrees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js.\nIn this section, we will learn how to use functions provided in parallelPlot package to build an interactive parallel coordinates plot.\n\n5.1 The basic plot\nThe code chunk below plots an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. We will learn how to overcome this problem in the next section.\n\n\n5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive features of parallelPlot is that we can click on a variable of interest, for example Happiness score and the monotonous blue colour (default) will change to a blues with different intensity colour scheme being used.\n\n\n5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot a histogram along the axis of each variable.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09d.html#references",
    "title": "Hands-on Exercise 9d: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "6 References",
    "text": "6 References\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main sections. Firstly, we will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, we will learn how to plot static treemap by using treemap package. In the third section, we will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#overview",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main sections. Firstly, we will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, we will learn how to plot static treemap by using treemap package. In the third section, we will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "2 Installing and Launching R Packages",
    "text": "2 Installing and Launching R Packages\nBefore we get started, we are required to check if treemap and tidyverse packages have been installed in our R environment.\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#data-wrangling",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "3 Data Wrangling",
    "text": "3 Data Wrangling\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal of Urban Redevelopment Authority (URA).\n\n3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n3.2 Data Wrangling and Manipulation\nThe data.frame realis2018 is in transaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When we then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nLearners who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n\n3.3 Grouped summaries without the Pipe\nThe code chunk below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`,\n                                `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped,\n                                    `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                                    `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                                    `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm =  TRUE),\n                                    `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though it is not primarily important.\n\n\n3.4 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;%\n  group_by(`Project Name`, `Planning Region`,\n           `Planning Area`, `Property Type`,\n            `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "4 Designing Treemap with treemap Package",
    "text": "4 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n4.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2018.\nFirst, we will select records belonging to resale condominium property type from realis2018_summarised data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n4.2 Using the basic arguments\nThe code chunk below designs a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s values will be used to map the sizes of the rectangles of the treemaps.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensities showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determine the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\n\n4.3 Working with vColor and type arguments\nIn the code chunk below, type argument is defined as value.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\n\n\n\nThe rectangles are coloured with different intensities of green, reflecting their respective median unit prices.\n\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\n\n4.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” treemap is the default value for mapping.\nThe “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color.\nThe “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n4.5 The “value” type treemap\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"value\",\n        palette = \"RdYlBu\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\n\n4.6 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"RdYlBu\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe colour scheme used is very confusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\n\n\nTo overcome this problem, a single colour palette such as Blues should be used instead.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Blues\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n4.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n4.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Blues\",\n        algorithm = \"squarified\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n4.9 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to determine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Blues\",\n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title = \"Resale Condominium by Planning Region and Area, 2018\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "5 Designing Treemap using treemapify Package",
    "text": "5 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, we will learn how to design treemps closely resembling treemaps designed in previous section by using treemapify. Before getting started, it is recommended to read Introduction to “treemapify” its user guide.2\n\n5.1 Designing a basic treemap\n\nggplot(data = realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") +\n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n5.2 Defining hierarchy\nDesigning treemap with Group by Planning Region\n\nggplot(data = realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") +\n  geom_treemap()\n\n\n\n\nGroup by Planning Area\n\nggplot(data = realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +\n  geom_treemap()\n\n\n\n\nAdding boundary line\n\nggplot(data = realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +\n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"grey40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09e.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 9e: Treemap Visualisation with R",
    "section": "6 Designing Interactive Treemap using d3treeR",
    "text": "6 Designing Interactive Treemap using d3treeR\n\n6.1 Installing d3treeR package\nThis slide shows how to install a R package which is not available in cran.\n\nIf this is the first time installing a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ninstall.packages(\"devtools\")\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package\n\n\nlibrary(d3treeR)\n\n\n\n6.2 Designing An Interactive Treemap\nThe codes below performs two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is saved as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n              index = c(\"Planning Region\", \"Planning Area\"),\n              vSize = \"Total Unit Sold\",\n              vColor = \"Median Unit Price ($ psm)\",\n              type = \"value\",\n              title = \"Private Residential Property Sold, 2018\",\n              title.legend = \"Median Unit Price (S$ per sq. m)\"\n              )\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm, rootname = \"Singapore\")"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#loading-and-installing-the-r-packages",
    "href": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#loading-and-installing-the-r-packages",
    "title": "In-class Exercise 09",
    "section": "Loading and Installing the R Packages",
    "text": "Loading and Installing the R Packages\n\npacman::p_load(scatterPlotMatrix,\nparallelPlot, cluster, factoextra,\ntidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#loading-the-data-wine_quality-dataset",
    "href": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#loading-the-data-wine_quality-dataset",
    "title": "In-class Exercise 09",
    "section": "Loading the data (Wine_quality dataset)",
    "text": "Loading the data (Wine_quality dataset)\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#eda",
    "href": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#eda",
    "title": "In-class Exercise 09",
    "section": "EDA",
    "text": "EDA\n\nggplot(data = wine,\n       aes(x = type)) +\n  geom_bar()"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#filtering-out-white-wine",
    "href": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#filtering-out-white-wine",
    "title": "In-class Exercise 09",
    "section": "Filtering out white wine",
    "text": "Filtering out white wine\n\nwhitewine &lt;- wine %&gt;%\n  filter(type == \"white\") %&gt;%\n  select(c(1:11))  # Dropped last 2 variables: quality of wine and wine type - to tidy up data.frame"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#forming-interactive-scatter-plot-matrix",
    "href": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#forming-interactive-scatter-plot-matrix",
    "title": "In-class Exercise 09",
    "section": "Forming Interactive Scatter Plot Matrix",
    "text": "Forming Interactive Scatter Plot Matrix\n\nscatterPlotMatrix(whitewine,\n                  corrPlotType = \"Text\",\n                  distribType = 1,\n                  rotateTitle = TRUE,\n                  width = 500, # when using this function/library (html widgets) the widget is a container by itself hence stating the width and height to define the container itself. (Display pixel)\n                  height = 500)\n\n\n\n\n\nHovering to a point in the scatter plot we can see the corresponding data for other variables. It is helpful in the sense that if there are multiple outliers, it can help us detect anomalies.\nExplanation of functions and usage:\ncorrPlotType - Controls the type of correlation plots to use (4 types: Circles, Text, AbsText, Empty)\ndistribType - Binary code indicating the type of distribution plot (bit 1: density plot, bit 2: histogram)\ncontinousCS - For various colour schemes\nhttps://cran.r-project.org/web/packages/scatterPlotMatrix/scatterPlotMatrix.pdf\nNote:\nIf axis titles are overlapping we can also use use rotateTitle"
  },
  {
    "objectID": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#computing-cluster-analysis-to-dervie-clusters",
    "href": "In-class_Ex/In-Class_Ex09/In-class_Ex09.html#computing-cluster-analysis-to-dervie-clusters",
    "title": "In-class Exercise 09",
    "section": "Computing cluster analysis (to dervie clusters)",
    "text": "Computing cluster analysis (to dervie clusters)\n\n# fviz_gap_stat()# code used to determine optimal clusters\n\n\nset.seed(123) # seed value requried to make sure it is reproducible \nkmeans4 &lt;- kmeans(whitewine, 4, nstart = 25) # nstart = 25, typical clustering algorithim \nprint(kmeans4)\n\nK-means clustering with 4 clusters of sizes 757, 978, 1444, 1719\n\nCluster means:\n  fixed acidity volatile acidity citric acid residual sugar  chlorides\n1      6.981506        0.2965786   0.3563540       9.705878 0.05227081\n2      6.805112        0.2759356   0.3168814       3.607822 0.04012781\n3      6.908172        0.2776939   0.3455402       7.780852 0.04919668\n4      6.782403        0.2719372   0.3247469       5.348342 0.04324549\n  free sulfur dioxide total sulfur dioxide   density       pH sulphates\n1            52.83421             206.8164 0.9965522 3.176975 0.5179392\n2            20.52761              83.1411 0.9919192 3.175256 0.4707566\n3            42.31129             160.3061 0.9951215 3.193996 0.4940651\n4            30.11635             121.1963 0.9931958 3.195829 0.4847935\n    alcohol\n1  9.611471\n2 11.233930\n3 10.120392\n4 10.833256\n\nClustering vector:\n   [1] 3 4 2 1 1 2 4 3 4 4 2 4 2 3 3 4 2 2 3 4 2 2 4 3 4 1 3 4 4 4 4 2 2 4 3 4 3\n  [38] 4 3 3 3 3 3 3 3 3 1 1 3 3 3 4 2 4 4 1 1 3 2 4 4 3 3 2 4 4 4 3 2 4 1 1 1 2\n  [75] 2 4 2 2 4 4 4 3 3 1 3 3 3 1 3 3 3 1 4 4 3 1 3 2 2 3 1 3 3 3 1 4 3 3 3 1 3\n [112] 1 1 3 3 2 4 2 1 1 2 4 4 4 3 3 4 1 3 3 2 1 1 1 1 3 4 3 2 2 2 3 4 2 2 4 3 2\n [149] 2 4 3 3 4 2 2 1 1 4 4 4 4 3 2 1 1 3 1 2 3 4 4 2 2 4 3 3 2 3 4 3 3 1 3 1 1\n [186] 1 3 4 4 1 1 3 4 4 1 1 1 1 1 1 1 1 1 4 4 3 4 4 2 3 2 4 4 4 4 3 3 3 3 3 3 3\n [223] 4 3 4 3 1 1 1 3 4 1 1 1 1 1 1 1 4 3 1 2 2 1 3 1 4 2 2 4 1 1 3 4 3 3 2 2 4\n [260] 2 4 3 2 1 3 3 3 3 3 3 3 3 3 4 1 3 3 2 2 4 4 4 1 1 1 3 1 1 1 1 1 3 1 3 3 3\n [297] 3 1 3 4 2 2 2 3 3 3 3 3 4 3 2 3 3 3 3 4 4 4 4 2 2 4 4 4 1 1 1 3 1 2 4 4 2\n [334] 4 2 2 4 3 4 3 3 4 4 3 3 4 2 3 4 3 3 4 4 4 1 1 1 3 3 3 3 2 4 1 2 4 3 3 3 2\n [371] 3 3 1 3 2 2 4 2 3 4 2 3 3 3 4 2 4 1 4 1 1 2 4 2 3 3 2 4 3 2 4 3 4 1 3 3 4\n [408] 4 4 2 3 3 2 2 3 3 2 1 2 4 4 1 1 1 3 1 1 1 2 1 1 2 1 3 4 2 1 1 1 4 2 4 4 1\n [445] 3 2 3 4 4 4 3 4 3 4 4 4 2 4 1 1 4 3 3 2 3 4 3 2 3 1 3 1 2 4 4 1 4 4 3 3 3\n [482] 4 4 3 1 4 4 2 3 3 2 2 3 3 4 3 1 3 3 1 1 3 1 1 3 3 4 3 3 3 3 3 4 2 4 3 3 3\n [519] 2 2 4 4 2 2 2 4 2 4 4 4 4 3 3 3 3 3 3 3 2 1 3 1 3 3 3 3 3 2 4 1 3 2 4 3 4\n [556] 2 3 4 3 3 3 4 3 4 3 2 2 3 3 3 1 4 3 3 4 1 1 3 4 4 1 4 3 2 4 2 3 4 4 4 4 4\n [593] 3 4 4 4 3 4 4 2 3 4 4 4 4 4 3 3 3 2 4 2 4 4 4 4 2 1 1 4 1 3 4 2 4 4 3 1 1\n [630] 2 3 3 4 1 3 4 4 3 1 1 4 1 1 3 3 3 3 3 1 1 1 1 1 4 3 4 2 4 1 1 2 4 3 2 3 4\n [667] 1 3 3 1 1 2 3 4 1 1 1 2 2 2 3 3 3 3 3 1 4 1 1 4 4 1 1 3 1 1 2 1 1 1 1 4 2\n [704] 4 4 2 1 3 4 2 3 4 4 1 1 3 1 3 3 4 3 3 4 2 4 4 4 2 3 3 4 1 2 3 1 4 3 1 3 4\n [741] 2 2 4 3 3 4 1 3 3 3 3 3 3 1 4 4 3 3 3 4 3 3 1 4 3 4 1 2 4 4 4 3 3 3 4 4 2\n [778] 1 3 3 2 1 3 3 1 4 4 4 4 4 4 2 3 2 3 3 1 3 4 2 3 1 1 3 4 3 1 1 1 1 1 4 3 3\n [815] 1 4 2 4 4 4 2 1 4 4 2 3 3 4 2 2 4 3 4 2 4 4 3 3 3 4 4 3 3 4 4 4 3 2 3 4 4\n [852] 3 4 3 4 4 3 3 3 3 4 1 3 4 3 4 4 3 3 2 3 3 4 2 2 4 4 4 4 4 4 4 4 4 1 4 3 2\n [889] 3 2 3 4 4 4 4 2 1 2 2 1 3 4 1 1 3 2 2 4 3 1 4 4 4 2 2 2 4 4 4 4 3 3 3 1 3\n [926] 2 2 3 3 4 2 1 1 1 1 1 2 4 1 1 1 1 2 4 4 4 1 3 2 2 4 4 2 4 4 4 4 2 2 3 3 4\n [963] 3 4 3 2 1 3 2 2 2 4 3 2 4 4 4 1 3 2 2 3 2 2 3 4 3 3 3 4 3 2 1 2 3 3 2 3 3\n[1000] 3 2 1 1 4 3 2 3 2 1 3 4 3 2 1 3 4 4 4 3 1 4 4 1 3 3 4 3 2 4 1 3 1 1 1 1 3\n[1037] 2 2 4 2 4 2 4 1 2 2 4 2 2 4 3 4 2 4 2 4 4 1 4 3 4 1 1 1 3 4 3 4 2 3 3 4 4\n[1074] 1 3 4 3 4 1 1 4 3 3 1 4 3 4 4 1 4 1 3 3 4 1 2 3 4 4 4 3 4 3 4 3 1 4 2 2 3\n[1111] 2 2 3 2 2 2 2 1 2 4 4 4 2 4 4 3 3 2 2 4 3 4 3 4 4 3 3 3 4 2 2 3 4 4 4 1 3\n[1148] 3 4 1 1 1 2 2 3 3 4 4 1 4 3 4 3 1 2 4 2 4 2 3 4 4 4 4 1 3 1 3 3 4 4 4 4 4\n[1185] 4 1 3 4 3 2 4 4 4 4 1 3 4 4 4 2 2 2 1 2 2 1 3 1 4 4 2 3 3 2 2 3 2 1 4 2 1\n[1222] 4 4 3 4 2 4 4 4 2 1 4 2 4 3 1 2 4 4 3 3 3 3 4 4 1 3 2 2 1 3 3 3 3 3 4 3 1\n[1259] 1 1 1 3 3 1 2 3 4 3 4 1 3 4 3 4 1 4 3 4 4 3 4 3 3 3 3 4 3 4 4 2 2 1 2 2 2\n[1296] 1 4 4 3 3 3 3 1 3 1 4 4 4 4 2 3 4 3 3 3 3 1 3 2 1 4 4 3 3 3 4 3 3 2 4 4 4\n[1333] 1 3 4 1 3 1 1 4 4 3 4 3 3 4 3 3 3 2 4 4 1 1 3 3 1 3 4 4 3 1 4 2 3 4 2 4 1\n[1370] 1 4 3 3 3 4 4 4 4 4 4 3 2 2 2 4 4 4 2 4 1 4 2 2 2 4 2 4 1 1 2 1 1 4 4 2 4\n[1407] 2 2 1 4 2 2 3 4 4 2 4 1 4 4 4 2 4 1 4 4 4 3 2 2 4 2 2 2 3 2 1 2 1 1 3 4 4\n[1444] 4 3 4 2 3 3 3 3 4 3 3 1 3 2 4 3 4 4 3 3 4 3 3 3 2 2 4 3 3 2 4 2 3 3 2 3 4\n[1481] 3 4 1 2 4 4 2 3 1 1 4 2 1 3 1 1 2 4 2 3 4 3 4 4 4 4 1 3 3 4 4 4 4 3 4 4 3\n[1518] 3 2 3 3 4 3 3 3 3 3 1 3 3 3 3 1 4 3 4 2 3 4 4 3 2 4 2 2 3 3 3 4 4 3 4 3 3\n[1555] 3 3 3 3 4 2 3 4 4 3 4 4 3 4 1 3 3 1 3 4 4 1 2 4 3 1 4 2 4 3 1 3 3 1 3 4 3\n[1592] 3 4 2 4 1 4 1 4 2 4 1 2 2 4 4 4 4 1 1 4 2 2 4 4 3 1 4 1 4 2 4 3 4 4 3 1 4\n[1629] 4 2 4 4 4 4 1 4 3 3 1 4 3 3 4 3 4 3 3 2 2 3 4 1 4 3 3 4 2 3 1 1 1 1 4 3 3\n[1666] 4 2 4 2 4 3 2 3 3 1 1 2 3 3 4 1 1 1 1 1 1 3 1 1 4 3 1 1 1 3 4 1 1 1 3 4 1\n[1703] 4 3 3 4 3 3 3 3 2 4 3 4 4 3 4 4 3 2 3 1 3 3 4 3 2 1 4 4 4 1 4 4 1 3 2 1 2\n[1740] 2 3 3 3 3 4 1 2 3 2 4 3 3 1 3 2 3 1 1 2 1 1 4 2 4 1 1 1 3 3 4 3 3 3 3 2 4\n[1777] 3 3 3 3 3 1 3 2 4 3 4 3 4 1 3 4 3 1 4 3 4 4 3 3 1 2 3 3 1 4 4 1 4 1 3 4 2\n[1814] 4 2 3 4 4 2 4 3 4 2 1 3 2 3 1 1 3 3 3 3 3 3 1 4 4 1 4 3 4 1 4 2 3 3 3 1 1\n[1851] 3 2 4 4 3 1 3 3 3 1 3 1 4 1 4 4 1 4 3 3 3 3 3 3 3 3 3 2 1 2 1 2 1 1 4 2 4\n[1888] 3 1 4 1 1 3 3 3 1 3 3 2 4 3 4 3 4 1 3 4 3 2 4 3 2 4 3 4 2 3 2 3 1 3 4 4 2\n[1925] 2 2 2 3 1 3 1 1 2 3 2 3 1 3 2 3 1 3 1 1 1 3 3 1 4 3 1 3 4 3 1 3 2 2 1 2 2\n[1962] 4 2 1 3 3 4 1 3 3 4 3 4 4 4 1 1 3 4 1 1 1 1 1 1 3 3 3 1 4 4 1 2 3 3 3 3 3\n[1999] 3 1 3 3 3 3 3 3 3 2 3 2 2 3 3 4 2 2 4 2 4 4 3 3 1 3 1 3 2 3 3 1 4 3 2 1 4\n[2036] 2 3 3 4 2 1 4 4 4 4 2 4 3 3 3 4 3 3 2 2 3 3 3 1 3 1 2 4 4 3 4 4 3 4 4 3 4\n[2073] 3 1 3 4 4 1 4 4 4 2 4 4 3 3 2 3 4 3 3 3 2 4 4 3 4 3 3 3 3 2 1 4 3 4 1 3 3\n[2110] 1 3 3 3 2 1 3 2 4 4 4 3 4 3 3 4 3 3 1 3 4 4 3 3 3 4 1 4 1 2 2 4 4 3 2 3 3\n[2147] 4 4 2 2 4 4 2 2 1 3 2 2 4 2 4 2 4 2 4 3 3 1 1 1 1 1 4 3 1 1 4 4 3 4 3 4 3\n[2184] 3 4 2 2 4 2 4 4 3 3 4 2 4 2 2 1 1 3 3 1 3 3 3 4 4 4 4 3 4 4 4 4 3 2 4 3 4\n[2221] 4 3 3 3 3 3 3 3 4 3 4 3 2 3 2 4 1 3 3 4 3 1 3 3 1 4 3 3 2 1 1 4 3 1 3 4 4\n[2258] 4 1 4 1 4 2 3 3 3 3 3 3 3 4 3 4 2 4 3 1 2 1 3 2 2 1 1 1 1 3 3 1 2 4 3 1 2\n[2295] 4 3 3 1 4 4 4 4 1 4 3 3 4 3 4 4 3 4 4 2 4 3 4 3 3 2 4 3 4 3 1 4 4 4 4 3 1\n[2332] 3 1 4 1 4 1 3 3 2 3 3 2 3 2 1 3 2 4 3 1 1 4 2 2 4 4 2 1 4 4 2 3 3 1 4 1 1\n[2369] 3 3 4 1 2 2 1 3 1 2 1 1 1 3 4 2 4 3 3 3 2 2 4 3 4 4 1 1 1 2 2 2 2 4 1 4 4\n[2406] 1 2 4 1 4 1 1 1 4 1 4 1 1 2 1 4 1 1 4 1 4 3 1 3 1 1 3 1 1 1 4 3 3 3 4 3 3\n[2443] 1 1 1 1 1 4 4 1 3 3 4 4 1 1 3 3 1 3 3 2 2 3 4 3 3 4 2 4 3 3 2 4 2 4 3 2 1\n[2480] 4 4 1 1 1 1 1 4 4 4 3 4 1 3 4 4 3 2 4 4 3 4 1 4 4 3 1 1 4 3 4 1 1 2 4 3 2\n[2517] 3 1 2 1 3 4 3 3 3 3 4 4 4 3 3 3 3 3 2 3 4 4 4 4 3 3 3 4 4 3 3 4 1 1 4 1 4\n[2554] 3 3 3 3 3 3 4 2 4 2 4 3 1 2 4 1 4 4 2 2 3 3 1 1 1 4 4 3 3 3 3 3 3 3 2 3 3\n[2591] 4 3 3 3 4 3 1 4 1 1 4 1 4 4 4 2 3 1 1 2 3 1 4 4 2 4 4 4 4 3 3 4 4 4 2 3 4\n[2628] 4 1 1 4 4 1 3 1 2 3 1 4 2 2 3 2 3 3 4 2 4 3 3 3 3 2 3 1 1 1 4 3 2 3 3 4 2\n[2665] 2 4 3 4 4 3 3 3 4 2 4 4 2 3 4 4 4 3 4 4 4 2 4 1 3 4 4 4 3 4 4 4 3 2 3 4 2\n[2702] 4 4 4 1 1 1 4 1 1 1 3 3 1 1 3 1 3 2 3 2 3 4 4 3 3 2 4 1 2 1 3 4 2 3 1 4 2\n[2739] 4 2 3 4 3 2 2 2 3 4 3 4 3 4 4 2 2 1 1 2 2 4 3 3 3 4 3 4 2 3 4 3 1 4 4 2 4\n[2776] 4 4 4 2 4 4 3 1 1 1 3 2 3 3 3 1 1 1 4 3 2 4 3 4 4 1 1 2 2 2 4 3 3 1 3 2 4\n[2813] 4 3 2 2 4 2 3 4 4 1 3 2 3 3 1 3 3 3 3 3 2 4 4 3 1 3 2 2 2 2 2 2 2 2 2 2 3\n[2850] 1 3 2 3 4 2 3 4 2 3 4 3 2 2 2 4 4 4 4 4 4 4 2 3 2 4 2 3 3 4 2 2 2 4 2 4 2\n[2887] 2 2 2 4 3 3 1 3 2 3 1 1 2 3 2 2 3 2 4 3 1 2 2 2 3 3 2 1 2 2 4 4 2 4 2 1 4\n[2924] 4 4 1 2 3 3 4 3 2 1 4 2 2 2 1 4 4 4 4 3 4 4 3 4 4 1 4 4 2 4 4 2 4 2 2 2 2\n[2961] 4 4 2 4 4 4 4 4 3 2 3 4 4 4 4 3 4 4 4 4 4 2 1 3 2 4 4 4 2 1 3 3 4 4 4 4 4\n[2998] 3 4 4 4 4 3 2 4 3 1 3 3 1 1 4 2 4 2 2 4 3 4 2 2 2 4 2 4 3 4 3 4 4 4 4 2 1\n[3035] 3 2 1 3 4 1 4 3 3 4 4 2 4 3 4 1 1 1 3 4 2 4 2 4 1 2 3 3 4 3 1 4 1 4 4 2 4\n[3072] 2 3 4 4 2 4 1 2 4 2 3 2 2 2 2 2 1 2 2 2 1 3 4 2 2 2 4 4 4 4 2 4 4 4 3 3 3\n[3109] 3 1 4 2 4 4 4 4 2 2 3 2 1 4 4 2 4 3 4 2 2 4 3 1 4 4 4 1 4 4 4 4 1 2 4 4 4\n[3146] 4 4 3 4 3 2 4 1 2 4 4 4 4 4 4 2 4 4 4 1 4 4 4 2 4 3 2 4 4 4 3 2 3 2 4 2 4\n[3183] 4 2 2 4 2 4 4 3 4 3 4 4 2 4 4 4 4 4 3 4 2 4 3 3 2 4 3 3 4 3 4 3 2 2 4 4 4\n[3220] 2 2 2 4 3 3 2 4 1 1 4 3 4 2 2 4 3 3 3 4 2 4 4 4 2 2 4 4 3 3 3 4 3 4 4 1 1\n[3257] 1 1 1 1 1 2 1 2 1 3 4 3 4 1 4 2 2 4 4 2 3 4 1 4 4 4 4 3 4 4 4 4 3 1 2 2 1\n[3294] 2 4 1 1 1 4 4 2 2 2 2 3 2 3 1 4 2 4 3 2 2 1 2 2 4 4 3 4 2 4 2 4 4 3 2 4 4\n[3331] 3 3 3 3 2 1 1 1 2 2 4 2 4 1 1 1 1 3 2 2 4 2 2 2 4 4 3 2 2 2 2 2 4 2 2 2 4\n[3368] 4 3 4 4 4 3 4 3 4 3 1 3 1 4 4 4 3 3 4 3 1 2 2 4 4 2 4 1 1 4 1 1 2 4 4 4 4\n[3405] 2 4 2 1 1 4 3 4 3 1 3 3 1 2 1 3 3 2 4 3 4 3 3 3 4 3 3 3 4 2 2 2 2 4 1 4 4\n[3442] 4 2 4 1 4 3 2 4 4 4 4 4 2 4 2 3 3 4 3 4 1 4 4 3 4 4 1 2 3 1 4 4 2 1 3 2 3\n[3479] 3 2 2 4 2 2 2 4 2 1 2 2 3 4 4 4 4 4 3 3 4 4 4 4 3 2 4 4 3 4 3 3 3 2 4 2 2\n[3516] 2 3 4 4 4 1 3 3 1 4 4 4 3 2 4 3 3 2 3 3 3 2 4 4 2 2 4 3 3 3 1 3 1 4 3 4 4\n[3553] 4 4 2 4 4 2 4 2 2 2 3 2 2 2 4 2 2 2 2 2 4 2 4 4 3 4 4 2 3 4 2 2 2 4 3 4 4\n[3590] 4 4 3 3 3 4 4 4 3 3 1 2 4 4 4 2 3 3 2 3 3 3 2 4 3 3 2 1 4 4 4 3 4 2 4 2 1\n[3627] 4 1 3 3 4 4 4 4 3 2 2 4 2 2 4 3 3 4 4 3 2 2 4 4 4 1 4 1 4 4 1 4 3 4 4 3 2\n[3664] 3 3 4 3 4 2 4 3 2 2 2 4 3 2 3 4 4 1 4 4 1 4 1 3 2 1 4 3 4 4 4 4 3 4 1 2 3\n[3701] 3 4 3 3 3 3 2 4 1 3 2 3 3 1 2 1 3 4 4 1 3 4 4 3 4 4 4 3 2 4 1 3 4 4 4 2 2\n[3738] 4 4 3 3 3 3 3 3 3 4 1 4 3 3 4 3 3 4 4 4 3 3 4 4 2 2 2 4 1 1 1 4 1 4 4 4 4\n[3775] 1 4 4 4 4 2 1 4 2 1 4 2 1 1 1 1 1 1 4 3 4 4 2 2 4 3 2 2 4 4 2 2 2 4 4 4 3\n[3812] 3 4 3 3 4 4 4 4 4 4 3 1 1 4 2 4 2 4 2 4 4 4 4 3 4 4 4 3 4 2 1 4 4 2 3 4 3\n[3849] 2 2 4 4 2 4 4 3 2 4 4 1 1 3 1 1 2 4 4 1 1 3 3 1 1 3 1 4 3 2 3 2 4 4 4 3 4\n[3886] 2 3 2 4 4 2 4 4 2 4 2 3 3 4 4 2 2 2 2 4 2 2 2 4 4 3 4 2 4 4 4 3 1 4 4 4 3\n[3923] 2 4 4 2 2 4 3 3 2 4 4 2 2 1 4 3 2 3 3 3 4 4 3 3 4 3 4 3 3 3 2 4 3 2 4 2 4\n[3960] 4 3 3 4 4 3 2 4 1 1 4 3 4 2 1 1 3 4 4 1 1 3 3 3 4 4 4 4 1 4 4 1 4 2 4 4 4\n[3997] 4 3 4 4 4 4 2 4 4 4 2 4 2 3 4 3 4 3 1 2 3 4 1 2 2 4 3 3 3 2 3 3 2 4 4 4 4\n[4034] 4 4 3 3 3 4 4 1 3 4 4 4 4 3 4 4 2 4 2 3 4 3 2 4 4 4 2 2 2 4 4 2 4 3 3 3 4\n[4071] 3 2 3 4 2 4 4 4 4 2 4 4 3 3 2 2 2 4 2 4 3 2 4 2 2 2 4 2 4 4 2 3 3 2 2 4 3\n[4108] 3 4 3 1 2 2 2 4 2 3 3 4 3 4 3 3 2 2 3 3 1 1 2 4 1 1 4 2 4 4 1 2 3 3 3 4 4\n[4145] 3 3 4 3 4 2 1 1 4 1 1 1 1 3 3 3 3 3 3 4 4 2 3 4 4 4 3 4 3 2 3 3 3 4 4 1 4\n[4182] 2 3 2 2 1 2 4 4 4 2 4 2 2 2 2 2 3 3 2 2 2 4 3 4 2 3 4 2 2 4 1 3 2 1 1 1 4\n[4219] 3 1 2 4 4 2 2 1 3 2 1 4 4 2 2 4 4 4 4 2 4 2 4 3 3 2 4 4 2 4 4 3 2 2 2 2 4\n[4256] 4 4 4 4 4 3 4 3 3 4 3 4 4 3 1 3 1 4 4 4 4 4 3 2 4 4 4 4 2 2 2 2 4 2 4 4 1\n[4293] 4 1 4 1 4 4 4 3 3 3 1 4 4 4 4 4 2 4 3 4 4 2 4 4 2 3 4 4 1 3 4 4 4 3 3 3 3\n[4330] 3 3 3 3 3 3 3 3 3 3 2 3 4 3 4 4 4 4 3 3 1 2 4 3 3 3 4 3 1 3 1 3 4 4 4 4 3\n[4367] 4 4 4 4 4 2 4 2 3 1 4 2 4 4 3 3 4 2 3 3 3 2 2 4 3 1 3 3 3 3 3 3 3 3 3 4 3\n[4404] 1 1 1 4 2 1 4 3 2 4 2 4 4 3 4 4 4 4 4 4 4 4 4 4 1 3 3 3 2 2 1 3 3 2 3 4 4\n[4441] 3 4 3 4 4 4 4 2 4 3 4 1 3 2 3 3 3 3 4 4 3 3 4 4 4 4 3 3 2 4 2 2 2 4 4 4 4\n[4478] 3 3 4 4 3 3 4 4 2 2 2 4 4 4 2 2 3 2 1 2 3 4 2 3 3 3 4 4 3 4 2 3 2 3 4 4 2\n[4515] 1 4 2 2 2 3 1 1 2 3 3 3 1 2 2 3 3 3 4 4 4 3 3 2 4 2 4 4 2 2 4 4 2 2 1 2 2\n[4552] 4 4 4 4 2 4 1 4 4 4 2 4 4 4 3 3 3 4 4 2 2 2 2 4 4 2 2 2 4 4 4 3 3 4 3 4 4\n[4589] 4 4 3 1 3 4 4 4 4 2 4 2 4 4 3 4 3 2 4 3 2 2 2 2 3 3 3 4 2 4 4 1 4 2 4 4 2\n[4626] 3 1 2 2 2 4 4 1 1 4 4 3 4 3 1 4 4 2 1 4 3 2 4 1 2 2 4 1 2 3 3 3 3 4 2 2 3\n[4663] 4 4 4 4 1 4 4 4 3 3 3 4 3 3 4 4 3 3 4 2 2 4 1 4 4 3 3 3 3 3 3 3 3 4 2 4 4\n[4700] 3 3 3 3 2 1 4 4 4 4 3 4 4 4 2 4 2 2 4 4 2 2 2 4 3 2 4 2 4 4 2 4 3 3 4 2 2\n[4737] 2 4 4 2 1 4 4 3 2 1 4 2 3 3 3 1 2 4 4 2 4 4 4 4 4 4 2 4 4 2 4 3 3 3 3 3 1\n[4774] 2 4 4 4 4 4 2 4 3 4 4 3 2 4 4 3 4 4 4 4 3 3 3 3 2 4 4 4 3 4 4 2 2 4 4 2 3\n[4811] 3 2 4 3 4 4 3 4 2 4 3 4 3 4 3 4 4 2 3 2 4 4 4 2 2 4 2 1 4 2 4 1 2 3 3 2 3\n[4848] 4 3 3 3 3 4 2 2 3 3 4 3 4 4 2 2 2 3 2 4 2 4 2 4 2 3 4 4 2 4 2 2 3 3 4 3 3\n[4885] 3 3 4 2 4 4 2 4 4 2 3 4 4 2\n\nWithin cluster sum of squares by cluster:\n[1] 681403.3 357903.9 579703.3 462118.7\n (between_SS / total_SS =  80.0 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n# fviz_cluster(kmeans4, data = whitewine)\n\n\nwhitewine &lt;- whitewine %&gt;%\n  mutate(Cluster = kmeans4$cluster) # new field created in whitewine, taken from kmeans4: cluster variable\n\n\nwhitewine$Cluster &lt;-\nas_factor(whitewine$Cluster) # initially cluster value is interger (continous variable) convert it to obejct class factor. (Cluster of 1,2,3 etc)\n\n\nwhitewine %&gt;%\n  parallelPlot(refColumnDim = \"Cluster\",\n               width = 300,\n               height = 250,\n               rotateTitle = TRUE)"
  }
]